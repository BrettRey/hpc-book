% Glossary entries for the HPC book
% This file is \input from the main document after the preamble

% ===== Core framework terms =====

\newglossaryentry{hpc}{
  name={homeostatic property cluster (HPC)},
  text={HPC},
  description={A category whose members share properties not because of a common essence but because causal processes maintain the co-occurrence of those properties. Identified by two diagnostics: \emph{projectibility} (the category supports induction) and \emph{homeostasis} (named mechanisms maintain the cluster under perturbation). See Chs~4, 7, 8}
}

\newglossaryentry{projectibility}{
  name={projectibility},
  text={projectibility},
  description={The capacity of a category to support induction: knowing that an item belongs to the category licenses predictions about its other properties. A category is projectible if learning from a finite sample allows you to predict unobserved instances. Projectibility is one of the two diagnostics for genuine HPC status. See Ch~6}
}

\newglossaryentry{homeostasis}{
  name={homeostasis},
  text={homeostasis},
  description={Not mere stability but active return: a homeostatic system, when perturbed, tends to return to its prior configuration rather than settling into any stable state. Grammatical categories maintain homeostasis through mechanisms like interactive alignment (speakers correct each other) and entrenchment (high-frequency items anchor the cluster). See Ch~4}
}

\newglossaryentry{entrenchment}{
  name={entrenchment},
  text={entrenchment},
  description={The strengthening of mental representations through repeated use. High-frequency items are processed faster, stored more robustly, and resist analogical pressure. Entrenchment anchors categories by making their most frequent members highly accessible and resistant to change. See Ch~4}
}

\newglossaryentry{essentialism}{
  name={essentialism},
  text={essentialism},
  description={The view that categories have definitions: necessary and sufficient conditions that determine membership. Essentialism about grammar claims that categories like \textsc{noun} or \textsc{verb} can be defined by invariant properties. The HPC framework rejects this: categories are maintained by mechanisms, not defined by essences. See Ch~2}
}

\newglossaryentry{stabiliser}{
  name={stabiliser},
  text={stabiliser},
  description={A mechanism that maintains a category cluster. Where \enquote{mechanism} emphasises causal structure, \enquote{stabiliser} emphasises the functional role—what keeps the cluster clustered. Something counts as a stabiliser if removing it would change the clustering. Example stabilisers: acquisition, entrenchment, alignment, transmission, functional pressure. See Ch~7}
}

\newglossaryentry{alignment}{
  name={interactive alignment},
  text={alignment},
  description={The tendency of interlocutors to converge on shared linguistic choices during conversation. Alignment maintains categories by enforcing community-wide coherence: when speakers accommodate to each other, they reinforce shared norms; when they resist innovations, they exert corrective pressure. See Ch~4}
}

\newglossaryentry{prototype}{
  name={prototype},
  text={prototype},
  description={The central, most typical member of a category—the first example that comes to mind, the item that best exemplifies the category's properties. Prototype theory describes categorical structure but doesn't explain what maintains it. HPC explains why prototypes are prototypes: they're the items maintained most robustly by the braid of mechanisms. See Ch~4}
}

\newglossaryentry{maintenanceview}{
  name={maintenance view},
  text={maintenance view},
  description={The claim that categories are real because they are maintained—that what makes a linguistic category a genuine kind is not an essence but the ongoing operation of stabilising mechanisms. \enquote{Maintenance isn't just preventing breakdown; it's the whole process of keeping something going} (Stewart Brand). See Ch~4}
}

\newglossaryentry{properfunction}{
  name={proper function},
  text={proper function},
  description={In Ruth Millikan's framework: the function an item has in virtue of its history of selection. A heart's proper function is pumping blood because that's the function that explains its reproductive success. Applied to grammar: the proper function of a construction is the function that explains its transmission across generations. See Ch~10}
}

\newglossaryentry{derivedproperfunction}{
  name={derived proper function},
  text={derived proper function},
  description={A function an item acquires by being recruited to serve a purpose that was not its original selected function. Example: the definite article's proper function may be discourse tracking, but it acquires derived functions (weak definites, generics) when speakers exploit stable side effects. See Ch~10}
}

\newglossaryentry{deitality}{
  name={deitality},
  text={deitality},
  description={The morphosyntactic form cluster associated with determiners like \textit{the}—the bundle of formal properties (definiteness agreement, article drop, anaphoric licensing) that travel together independently of the semantic definiteness cluster. Proposed as a term to distinguish morphosyntactic patterning from semantic definiteness. See Ch~10}
}

\newglossaryentry{fatclass}{
  name={fat class},
  text={fat class},
  description={A label that lumps distinct causal clusters into a single bin—a wastebasket category. Fat classes miss the projectibility diagnostic: learning one subclass doesn't let you predict others. Example: traditional \textsc{adverb} pools manner adverbs, degree words, and sentence adverbs—items maintained by different mechanisms. See Ch~8}
}

\newglossaryentry{thinclass}{
  name={thin class},
  text={thin class},
  description={A pattern that barely exists as a maintained kind. Thin classes miss the homeostasis diagnostic: the mechanisms that would stabilise them are absent or too weak. Example: preposition doubling (\textit{from which to choose from}) is a thin pattern—it exists but is not reproduced as a target construction. See Ch~8}
}

\newglossaryentry{comparativeconcept}{
  name={comparative concept},
  text={comparative concept},
  description={An analyst's tool constructed for cross-linguistic comparison (Haspelmath's term). Comparative concepts are defined by the typologist, not discovered in particular languages. They may be useful without being natural kinds—\textsc{subject} as a comparative concept needn't be maintained by the same mechanisms across languages. See Ch~8}
}

\newglossaryentry{madagascarfallacy}{
  name={Madagascar fallacy},
  text={Madagascar fallacy},
  description={The mistake of treating an ecosystem as if it were a species—of attributing to a collection the kind-status that belongs only to its components. Applied to language: \textit{English} is an ecosystem of HPCs, not itself a single HPC. See Ch~8}
}

% ===== Countability (Ch 9) =====

\newglossaryentry{individuationcluster}{
  name={individuation cluster},
  text={individuation cluster},
  description={The semantic cluster of properties that make a referent construable as a discrete, countable entity: boundedness, atomicity, enumerability, and homogeneity resistance. Example: a \textit{ball bearing} has all four properties; \textit{water} has none. Maintained by perceptual mechanisms (edge detection, object files) and cognitive processes (cross-modal integration). Coupled with the count cluster to form countability. See Ch~9}
}

\newglossaryentry{countcluster}{
  name={count cluster},
  text={count cluster},
  description={The morphosyntactic cluster of properties that travel together in English count nouns: plural inflection, compatibility with cardinals (\textit{three books}), acceptance of \textit{many}/\textit{few}, and plural agreement. Example: knowing \textit{cat} takes a plural lets you predict it takes \textit{a}, \textit{several}, and \textit{many}. Quasi-count nouns like \textit{cattle} accept loose properties (\textit{many cattle}) but reject tight ones (\textit{*three cattle}). See Ch~9}
}

\newglossaryentry{bidirectionalinference}{
  name={bidirectional inference},
  text={bidirectional inference},
  description={The mechanism coupling semantic construal to morphosyntactic form. In comprehension, count morphosyntax leads hearers to expect atomic referents; in production, an individuated construal prompts count syntax. Each count property becomes a cue to the same underlying condition. Example: hearing \textit{three dogs} cues individuation; intending individuation prompts \textit{three} over \textit{much}. See Ch~9}
}

\newglossaryentry{functionalanchoring}{
  name={functional anchoring},
  text={functional anchoring},
  description={The mechanism by which a lexical alternative bleeds pressure for regularisation. When a singulative lexeme handles the function that analogy would otherwise push a quasi-count noun to fill, the quasi-count noun persists without extending tight-linkage properties. Example: \textit{cattle} remains quasi-count for centuries because \textit{cow}, \textit{bull}, and \textit{head of cattle} handle singulative reference. Contrast \textit{data}, which drifts toward mass status as \textit{datum} dies. See Ch~9}
}

\newglossaryentry{chunking}{
  name={chunking},
  text={chunking},
  description={The cognitive process whereby high-frequency sequences are stored and retrieved as units, bypassing compositional assembly. Example: \textit{many cattle} is a chunk—retrieved whole—while \textit{three cattle} must be assembled online and fails because the components don't fit. Explains why quasi-count nouns feel natural in loose frames but deviant in tight ones. See Ch~9}
}

\newglossaryentry{basin}{
  name={basin (attractor)},
  text={basin},
  description={A dynamical-systems metaphor for category structure: a region in parameter space toward which system states are drawn. Think of a spinning top—the basin keeps it upright despite perturbations. Members near the centre satisfy all diagnostics; those at the periphery satisfy only some. Example: \textit{book} spins at the centre of the count basin, clearing all precision locks; \textit{cattle} spins off-centre, clearing only loose ones. See Chs~5, 9}
}

% ===== Definiteness (Ch 10) =====

\newglossaryentry{definitenesscluster}{
  name={definiteness cluster},
  text={definiteness cluster},
  description={The semantic cluster of properties that make a referent identifiable: familiarity (discourse-old), uniqueness (one candidate in the domain), identifiability (hearer can pick it out). Maintained by discourse tracking, domain restriction, and Theory of Mind. Children acquire components sequentially: familiarity by age 2--3, uniqueness by 4--5, identifiability by 5--6. Distinct from the morphosyntactic form cluster (deitality). See Ch~10}
}

\newglossaryentry{normalconditions}{
  name={Normal conditions},
  text={Normal conditions},
  description={In Millikan's framework: the conditions under which a device (form, construction) performs its proper function—the circumstances that explain its reproductive success. Example: the definite article's Normal conditions include speaker and hearer sharing a discourse model and the referent being uniquely identifiable within it. Derived functions (weak definites, generics) exploit stable side effects while the Normal function remains intact elsewhere. See Ch~10}
}

% ===== General framework =====

\newglossaryentry{fieldrelativeprojectibility}{
  name={field-relative projectibility},
  text={field-relative projectibility},
  description={The principle that a category's projectibility is indexed to an analytical domain—different subfields may have different right-sized categories for overlapping extensions. Example: for a botanist, \textit{tomato} is a fruit (projectibility indexed to reproductive structure); for a chef, it's a vegetable (projectibility indexed to culinary use). Both are correct for their purposes. Applied to grammar: definiteness (semantic) and deitality (morphosyntactic) project differently because they answer different questions. See Chs~6, 10}
}

\newglossaryentry{twodiagnostictest}{
  name={two-diagnostic test},
  text={two-diagnostic test},
  description={The framework for determining whether a putative category is a genuine HPC kind. Two independent diagnostics must be satisfied: (1) \emph{projectibility}—knowing an item belongs to the category supports induction about its other properties; (2) \emph{homeostasis}—identifiable mechanisms maintain the cluster under perturbation. Example: the count cluster passes both (plural marking predicts cardinal compatibility; bidirectional inference maintains the coupling). Thin categories fail homeostasis; fat categories fail projectibility. See Ch~8}
}

\newglossaryentry{copiedkind}{
  name={copied kind},
  text={copied kind},
  description={A category whose members are produced from each other or from a common template—they share properties because they share a lineage, not because they share an essence (Millikan's term). Biological species are copied kinds; artefacts like screwdrivers are copied kinds; grammatical categories are copied kinds par excellence. See Ch~4}
}

\newglossaryentry{unicept}{
  name={unicept},
  text={unicept},
  description={A concept that tracks sameness through multiple fallible methods—we recognise a friend by face, voice, gait, or handwriting, with none privileged as definitional (Millikan's term). Applied to grammar: we identify nouns through plural morphology, determiner compatibility, argument positions, semantic features, and more. The category is what the diagnostics converge on, not what any single diagnostic defines. See Ch~4}
}

\newglossaryentry{iteratedtransmission}{
  name={iterated transmission},
  text={iterated transmission},
  description={The process by which language is passed imperfectly across generations, with structure emerging from the transmission dynamics themselves. Easy-to-learn variants survive; hard-to-learn variants are distorted or lost. Kirby's artificial-language experiments show that arbitrary initial languages become compositional through iterated transmission. See Ch~4}
}

\newglossaryentry{perturbationsensitivity}{
  name={perturbation sensitivity},
  text={perturbation sensitivity},
  description={The diagnostic test for genuine homeostasis: weaken a mechanism and the cluster should fray. A genuine HPC resists perturbation or self-corrects; a mere label is perturbation-inert. Example: heritage language attrition shows perturbation sensitivity—when transmission weakens, category boundaries become variable in predictable ways. See Ch~8}
}

\newglossaryentry{cliquishstability}{
  name={cliquish stability},
  text={cliquish stability},
  description={Slater's term: finding some properties reliably indicates the whole cluster. Cliquish stability can hold even when instance stability is imperfect—even if individual nouns drift, the correlation structure persists. This is what matters for induction: we care whether knowing an item is a noun licenses predictions about its other properties. See Ch~4}
}

% ===== Discreteness and gradience (Ch 5) =====

\newglossaryentry{dynamicdiscreteness}{
  name={dynamic discreteness},
  text={dynamic discreteness},
  description={Discreteness that is achieved by mechanisms rather than given by essences. Category boundaries are sharp—membership is binary—but the sharpness is maintained by stabilising forces (acquisition, entrenchment, alignment, transmission) rather than by definitional content. The view dissolves the apparent contradiction between sharp categories and gradient judgments. See Ch~5}
}

\newglossaryentry{realgradience}{
  name={real gradience},
  text={real gradience},
  description={Gradient structure that is genuine evidence about category organisation, not noise to be explained away. Typicality judgments, variable acceptability, and boundary instability reflect distance from category cores maintained by mechanisms. Gradience is epistemic (in our access), not ontological (in membership itself). See Ch~5}
}

\newglossaryentry{relativetolerance}{
  name={relative tolerance},
  text={relative tolerance},
  description={The principle that changes negligibly small relative to the current scale preserve category membership, while changes appreciable at that scale may not. One grain doesn't matter when you have a thousand; it may matter when you have fifty. This explains why tolerance intuitions coexist with boundary intuitions—both are correct, just in different regimes. See Ch~5}
}

% ===== Projectibility mechanisms (Ch 6) =====

\newglossaryentry{mechanisticdrift}{
  name={mechanistic drift},
  text={mechanistic drift},
  description={The phenomenon whereby the mechanisms that currently maintain a category may differ from those that originally produced it. Like a volcanic island now maintained by coral reefs rather than eruptions: the label names the island, not the volcano. Example: aspect labels may persist after the semantic invariants that motivated them have been replaced by lexeme-specific cue structures. See Ch~6}
}

\newglossaryentry{grueproblem}{
  name={grue problem},
  text={grue problem},
  description={Goodman's riddle: why do we project \enquote{green} but not \enquote{grue} (green if examined before time $t$, blue otherwise)? The mechanistic answer: green is projectible because mechanisms produce greenness; no mechanism produces grueness. Applied to language: \textsc{noun} projects because mechanisms cluster nominal properties; pseudo-categories like \enquote{words starting with B} don't. See Ch~6}
}

\newglossaryentry{crosscuttingkinds}{
  name={crosscutting kinds},
  text={crosscutting kinds},
  description={Khalidi's term: overlapping classification schemes where the same entity can be a node in multiple causal networks simultaneously. A tomato is both a fruit (botanical mechanisms) and a vegetable (culinary mechanisms). Applied to grammar: definiteness (semantic) and deitality (morphosyntactic) are crosscutting kinds with overlapping extensions. See Ch~6}
}

% ===== Essentialism and its alternatives (Ch 1–3) =====

\newglossaryentry{nominalism}{
  name={nominalism},
  text={nominalism},
  description={The view that categories are convenient fictions—labels we apply for practical purposes without claiming they correspond to natural kinds. Haspelmath's comparative concepts are nominalist in spirit: useful tools for cross-linguistic comparison, not discoveries about the mind. The HPC framework rejects nominalism: categories are real because maintained. See Ch~3}
}

\newglossaryentry{grammaticalisation}{
  name={grammaticalisation},
  text={grammaticalisation},
  description={The diachronic process by which lexical items become grammatical markers. \textit{Will} went from volitional verb to future auxiliary; \textit{while} from noun to subordinator. Grammaticalisation trajectories are gradual, driven by frequency, phonological reduction, semantic bleaching, and reanalysis. The boundary zone is populated because language change populates it. See Ch~2}
}

\newglossaryentry{replicator}{
  name={replicator},
  text={replicator},
  description={In David Hull's framework: an entity that passes copies of itself through time, with variations filtered by transmission. Linguistic variants are replicators—they reproduce across speakers and generations, with easier-to-learn variants out-competing harder ones. The replicator concept links language to evolutionary dynamics without requiring genetic inheritance. See Ch~5}
}

\newglossaryentry{interactor}{
  name={interactor},
  text={interactor},
  description={In David Hull's framework: an entity that interacts with its environment in ways that cause differential replication. Communicative episodes are interactors—they're where selection pressure applies to linguistic variants. Successful communication reinforces the forms used; failed communication weakens them. See Ch~5}
}

\newglossaryentry{verblessclause}{
  name={verbless clause},
  text={verbless clause},
  description={A construction with subject + predicate structure but no verb in the predicate (e.g., \textit{with their hands above their heads}). \textit{CGEL} calls these clauses despite defining clauses as VP-headed—a telling inconsistency. The HPC view explains why: VP-headedness and predication usually cluster but can come apart where mechanisms compete. See Ch~2}
}

\newglossaryentry{opentexture}{
  name={open texture},
  text={open texture},
  description={Hart's term: the penumbral region where existing rules don't determine outcomes. Law responds to open texture with institutional repair (litigation, legislation). Natural language has no Supreme Court—grammaticalisation proceeds without appeal. Open texture in grammar is where mechanisms are weak or in competition. See Ch~2}
}

