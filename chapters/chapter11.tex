\chapter{Lexical categories and their maintenance}
\label{ch:lexical-categories}

% Chapter 11: Third Part III case study
% Target: ~6,200 words
% Structure: The Anatomist's Table (Wastebasket → Skeleton → Mimics)

\epigraph{The resemblance of one animal to another is of exactly the same essential nature as the resemblance to a leaf, or to bark, or to desert sand, and answers exactly the same purpose.}{— Alfred Russel Wallace, \textit{Mimicry, and Other Protective Resemblances Among Animals} (1867)}

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{The mess}
\label{sec:11:hook}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

\mention{Quickly}. \mention{Very}. \mention{Somewhat}. \mention{Absolutely}. \mention{Frankly}. \mention{Apparently}. \mention{Probably}. \mention{Already}. \mention{Still}. \mention{Only}. \mention{Even}. \mention{Not}. \mention{Moreover}. \mention{However}. \mention{Therefore}. \mention{Otherwise}.

What do these words have in common? The dictionary says they're adverbs. But what does that mean? They modify different things: \mention{quickly} modifies manner, \mention{very} and \mention{somewhat} modify degree, \mention{frankly} signals speaker stance, \mention{apparently} and \mention{probably} mark epistemic status, \mention{already} and \mention{still} locate events in time, \mention{only} and \mention{even} are focus particles, \mention{not} negates, \mention{moreover} and \mention{however} organize discourse, \mention{therefore} marks inference. Their distributions overlap only partially. Their semantic contributions share almost nothing. The label \mention{adverb} gathers them like socks in a drawer---not by what they are, but by what they aren't. They're not nouns; they're not verbs; they're not adjectives. What remains is the bin.

And then there's \mention{otherwise}---the word that kept Rodney Huddleston awake in Chapter~\ref{ch:words-wont-hold-still}. Dictionaries call it an adverb, but it can also be predicative (\mention{the truth is quite otherwise}), a conjunct (\mention{otherwise we'll be late}), and something close to a preposition in \mention{this suggests otherwise}. The word wouldn't hold still then; it still won't. That's not a bug in the analysis. That's the wastebasket showing its seams.

\bigskip
This chapter is a dissection. We will find what holds together and what doesn't.

I won't catalog every lexical category. The goal is to ask a different question: what makes a category cohere---or fail to cohere? We'll examine four major classes (nouns, verbs, adjectives, adverbs) and one apparent class (pronouns) that turns out to be several. The closed functional categories---determiners, prepositions, conjunctions---are a different story, better left to typological specialists \citep{haspelmath2010}. Our business is with the mechanisms, and the mechanisms are clearest where they succeed spectacularly (nouns and verbs), fail instructively (adverbs), or produce an illusion that rewards closer inspection (pronouns).

The structure follows the anatomist's table. First, the wastebasket: the category that \textit{doesn't} hold together. Then the skeleton: the categories that hold together so well they appear in every language ever described. Then the mimics: the forms that look alike on the surface but turn out to be different animals underneath, convergently evolved to occupy the same ecological niche.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{The wastebasket: adverbs}
\label{sec:11:wastebasket}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

Start with failure. If lexical categories are \abbr{HPC} kinds maintained by mechanisms, then a class with no unified maintenance regime should fall apart under scrutiny. Adverbs are that class.

The traditional definition is distributional: adverbs modify verbs, adjectives, or other adverbs. But this is too broad. \mention{Yesterday} modifies a clause, not a verb; \mention{even} is a focus particle; \mention{however} is a discourse connective; \mention{very} is a degree word; \mention{frankly} is an evidential marker. We've lumped together half a dozen functional types because they share one negative property: they can't be the head of a noun phrase or predicative complement. Excellent storage capacity; terrible explanatory power.

From a teleosemantic perspective \citep{millikan1984}, a category should have a \textit{proper function}---the job its members were selected to do. Nouns refer; verbs predicate; adjectives attribute properties. What is the proper function of an adverb? The question has no good answer. Manner modifiers (\mention{quickly}) describe how an event unfolds. Degree modifiers (\mention{very}, \mention{slightly}) scale a gradable property. Evidential markers (\mention{apparently}, \mention{frankly}) signal the speaker's epistemic stance. Discourse connectives (\mention{however}, \mention{moreover}) structure information flow. There is no unified \textit{for}.

Grammaticalization reveals the heterogeneity. Manner adverbs in English derive from adjectives via \mention{-ly}, and their syntax still resembles adjectival modification. Time adverbs like \mention{today} and \mention{tonight} are etymologically noun phrases (cf. Old English \textit{tōdæge}, `on this day'), and they retain nominal properties: they resist determiners, they can serve as temporal anchors, they combine with prepositions only marginally (\mention{since yesterday} vs. \ungram since quickly). Focus particles like \mention{even} and \mention{only} pattern with focus-marking constructions; they can modify almost any constituent (\mention{even Kim}, \mention{only the red one}, \mention{I only eat fish}), a distribution no manner adverb shares. Each subclass has its own history, its own syntactic home, its own path into the language. The category \mention{adverb} is a reunion of strangers who happen to share a bus stop.

Simon Kirby's iterated-learning framework \citep{kirby2008} makes a prediction here: heterogeneity is unstable. Languages evolve toward learnability; if a category lacks a coherent core, learners should either fragment it into tighter subcategories or regularise it by eliminating outliers. What keeps \mention{adverb} intact is not homeostasis but frequency. \mention{Very}, \mention{not}, \mention{just}, \mention{only}, \mention{even}, \mention{always}, \mention{never}---these are among the highest-frequency words in the language \citep{davies2008}. They survive as memorised tokens, not as projections from a productive schema. Take away the fossil collection and the category dissolves.

This is the diagnostic from Chapter~\ref{ch:failure-modes}: \mention{adverb} is a \textit{fat} category. It groups items by a distributional convenience, not a principled clustering. It fails the homeostasis test: perturbation in one region doesn't propagate. If children stopped learning \mention{however} tomorrow, it would not affect the acquisition of \mention{quickly}; if \mention{very} disappeared, \mention{yesterday} would carry on undisturbed. The properties don't reinforce each other; the subclasses don't share a mechanism. The category has a name but not a nature.

Compare this to what follows.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{The skeleton: nouns and verbs}
\label{sec:11:skeleton}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

Every language ever described has nouns and verbs. Not everyone agrees about what exactly \textit{makes} a noun a noun or a verb a verb, but the categories themselves are cross-linguistic constants. This is a remarkable empirical fact. It demands explanation.

The distributional profile of a prototypical noun---say, \mention{dog}---comprises a cluster of properties that reinforce each other. Nouns can function as arguments: subjects, objects, obliques. They take determiners. They inflect for number. They participate in possessive constructions. They trigger agreement. They are the default category for introducing new referents into discourse. These properties don't follow from each other by logical necessity, but they correlate with such regularity that typologists can use any one of them to identify the rest \citep{croft2001}. That correlation is the signature of homeostasis.

Verbs show the same clustering on a different axis. They serve as predicates. They take arguments. They inflect for tense-aspect-mood. They trigger subject agreement. They combine with auxiliaries. They are the default category for asserting what is going on. Again: the properties don't entail each other, but they cohere so tightly that the presence of one licenses inferences about the others.

Why should this be? The standard formalist answer appeals to Universal Grammar: nouns and verbs are categories built into the human language faculty. But that answer merely restates the observation. Why should the language faculty include exactly these two major lexical categories and not others? Why these clusters and not some rearrangement?

The \abbr{HPC} answer is causal. Nouns and verbs are stable because they are maintained by converging mechanisms at multiple scales.

At the \textit{cognitive} scale, nouns and verbs track a fundamental conceptual distinction: \textit{things} and \textit{events}. Developmental psychology shows that infants distinguish objects from actions before they have words for either \citep{spelke2007}. The perceptual difference is not linguistic in origin; it's part of domain-general cognition. But because the distinction is cognitively available, languages consistently recruit it. Nouns are the natural home for object concepts; verbs are the natural home for event concepts. The fit between conceptual structure and grammatical structure is not accidental. The categories are projectible because they carve the world at a joint the mind already recognizes.

At the \textit{discourse} scale, the noun/verb distinction tracks a fundamental communicative function: \textit{reference} and \textit{predication}. Discourse moves forward when speakers introduce referents and say things about them. Nouns provide the referents; verbs provide the predications. This is not a contingent fact about some languages; it's a constraint on any system that conveys propositional content. A language that lacked the distinction would lack the machinery for basic assertion. The functional pressure is universal, and the grammatical categories that serve it are correspondingly robust.

At the \textit{acquisition} scale, the noun/verb distinction is learned early and transferred broadly. Children acquiring English generalise nominal morphology to novel nouns and verbal morphology to novel verbs \citep{tomasello2003}. Errors like \mention{I goed} or \mention{two sheeps} show that children have abstracted a productive schema, not just memorised individual forms. Crucially, they don't extend nominal morphology to verbs or vice versa: the categories are represented as distinct, and their properties cluster together in the child's grammar as they do in the adult's. This is the \textit{projectibility} diagnostic from Chapter~\ref{ch:projectibility}: new items are slotted into the existing category and inherit its properties. The clustering survives transmission.

At the \textit{typological} scale, the noun/verb distinction appears in every language we have records for. This is not proof of universality---we haven't examined every possible language, and some analyses of Salish languages have questioned whether the distinction is grammatically obligatory \citep{kinkade1983}. But even in languages where the evidence is contested, the semantic domains of objects and events are consistently distinguished; the debate is about whether the distinction is encoded in morphology, in syntax, or in both. The robust cross-linguistic tendency is itself evidence of mechanism: whatever forces produce noun/verb stability in English also operate in Mandarin, in Swahili, in Warlpiri \citep{haspelmath2010}.

The contrast with adverbs is stark. Nouns and verbs are tight \abbr{HPC} kinds: perturbation in one property propagates to the others, acquisition generalises across the category, and the cluster is stable across languages and registers. Adverbs are not: the subcategories are functionally independent, learning is item-specific, and cross-linguistic comparison shows enormous variability. The difference is not gradual. It is architectural. Nouns and verbs have thick braids of mechanism holding them together; adverbs have a label.

Carl Zimmer once observed that sharks and dolphins look alike because physics imposes a penalty on drag: streamlined bodies are hydrodynamically efficient, regardless of ancestry \citep{zimmer2015}. The parallel here is instructive. Nouns and verbs look alike across languages because communication imposes pressure on form: a system that marks reference and predication will be easier to learn, easier to use, easier to transmit. The categories are not Platonic forms; they are standing waves maintained by converging forces. What persists is not the category as a thing; what persists is the maintenance regime.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{The asymmetry: adjectives}
\label{sec:11:adjectives}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

Adjectives occupy the middle ground. They are tighter than adverbs but looser than nouns or verbs. Some languages have them; others do without.

In English, adjectives form a recognizable cluster. They appear in attributive position (\mention{the tall building}), predicative position (\mention{the building is tall}), and postpositive position (\mention{something tall}). They take degree modifiers (\mention{very tall}). They inflect for comparison (\mention{taller}, \mention{tallest}). They can be nominalised (\mention{the young}, \mention{the poor}). The properties co-occur with enough regularity that we can project them: a novel adjective will be expected to participate in all of them.

But the clustering is weaker than for nouns and verbs. Not all adjectives accept comparison (\ungram\mention{more dead}, \ungram\mention{most unique}). Not all occupy all three positions (\ungram\mention{the asleep child}, \ungram\mention{the mere building}). Derived adjectives like \mention{computational} resist degree modification (\ungram\mention{very computational}). The cluster has gaps. Its edges fray.

Cross-linguistically, the variability is dramatic. Many languages encode property concepts as verbs: Mandarin \mention{tā hěn gāo} (`he very tall') uses an unmarked stative predicate, not an adjective plus copula.  Others encode them as nouns: in Polynesian languages, colour terms pattern morphosyntactically with kin terms and body parts. Some languages have only a small, closed class of \enquote{true} adjectives---perhaps a dozen words---while property modification is otherwise handled by relative clauses or denominal constructions \citep{dixon2004}. The category \mention{adjective} is not a cross-linguistic universal. It is, in Martin Haspelmath's terminology, a \term{comparative concept}: a yardstick researchers bring to the data, not a category found in every language \citep{haspelmath2010}.

What explains the asymmetry?

The mechanisms that stabilize nouns and verbs are weaker for adjectives. At the cognitive scale, property concepts are parasitic on object concepts: \mention{big} needs a referent to be big; \mention{red} needs a surface to be red. Adjectives modify; they don't stand alone. The conceptual grounding is derivative rather than fundamental \citep{givon2001}. At the discourse scale, property attribution is optional: you can identify a referent and predicate an event without ever mentioning a property. The communicative pressure is weaker; the grammatical reflex is correspondingly less robust.

Semantic type matters here. R.M.W. Dixon's typological work \citeyearpar{dixon2004} shows that languages differ in which property types receive adjectival treatment:

\begin{itemize}
\item \textbf{Dimension} (\mention{big}, \mention{long}): high frequency, scalar, degree-compatible. These are the most stable across languages.
\item \textbf{Age} (\mention{young}, \mention{old}): relational to temporal deixis, may pattern with participles or stative verbs.
\item \textbf{Colour} (\mention{red}, \mention{green}): often derived from nouns (\mention{gold}, \mention{ash}), sometimes form a small closed class.
\item \textbf{Value} (\mention{good}, \mention{bad}): highly evaluative, prone to grammaticalization, unstable clustering.
\end{itemize}

Each type has a different mechanism profile. Dimension adjectives show the tightest fit with degree morphology; colour adjectives show the greatest variability across languages. The category \mention{adjective} is not a single cluster but a family of overlapping subclusters, held together more loosely than nouns or verbs.

To use Zimmer's zoological metaphor: if nouns and verbs are the skeleton, adjectives are the plumage. Some birds have exploded this category into a massive display (English). Others have almost none (languages that use verbs for properties). Plumage is not essential to flight; the skeleton is. Adjectives are an evolutionary luxury. They emerge where discourse economy creates a niche for property modification, but the niche isn't deep enough to guarantee the category's presence in every language \citep{croft2001}.

The \abbr{HPC} framework clarifies the difference. Adjectives are a thinner \abbr{HPC} kind than nouns or verbs. The clustering is real, and it supports genuine projectibility: if I coin \mention{blick} as an adjective, you will expect it to take \mention{very}, to appear attributively, to compare. But the mechanisms are weaker, the cross-linguistic stability is lower, and the category is liable to dissolve into verb-like or noun-like strategies depending on the language's historical trajectory. Where nouns and verbs are architectural load-bearers, adjectives are decorative but disposable.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{The mimics: convergent evolution in pronouns}
\label{sec:11:mimics}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

Now for the surprise.

Consider three items: \mention{today}, relative \mention{who}, and interrogative \mention{who}. They look different on the surface---one is temporal, one is an operator, one starts a question. But they share a striking distributional property: they all resist determiners.

\ea[*]{\label{ex:det-resist-today}\mention{the today} / \ungram\mention{a today}}
\z
\ea[*]{\label{ex:det-resist-rel}\mention{the person the who called}}
\z
\ea[*]{\label{ex:det-resist-int}\mention{The who called?}}
\z
Why should these three items pattern alike? Traditional accounts would classify them as pronouns or pro-forms and leave it at that. But the classification masks a deeper question: what \textit{makes} them resist determiners?

Return to Wallace's observation about mimicry. A shark and a dolphin look remarkably similar: streamlined bodies, dorsal fins, pectoral flippers. But they are not related. Sharks are cartilaginous fish; dolphins are mammals. They look alike because physics imposes a penalty on drag. Water is dense; to move efficiently through it, you need a certain body shape. The constraint is external, not genealogical. Sharks and dolphins are \textit{convergently evolved}: they arrived at the same phenotype through different ancestral paths because they face the same environmental pressure.

Now consider the three \enquote{pronouns.} They resist determiners for different reasons:

\begin{itemize}
\item \textbf{Deictics} (\mention{today}, \mention{here}, \mention{she}): These are \textit{indexicals}. Their reference is fixed by context---the speaker, the time, the place of utterance. A determiner would be redundant: you don't need \mention{the} to pick out a referent when the deictic anchor already does the job. The saturation is contextual, and contextual saturation makes the determiner slot empty. The proper function (Millikan's term) is to anchor reference to demonstrative space.

\item \textbf{Anaphors} (relative \mention{who}, \mention{which}): These are \textit{bound variables}. Their reference depends on an antecedent in the discourse; the relative clause restricts the set. A determiner would violate the dependency: you can't simultaneously restrict by antecedent and by article. The saturation is structural, and structural saturation blocks the determiner. The proper function is to create a bound-variable dependency.

\item \textbf{Interrogatives} (\mention{who?}, \mention{what?}): These are \textit{variables over alternatives}. They don't refer to a single entity; they range over a set of candidates. A determiner would impose external restriction on what is already a restrictor. This is why \mention{the who} sounds wrong: not because it's redundant (as with deictics), but because you're trying to restrict a restrictor. The proper function is to delineate alternatives.
\end{itemize}

Three different functional mechanisms; one shared distributional property. The categories \textit{look} alike because they face the same grammatical pressure: referential saturation makes an overt determiner unnecessary or incoherent. But the saturation is achieved by different routes---contextual, variable-bound, alternatives-based. The surface unity is real; the underlying mechanism is \textit{braided}.

\begin{table}[htbp]
\centering
\caption{Saturation routes for determiner resistance}
\label{tab:11:saturation}
\begin{tabular}{llll}
\toprule
Category & Analogy & Saturation route & Proper function \\
\midrule
Deixis (\mention{today}) & Shark & Context & Anchor to demonstrative space \\
Anaphor (rel. \mention{who}) & Dolphin & Bound variable & Bound-variable dependency \\
Interrogative (\mention{who?}) & Ichthyosaur & Alternatives & Restrict quantifier domain \\
\bottomrule
\end{tabular}
\end{table}

This is convergent evolution in grammar. Sharks, dolphins, and ichthyosaurs (extinct marine reptiles) all evolved streamlined bodies---three lineages, one hydrodynamic optimum. Deictics, anaphors, and interrogatives all resist determiners---three functional routes, one distributional outcome. Calling them all \enquote{pronouns} is like calling sharks, dolphins, and ichthyosaurs all \enquote{fish} because they swim. It captures the phenotype but misses the ancestry.

Why does this matter? Because category stability depends on mechanism. If \mention{pronoun} were a unified \abbr{HPC} kind, we would expect perturbation in one member to propagate to the others. But it doesn't. If children stopped learning interrogative \mention{who}, deictic \mention{she} would be unaffected. The properties don't reinforce each other crossing the functional boundaries. The convergence is external, imposed by the shared pressure of referential saturation, not internal, maintained by a single homeostatic core.

Ruth Millikan's proper-function framework \citeyearpar{millikan1984} makes the distinction sharp. A proper function is what a form was selected for doing---not what it happens to do, but what it \textit{does in order to have been transmitted}. If determiner resistance arises from three different proper functions, then we have three different category-maintaining regimes overlapping on one distributional property. The unity is a scar of selection, not a structural essence.

The \textit{grammar} sees determiners as blocked; the \textit{cause} differs. This dissociation is the signature of braided mechanisms.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{The acquisition twist}
\label{sec:11:acquisition}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

If braided mechanisms are real, acquisition data should show the strands before the braid.

Michael Tomasello's usage-based research \citeyearpar{tomasello2003} suggests exactly this. Children don't learn \enquote{pronoun} as a unified category. They learn \mention{I} as part of the deictic system, \mention{what} as part of the interrogative frame, and relative \mention{who} as part of specific constructions like \mention{the man who...}. The learning paths are independent. The cross-strand generalisation---the recognition that all three resist determiners---comes later, if it comes at all.

Consider the acquisition of \mention{today}. Children hear it in highly formulaic contexts: \mention{What did you do today?}, \mention{Today we're going to the park.} They don't need to know it's a \enquote{pronoun}; they need to know it fills a temporal slot. The determiner resistance is implicit in the input: no child ever hears \ungram\mention{the today}. The constraint is absorbed incidentally, not extracted from a rule.

Now compare interrogative \mention{who}. Children learn it as part of the question-forming construction: \mention{Who ate the cake?}, \mention{Who is that?} The \mention{wh}-word is locked into the sentence-initial position; the determiner slot is irrelevant. Again, the absence of \ungram\mention{the who} is absorbed through negative evidence---through never hearing the ungrammatical form---not through learning a general principle about pro-forms.

What about overgeneralisation errors? If children extract a unified \mention{pronoun} category, we'd expect cross-strand errors: \ungram\mention{the who} by analogy with \mention{the man}, or \ungram\mention{a today} by analogy with \mention{a day}. Such errors are vanishingly rare. Ben Ambridge's entrenchment research \citeyearpar{ambridge2019} shows that children are sensitive to what \textit{hasn't} been heard: pre-emption is a statistical learning mechanism. If \mention{the today} never occurs, and \mention{today} occurs frequently, the absence itself is informative. But the pre-emption operates locally, within the deictic paradigm or within the interrogative paradigm. There is no evidence for cross-strand transfer.

This is the prediction for braided categories. Learn the strands independently; let the surface convergence emerge from shared environmental pressure. If someone asks: \enquote{When do children learn that pronouns resist determiners?}---the answer is that they probably never learn it \textit{as a generalization}. They learn that \mention{she} resists determiners, that \mention{who} resists determiners, that \mention{today} resists determiners. The unifying pattern is a linguist's abstraction, not a child's schema.

Simon Kirby's iterated-learning framework \citeyearpar{kirby2015} adds a transmission-level prediction. If the braid is loose---if the strands don't reinforce each other during transmission---then braided categories should show greater diachronic instability than unified categories. Languages may fragment the pronoun class differently, depending on which strand happens to dominate the speakers' representation. English bundles deixis, anaphor, and interrogative into a single morphological paradigm (\mention{who/whom/whose}, \mention{which}); some languages separate them. The \abbr{HPC} framework predicts this variability: braided categories have multiple stable equilibria, depending on which mechanisms dominate transmission.

The adult intuition that \enquote{pronouns} form a coherent class may itself be an illusion. The distributional overlap is real, but the underlying architecture is multiple. What adults experience as category unity is convergence without ancestry---Wallace's mimicry again.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{Worked example: focus modifiers and fused relatives}
\label{sec:11:worked-example}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

The mechanism-braiding analysis makes concrete predictions. If deixis, anaphor, and interrogative are maintained by different regimes, they should behave differently in contexts that probe those mechanisms. Focus modifiers provide the test.

Focus particles like \mention{exactly}, \mention{precisely}, and \mention{just} foreground the constituent they modify. They demand salience; the modified element must be in focus. This is the \term{Backgrounded Constituent Infelicity} (BCI) principle identified by Cuneo and Goldberg \citeyearpar{cuneogoldberg2023}: backgrounded constituents resist foregrounding operations.

Now compare interrogative \mention{who} with relative \mention{who}:

\ea[]{\label{ex:focus-int}\mention{Exactly who called?}}
\z
\ea[*]{\label{ex:focus-rel}\mention{the person exactly who called}}
\z
Interrogative \mention{who} accepts the focus modifier; relative \mention{who} rejects it. Why?

The mechanisms differ. Interrogative \mention{who} is inherently foregrounded: it introduces a question, anchors focus, and demands an answer. Focus modification is compatible---even expected. But relative \mention{who} is backgrounded: it restricts an antecedent, contributes old information, and typically appears in non-focal position. Adding \mention{exactly} tries to foreground a constituent whose job is to stay in the background. The mechanisms collide; the sentence fails.

This is the fingerprint of braided categories. If interrogative and relative \mention{who} were maintained by the same regime, they should behave identically under focus modification. They don't. The surface identity---both spelled \mention{who}, both resisting determiners---masks functional divergence. The category \mention{\mention{wh}-word} is a cover term for at least two distinct mechanisms.

The pattern extends. Fused relatives (\mention{whoever calls}, \mention{what you need}) occupy a middle position: they introduce definite reference without an overt antecedent.

\ea[]{\label{ex:fused}\mention{I'll help whoever needs it.}}
\z
\ea[]{\label{ex:fused-focus}\mention{?I'll help exactly whoever needs it.}}
\z
The focus-modified fused relative is marginal---better than restricting relative, worse than interrogative. This intermediate status makes sense if fused relatives combine features of both: they introduce a referent (like interrogatives) but presuppose its recoverability (like relatives). The focus-compatibility reflects the mechanism mix.

Ongoing experimental work may sharpen these predictions. If the BCI principle holds, then precision modifiers should track the foregrounding profile of the construction, not the morphological shape of the \mention{wh}-word.\footnote{Acceptability judgment studies testing these predictions are in preparation.} That is what mechanism-braiding predicts: same surface form, different syntactic license, because the mechanisms diverge.

%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
\section{Looking forward}
\label{sec:11:summary}
%--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --

We have dissected the dictionary list. What we found was not a single kind of unity but several.

\textbf{Adverbs} are a fat category: no unified proper function, no homeostatic reinforcement, no principled clustering. They persist as a label, not a kind. The wastebasket has excellent storage capacity, but the items inside share only a negative property: they are not something else.

\textbf{Nouns and verbs} are tight \abbr{HPC} kinds: robust cross-linguistic presence, converging mechanisms at cognitive, discourse, acquisition, and transmission scales. They are the skeleton---the load-bearing architecture without which a language can't function.

\textbf{Adjectives} are thinner \abbr{HPC} kinds: weaker mechanisms, variable cross-linguistic presence, but genuine clustering within languages that have them. They are plumage---sometimes spectacular, sometimes absent, never essential.

\textbf{Pronouns} are braided categories: multiple proper functions converging on one distributional profile. The shark, the dolphin, and the ichthyosaur all resist determiners---but for different reasons. The category name captures the surface; the mechanisms are plural.

This taxonomy is not exhaustive. Determiners, prepositions, and conjunctions have their own stories, their own mechanism profiles, their own degrees of homeostatic coherence. What the present analysis offers is a method: ask not \enquote{What is the definition of category X?} but \enquote{What maintains category X?} The answers differ by category, and the differences reveal the architecture.

One final refinement from Chapter~\ref{ch:projectibility}: \textit{field-relative projectibility}. Different subfields may have different right-sized categories for the same extension. Morphology cares about lexical category differently than syntax: \mention{cattle} is morphologically singular but syntactically plural. Typology cares differently than single-language grammar: Haspelmath's \enquote{comparative concepts} are projectible across languages, language-particular categories are projectible within. The \enquote{right-sized category} depends on the questions you're asking.

This explains why debates about lexical category boundaries persist. Are adjectives a subclass of nouns? Are adverbs a subclass of adjectives? The questions presuppose that category boundaries are fixed. The \abbr{HPC} framework says: fixed relative to what? Projectibility for morphological purposes may differ from projectibility for semantic purposes. The category is real, but its boundaries are indexed to analytical purpose.

We have moved from the dictionary's tidy list to the anatomist's table. The categories are not boxes into which words are sorted; they are standing waves maintained by mechanisms. Some waves are stable; others are braided; others are phantoms. Knowing the difference is the beginning of understanding lexical categories.
