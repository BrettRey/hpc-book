\chapter{How This Book Was Written}
\label{app:how-written}

There is scarce a sentence in this book that I composed in the usual way.

What that sentence means depends on what you take the usual way to be. If you imagine an author alone at a desk, pulling sentences from some internal reservoir of language and setting them down one after another until a chapter emerges, then yes: almost nothing here was written that way. But if the usual way includes reading, thinking, talking to colleagues, drafting, revising, and revising again~-- then perhaps the process wasn't so unusual after all. The difference is that several of my most important colleagues were large language models.

\section*{The Workflow}

My primary writing environment was Google Antigravity, an agentic system powered by Claude Sonnet 4.5 and Gemini 3. These models weren't external tools but the intelligence driving the environment itself. They handled the implementation tasks~-- generating code, manipulating files, formatting documents~-- directly, executing mechanical work that would otherwise have consumed hours of my attention.

But the intellectual work~-- the development of arguments, the refinement of theoretical positions, the search for the right framing~-- happened primarily in conversation with Claude Opus 4.5 \autocite{reynolds2025supplementary}. Sometimes I arrived with a half-formed intuition that Opus helped me articulate; sometimes I arrived with a developed position that Opus helped me stress-test. Opus would surface relevant literature, find where reasoning had gaps, identify where prose had gone soft. I would push back when Opus was overconfident or miscalibrated; Opus would adjust. The collaboration was genuine and bidirectional: not one mind doing the work while the other transcribed, but two systems~-- different in kind, overlapping in function~-- thinking more clearly together than either would have alone.

ChatGPT 5.1 served as the primary outside critic. Where Opus helped develop ideas, ChatGPT's role was adversarial: to find the holes, to push back, to ask what would falsify the claims I was making. I also consulted the newest versions of Grok and Kimi, each of which brought different sensibilities to the work. A kind of editorial board, except that I could convene them at 5:30 a.m. and they never complained about the length of my drafts. But the value was more than convenience. At Humber, I have wonderful colleagues, but no linguistics department~-- no one down the hall who happens to be thinking about the metaphysics of grammatical categories and has an hour to spare. Sending work to peers elsewhere means waiting weeks or months for feedback that, given their own full lives, is necessarily brief. The models offered what human colleagues couldn't: immediate, iterative, tireless engagement. They allowed me to have the back-and-forth of a seminar room in the solitude of my early mornings.

\section*{What the Models Did}

The models helped with structure. When I had a paper that had languished for eight years because I couldn't find the right organization, I fed it to one model for analysis and another for restructuring. The ideas were mine; the door to let them through was theirs.

The models helped with prose. I would ask for long sentences with participial phrases when the rhythm grew choppy, for chiasmus when I wanted a formulation to stick, for alternatives when a metaphor wasn't quite working. They understood that family portraits versus passport photos captured something about Wittgensteinian resemblance that rough guides and gaps didn't.

The models helped with rigour. I required explicit probability estimates for uncertain claims, pre-committed falsification criteria for theoretical predictions, and verification of every citation. When they hallucinated~-- and they did hallucinate~-- I caught it. That is the division of labour: they generate rapidly; I validate carefully.

The models even helped with fairness. I asked whether my critiques of essentialism and prototype theory followed Rapoport's Rules: express the opponent's position clearly, list points of agreement, say what you have learned from them, and only then criticize. The models could tell me when I was being uncharitable in ways I hadn't noticed.

\section*{What the Models Did Not Do}

The models didn't do the empirical work. The corpus frequencies in these chapters came from my own queries to COCA and GloWbE, my own coding decisions, my own verification that modifier uses had been properly subtracted from raw counts. The models can query corpora, but they can't yet be trusted to do so reliably for publishable research.

The models didn't originate the ideas. The claim that grammatical categories are homeostatic property clusters maintained by bidirectional inference~-- that is mine, for better or worse. The models helped me express it, test it, refine it. But they didn't hand it to me.

The models didn't provide ground truth. When Opus mischaracterized a source or conflated category with function~-- a cardinal sin in the framework I work within~-- I corrected it. My decades of experience with \textit{CGEL} and the broader linguistic literature provided the standard against which the models' outputs were measured. A novice using these same tools would produce confidently wrong material. The expert's role is to know what to check, what to trust, and when to override.

\section*{The Ethics of Acknowledgment}

Is this my book? Yes. The theoretical framework is mine. The empirical claims are mine to defend. The errors~-- and there will be errors~-- are mine to correct. I take full responsibility for every claim in these pages.

But it would be dishonest to pretend that I wrote it alone, in the way that authors of earlier generations wrote their books alone. I had collaborators who don't appear in the author line, who can't be thanked in the acknowledgments in quite the usual way, who won't read these words and feel recognized. This appendix is my attempt at recognition nonetheless.

The technology will change. By the time you read this, the specific models I named may already seem dated~-- quaint artifacts of the mid-2020s, like citing a particular version of Microsoft Word. What won't change, I suspect, is the basic division of labour: human judgment for what matters, machine assistance for getting it said. The usual way of writing books is already something different from what it was. This is how I wrote this one.
