\section{Prototype theory examined}

The prototype tradition began as a rebellion against definitions.

In the early 1970s, the psychologist Eleanor Rosch ran a series of experiments that should have been impossible on the classical view. She asked subjects to rate how good an example each item was of everyday categories: \textit{bird}, \textit{fruit}, \textit{furniture}, \textit{vehicle}. If categories were defined by necessary and sufficient conditions, the question would be meaningless. A robin either is or isn't a bird; there's no sense in which it could be a better bird than a penguin.

But subjects had no trouble answering. They rated robins as better birds than penguins, apples as better fruit than olives, chairs as better furniture than rugs. The ratings were consistent across subjects and stable across time. People had robust intuitions about category structure that the classical theory said they shouldn't have.

Rosch's interpretation: categories aren't defined by conditions. They're organised around prototypes, central members that best exemplify the category. Other members are included by similarity to the prototype, with membership grading off toward the periphery. A robin is a better bird than a penguin because a robin is closer to the prototype; a penguin is still a bird, but a marginal one. The boundaries aren't sharp lines but fuzzy gradients.

The idea spread fast. By the 1980s, prototype theory had become a major framework in cognitive psychology, and linguists were importing it wholesale. George Lakoff's \textit{Women, Fire, and Dangerous Things} (1987) argued that prototype structure was fundamental to human cognition, not a quirk of folk categories but the way concepts work. John Taylor's \textit{Linguistic Categorization} (1989, with subsequent editions) applied the framework systematically to grammatical categories. The cognitive linguistics movement, associated with Lakoff, Ronald Langacker, and others, built an entire research programme around the idea that linguistic categories are prototype-structured, gradient, and grounded in embodied experience.

The appeal was obvious. Here, finally, was a framework that took the evidence seriously. The messy cases that essentialism swept under the rug (the \textit{fun}s and \textit{near}s and \textit{otherwise}s) became data rather than noise. If category membership is gradient, then words can be more or less noun-like, more or less verbal, more or less adverbial. The boundaries don't have to be sharp because the theory doesn't predict sharp boundaries. The evidence that embarrassed essentialism confirmed prototype theory.

\subsection*{The linguistic applications went deep}

Consider parts of speech. The essentialist says: a word is a noun or it isn't. The prototype theorist says: \textit{nounhood} is a cluster of properties (reference to things, inflection for number, occurrence in certain syntactic frames) and words exhibit these properties to varying degrees. A word like \textit{dog} exhibits all of them; it's a prototypical noun. A word like \textit{fun} exhibits some but not others; it's a marginal noun, or a noun-becoming-adjective, or a word in the gradient space between categories. The labels become approximations rather than verdicts.

Consider syntactic constructions. The essentialist says: a sentence is grammatical or it isn't. The prototype theorist says: constructions have central instances and extended instances, with acceptability shading off toward the margins. \textit{The dog bit the man} is a prototypical transitive; \textit{The bed slept two people} is an extended transitive, coerced by analogy to the prototype; \textit{The stone kicked the ball} is further out still, requiring more contextual support to be acceptable. Grammaticality becomes a gradient, not a boundary.

Consider meaning. The essentialist says: a word has a definition, a set of conditions that determine what it applies to. The prototype theorist says: word meanings are organised around exemplars, with extension to new cases governed by similarity rather than rule. \textit{Bird} doesn't mean \enquote{feathered bipedal vertebrate capable of flight}; it means something like \enquote{thing similar to robins, sparrows, eagles.} Penguins count because they're similar enough; bats don't because they're not, despite meeting some of the featural criteria.

This framework captured something real. The gradient judgments Rosch documented are genuine. Speakers do have intuitions about better and worse examples. Categories do have internal structure. The essentialist picture (clean definitions, sharp boundaries, binary membership) was empirically false, and prototype theory said so clearly.

\subsection*{But there's a cost}

Prototype theory tells you that categories have fuzzy boundaries. It doesn't tell you why those boundaries are \textit{there} rather than \textit{elsewhere}. It tells you that peripheral members exist. It doesn't tell you why the periphery has the structure it has: why \textit{fun} is becoming adjective-like in one specific way and not another, why \textit{cattle} has exactly the peculiar profile it has, why \textit{otherwise} straddles exactly those categories and not others.

Return to \textit{cattle}. The prototype theorist can say: \textit{cattle} is a less prototypical noun than \textit{dog}. It lacks the singular–plural contrast that prototypical nouns have. It takes plural agreement but resists \textit{a} and \textit{one}. Fine, this describes its distance from the prototype. But if category membership is just similarity to a prototype, then nothing in that story explains why exactly this configuration appears rather than countless other logically possible ones. A word could be noun-like in its agreement but verb-like in its argument structure and adjective-like in its modification patterns. The space of possible non-prototypical members is vast. But actual non-prototypical members cluster in predictable ways. \textit{Cattle} isn't random noise around the noun prototype. It's a stable configuration that has persisted for centuries.

The stability problem is general. If categories are gradient similarity structures, they should drift. Each generation learns from slightly different data. Each speaker has slightly different exemplars in memory. Small perturbations should accumulate. Over time, categories should dissolve into chaos, or at least into unrecognisable configurations. But they don't. The periphery of \textit{noun} in English today looks broadly like the periphery of \textit{noun} a hundred years ago. Marginal members stay marginal. The gradient structure holds still.

Why?

Prototype theory, as it's usually deployed in linguistics, has no answer. Taylor's \textit{Linguistic Categorization}, perhaps the most influential application of the framework to grammar, describes prototype effects in detail but remains agnostic about what maintains them. It registers that categories have centres and edges. It doesn't say what keeps the edges from eroding.

\subsection*{An analogy}

Imagine mapping the distribution of a species across a landscape. You find that the species is densest in certain habitats and thins out toward others. You could describe this as a prototype structure: prototypical members live in the core habitat; peripheral members live at the margins. The description would be accurate.

But it would miss the explanation. The species is distributed that way because of ecological mechanisms: resource availability, predation pressure, climate tolerance. The distribution isn't a brute fact about similarity to a prototype. It's the outcome of processes that concentrate the population in some places and thin it in others. Change the mechanisms (introduce a new predator, shift the climate), and the distribution shifts predictably. If you want to know why the distribution has the shape it has, you need to identify the mechanisms. If you want to predict how the distribution will change, you need to model them.

Prototype theory, applied to language, is like the distributional description without the ecology. It captures the shape. It misses the dynamics.

Later work in the tradition does better. Exemplar models in psychology and usage-based approaches in linguistics invoke mechanisms explicitly. Frequency of exposure strengthens category membership. Similarity to stored exemplars determines extension to new cases. Analogy drives productivity. Entrenchment stabilises patterns. This is progress, the beginning of a mechanistic account. But it's scattered across the literature, rarely made central, and often in tension with the core prototype metaphor. Bolting mechanisms onto a framework that doesn't require them is different from building on mechanisms from the start.

\subsection*{The deeper issue}

Prototype theory, despite its rebellion against definitions, inherits a key assumption from the tradition it rejected: that categories are primarily synchronic structures.

The essentialist says: categories are defined by conditions. The prototype theorist says: categories are organised around exemplars. Both treat the category as something you can describe by examining its current state. Neither asks what maintains the category, what keeps it from collapsing, what generates its particular structure rather than some other structure.

This is a question about mechanisms. Not \enquote{what do the members of this category have in common?} but \enquote{what processes cause these properties to cluster and stay clustered?} Not \enquote{where is the boundary?} but \enquote{why is there a boundary there at all, and why does it persist?}

Prototype theory was right that essentialism failed. It was right that categories have gradient structure, fuzzy boundaries, better and worse members. It was wrong to treat these facts as self-explanatory, as if documenting the gradience were the same as understanding it. On the view I'll defend, prototype effects don't disappear. They become shadows cast by deeper causal structure.

\subsection*{What success would look like}

The failure of both traditions points toward what an adequate account would need to provide.

It would need to explain why categories have the structure they have: why \textit{cattle} has exactly that profile, why \textit{otherwise} straddles exactly those boundaries, why the adjective–adverb border is chronically unstable while the noun–verb border is relatively firm.

It would need to explain why categories persist: why the gradience doesn't dissolve into noise, why marginal members stay marginal, why speakers across generations converge on roughly the same category structure despite learning from different data.

It would need to make predictions: not just about which items are central and which are peripheral, but about how categories will respond to perturbation, where new items will land, what patterns of variation and change are possible and which are ruled out.

And it would need to do all this without retreating to essentialism, without positing hidden definitions that secretly do the work. The gradience is real. The stability is real. The account must explain both.

This is a tall order. But there's a framework that meets it, one developed to solve a structurally identical problem in a different domain. That framework treats categories not as defined types or similarity clusters but as populations maintained by causal processes. It's called the homeostatic property cluster view (homeostatic meaning self-stabilising), and it's the subject of the next chapter.
