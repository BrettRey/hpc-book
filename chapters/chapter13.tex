\chapter{The category zipper}
\label{ch:the-category-zipper}

\epigraph{If you have two complementary strands of DNA, they zip up. That's what they do.}{— Sri Kosuri, quoted in \textit{Harvard Gazette} (2019)}

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{When errors go wrong differently}
\label{sec:13:hook}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

You know the moment a zipper catches. The slider finds the teeth, they interlock, and the two sides move as one. You don't think about it. That's the point~-- when the coupling is tight, the mechanism disappears.

You also know the moment it doesn't catch. The slider moves but the teeth won't seat. Or it catches partway and then jams, leaving a gap where the fabric bulges through. The fix depends on where the failure is: at the bottom, you have to reseat the whole thing; in the middle, you can sometimes work it free; at the top, you're just short of done and the last few teeth won't close.

Language comprehension has all of these failure modes.

When you mishear a word, the error is a clean \term{slip}. You hear \mention{grape} as \mention{great}, not as a smear of sound. The perceptual system delivers discrete candidates even when the input is degraded. The mistake stays inside the system: one phoneme for another, one word for another. The zipper caught; it just caught on the wrong tooth.

When you misparse a sentence, the failure is a \term{jam}. You can get every word right and still get the structure wrong. \mention{The horse raced past the barn fell} is acoustically clear; the problem is that your parser zipped up the wrong configuration and only discovered the problem at \mention{fell}. The teeth were seating fine until they weren't.

And when you miss an implicature, the zipper looks closed but the fabric is \term{mis-tracked} underneath. \mention{Some students passed} registers as good news when the speaker meant it as bad. Every tooth is in place. The tracking is off.

\subsection{From failure modes to coupling regimes}

These three failure types diagnose three coupling regimes~-- and each regime licenses different diagnostic evidence.

\begin{enumerate}
    \item \textbf{Slip} (clean substitution) signals \term{transparent coupling}. Form and value are so tightly bound that errors stay within the contrast system. Perturbations shift category boundaries predictably where cues degrade; they don't produce extragrammatical gibberish. \emph{Diagnostic evidence}: perceptual confusion matrices cluster by featural similarity; mergers occur where acoustic cues weaken.

    \item \textbf{Jam} (late crash after locally coherent assembly) signals \term{architectural coupling}. Form templates pair with interpretive templates, but hidden commitments accumulate as parsing proceeds. The zipper catches partway, then fails when downstream requirements conflict. \emph{Diagnostic evidence}: garden-path signatures, revision points, cue-competition effects that show up in reading times or eye movements.

    \item \textbf{Mis-tracking} (surface OK, downstream mismatch) signals \term{loose coupling}. Multiple sources~-- lexical, constructional, pragmatic~-- contribute to interpretation, and they can align or misalign without local ill-formedness. \emph{Diagnostic evidence}: implicature failures, pragmatic infelicity in discourse, mismatches between what was said and what was understood that emerge only in interaction.
\end{enumerate}

The coupling regime reflects stabilizer weighting. Transparent coupling dominates where physical and perceptual constraints lock form to contrastive identity (phonemes). Architectural coupling dominates where conventional form--value pairings are compositionally assembled (constructions). Loose coupling dominates where contextual inference supplements or overrides encoded content (discourse). The zipper metaphor is a diagnostic instrument, not just an illustration: error shape tells you where to look for the stabilizers.

\subsection{What \enquote{value} means}

To say what's being coupled, we need a term that works across grains. We've already met the term \term{value}~-- what a unit counts as in the system when deployed, its contrastive role, recoverable by competent users. Here it does heavy lifting.

\term{Value} in this book is not evaluative worth, not teleological purpose, not \enquote{meaning} in the undifferentiated everyday sense. It is relational rather than intrinsic: a unit's value is constituted by what it contrasts with and what inferences it licenses. For phonemes, value is contrastive identity: /\ipa{k}/ counts as not-/\ipa{g}/, not-/\ipa{t}/, not-/\ipa{p}/, and that exhausts its contribution. For morphemes, value is conventional pairing: the form \mention{-ed} is associated with pastness by agreement, not resemblance. For constructions, value is interpretive template: a form configuration paired with a meaning configuration, compositionally and holistically.

The zipper, then, has form on one track and value on the other. What changes across grains is what kind of value, and how tightly form is coupled to it. This is why linguistic categories so often appear as \term{crosscutting kinds}: form clusters and value clusters may be maintained by different mechanisms, and the zipper can slip at any level.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Two diagnostics, asymmetrically applied}
\label{sec:13:diagnostics}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

How do we tell whether a category is a genuine kind~-- something that will repay induction~-- or just a convenient label? This chapter applies two diagnostics. Does the category \emph{project}: can patterns learned from one sample predict another? And is it \emph{maintained}: can we identify mechanisms that stabilize the cluster?

Boyd's homeostatic property-cluster framework treats projectibility as following from homeostatic maintenance: if mechanisms hold a cluster together, the cluster will support induction. For methodological clarity, I revise this relationship, treating projectibility and homeostasis as independent criteria that must both be satisfied.

Projectibility is tested directly via out-of-sample prediction: can patterns learned from one corpus identify categories in another? Homeostasis is inferred: can we name stabilizers and find their predicted signatures in the data? Both diagnostics have to pass for kindhood to be warranted. Appendix~\ref{app:diagnostics} details the operationalization, including thresholds, failure modes, and falsification conditions.

The case studies that follow apply these diagnostics to three positive cases~-- phonemes, morphemes, constructions~-- and three negative cases~-- academic register, Indo-European, polysynthetic. The positive cases show the framework scaling. The negative cases show it has teeth.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Transparent coupling: phonemes}
\label{sec:13:phonemes}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

The phoneme tier is the cleanest place to test the claim that linguistic categories are HPC kinds. Inventories are comparable across languages, there's independent theory about plausible stabilizers, and open resources allow fully reproducible analysis.

The cluster properties are familiar: acoustic cues (formant distributions, voice-onset time), production routines (reliable articulatory gestures), lexical contrast (minimal pairs making the distinction communicatively consequential), and perceptual categorization (listeners mapping continuous input onto discrete categories). These travel together without being definitionally linked.

What maintains the clustering? Four stabilizer types. First, quantal regions: \textcite{stevens1989} showed that the articulatory-to-acoustic mapping is non-linear, with certain configurations producing stable outputs across a range of variation~-- natural \enquote{parking spots} that constrain what phoneme contrasts are \emph{possible}. Second, dispersion pressure: \textcite{lindblom1990} argued that vowel inventories disperse in acoustic space to maximize discriminability, shaping which of the possible phonemes a language \emph{selects}. Third, perceptual tuning: \textcite{kuhl1992} demonstrated that infant perception is warped by early exposure, with category prototypes acting as perceptual magnets that tune the individual speaker to the community standard. Fourth, community norms: social transmission across generations stabilizes inventories through the mechanisms that cultural-tool accounts emphasize \parencite{ekstrom2025}.

Evidence comes from PHOIBLE 2.0 \parencite{moran2019phoible}, a database of phoneme inventories for roughly 2,700 languages. Two patterns satisfy the diagnostics. Plotting kernel-density ridgelines of total inventory sizes by family reveals a \emph{stability band}: medians cluster between 20 and 50 segments across unrelated families, with thin tails beyond. This isn't an artifact of pooling; it's cross-family regularity enabling inventory-level projection. Meanwhile, the vowel /y/~-- a front rounded vowel requiring precise articulatory coordination~-- shows a \emph{scaling curve}: a logistic model predicting /y/-presence from vowel-inventory size (cross-validated, grouped by family) achieves ROC-AUC $\approx 0.70$. Marked segments lacking quantal robustness appear mainly in larger systems where there's acoustic room. This is exactly what the stabilizer story predicts.

The \mention{pin}/\mention{pen} merger provides a stress test. In much of the American South and parts of the Midland, /\ipa{ɪ}/ and /\ipa{ɛ}/ have merged before nasal consonants \parencite{labov2006}. Speakers produce the same vowel in \mention{pin} and \mention{pen}; they can't reliably distinguish the two words by ear. The conditioning environment is revealing: before nasals, the vowels are subject to nasalization, which smears the formant cues. In exactly the environment where acoustic cues are least reliable, the contrast collapses. This is homeostasis failing in a predictable way~-- not random noise, but a consequence of perturbing the stabilizers.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Opaque coupling: words}
\label{sec:13:words}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

At the phoneme level, form directly realizes contrastive value. At the word level, form and value come apart. The form \mention{went} encodes pastness, but you can't read the value off the form~-- the connection is brute memory. This is \term{opaque coupling}.

\textcite{miller2021} develops an HPC stance at the level of particular lexemes~-- \mention{dog}, \mention{run}, \mention{egregious}~-- rejecting essence-based individuation in favour of mechanism-indexed clusters that are historically delimited and population-relative. The lexeme \mention{dog} maintains its identity not through a platonic essence but because spelling conventions, pronunciation norms, semantic associations, and syntactic patterns travel together, stabilized by orthographic standardization (educational institutions, publishing practices), frequency entrenchment (repetition in memory automating retrieval; \citealt{bybee2001}), editorial norms (copy-editing workflows flagging nonstandard usage), and register licensing (genre conventions sanctioning certain words in certain contexts).

The question is whether words can change semantically and still remain HPC kinds. The HistWords COHA embeddings \parencite{hamilton2016} provide decade-binned distributional representations for English words over the 20th century. High-drift adjectives (top decile of average cosine displacement, with documented drift terms like \mention{nice}, \mention{sick}, \mention{gay}, \mention{awful} forced in) are compared to frequency-matched controls with minimal drift. Some drift adjectives retain organized neighbourhoods even as their centres move: for \mention{nice}, nearest neighbours shift from \{pretty, lovely, pleasant\} in the 1900s to \{cute, wonderful, really\} by the 2000s; for \mention{sick}, from \{ill, tired, hungry\} to \{hurt, drunk, upset\}. A prototype classifier trained on early decades (1900--1940) and tested on later decades (1950--2000) recovers word identity well above baseline (macro-F1 = 0.84 vs.\ 0.03). Combined with a cohesion cutoff, only a subset of high-drift adjectives satisfies both criteria. The framework tells us to withhold kindhood for those lexeme--time slices rather than forcing a positive verdict. For the subset that passes, past usage fixes expectations that carry forward~-- exactly what the HPC picture predicts.

The \mention{go}--\mention{went} pattern provides a stress test. If form--value pairings are maintained by frequency and analogy, high-frequency irregulars should resist regularization; low-frequency irregulars should be vulnerable. \textcite{bybee2001} documents exactly this. High-frequency irregulars (\mention{go}--\mention{went}, \mention{have}--\mention{had}) show no regularization pressure. Mid-frequency irregulars (\mention{weave}--\mention{wove}) show variable forms. Low-frequency irregulars (\mention{cleave}--\mention{clove}) have largely regularized. Frequency protects the arbitrary pairing; analogy regularizes the unprotected. The two stabilizers interact in predictable ways.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Architectural coupling: constructions}
\label{sec:13:constructions}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

Constructions~-- conventionalized pairings of form and meaning that go beyond compositional rules~-- rely on multiple converging cues that speakers recognize as a gestalt. The form--value coupling is \emph{architectural}: built up from components, maintained by use, transmitted through interaction.

Three stabilizer types maintain constructions. Frequency and entrenchment work on millisecond-to-week timescales: each token use strengthens memory traces, increasing production probability, generating more tokens in a self-reinforcing loop \parencite{bybee2001}. Cue redundancy provides robustness: multiple formal features converge on the same interpretation, so if parallelism fails in a rushed email, the anchor string and licensing context still signal the construction. Normative pressure operates on year-to-decade timescales: editorial practices and style guides reinforce the canonical pattern, especially in formal registers.

If the construction tier is to do more than demonstrate feasibility, the diagnostics have to survive contact with heterogeneous constructions. The confirmatory analysis uses a battery of ten constructions spanning four cue regimes, tested across UD English corpora (GUM, EWT, GUMReddit). Eight are treated as positive candidates; two are included as designed brakes cases~-- pooled resultatives (predicted \enquote{too fat}) and \mention{X much?} (predicted register-local)~-- to force the framework to say no when it should. For the \mention{or even} construction, a classifier trained on GUM and tested on EWT achieves PR-AUC of 0.886 (full bundle); dropping parallelism reduces PR-AUC to 0.612. Ablation signatures show parallelism as a dominant stabilizer for scalar-additive constructions. The pooled resultative shows weak cross-corpus transfer and washed-out ablation signatures~-- exactly what the \enquote{too fat} diagnosis predicts. The \mention{X much?} construction falls below prevalence thresholds outside informal registers, confirming register-locality. The implication is deliberately narrow: the construction tier doesn't license a blanket HPC claim. Kindhood is earned case-by-case.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{The stabilizer-weighting map}
\label{sec:13:map}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

The three cases above~-- phonemes, words, constructions~-- are not a ladder. They are regions in a stabilization space defined by how form couples to value and which stabilizers carry the load. Table~\ref{tab:13:stabilizer-map} summarizes the mapping.

\begin{table}[htbp]
\centering
\caption{Stabilizer-weighting profiles across levels. Each level shows a characteristic coupling regime, error type, and dominant stabilizers.}
\label{tab:13:stabilizer-map}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Level} & \textbf{Coupling} & \textbf{Error type} & \textbf{Dominant stabilizers} \\
\midrule
Phoneme & Transparent & Slip & Quantal regions, dispersion, perceptual magnets \\
Word & Opaque & — & Frequency entrenchment, editorial norms, analogy \\
Construction & Architectural & Jam & Entrenchment, cue redundancy, normative pressure \\
Discourse & Loose & Mis-tracking & Pragmatic inference, common ground, accommodation \\
\bottomrule
\end{tabular}
\end{table}

The stabilizers form a braid, not a single cause. At the phoneme tier, biophysical constraints carve the design space, developmental learning binds cues, sociocultural norms transmit inventories. At the word tier, frequency entrenches forms, editorial standards enforce conventions, usage communities police extensions. At the construction tier, cue redundancy protects against noise, normative pressure corrects deviations, genre licensing regulates distribution. The mechanisms shift in their balance: articulatory constraints weigh heavily for phonemes, frequency and norms for words, cue redundancy and editorial pressure for constructions. But at every tier, multiple forces interact: body, cognition, and society always contribute.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Negative cases: when the framework says no}
\label{sec:13:negative}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

The HPC framework would be toothless if it said yes to everything. Here are three cases where it says no~-- each for a different reason.

\emph{Academic register} has a recognizable flavour: passive constructions, nominalizations, hedges like \mention{it has been argued}. The features cluster; experienced readers identify academic prose instantly. But put the same researcher in front of a grant panel, a blog audience, and a conference poster, and the passives evaporate, the hedges reweight. The bundle doesn't resist perturbation; it dissolves and reconstitutes. The stabilizers~-- genre conventions, disciplinary gatekeeping, editorial norms~-- have high \term{looping intensity}: the category changes because it is classified. This is maintenance by institutional policing, not cognitive binding. It belongs in the same ontological category as \enquote{formal attire}~-- real, consequential, but not projectible in the way phonemes and constructions are.

\emph{Indo-European} is a language family defined by historical descent. The cluster properties~-- cognate vocabulary, shared sound correspondences, similar grammatical patterns~-- are real. But ask what would push English \emph{back toward} Proto-Indo-European. Nothing. There's no homeostatic pressure maintaining Indo-European-ness. English drifts away from PIE continuously; contact with non-IE languages accelerates the drift. Historical kinds are defined by causal continuity with an origin; homeostatic kinds are defined by stabilizers that maintain covariance. Confusing them invites explanatory error.

\emph{Polysynthetic languages} are characterized by high morpheme-to-word ratios, incorporating structures, and complex verb templates. Mohawk, Chukchi, and Ainu are standard examples. But the same stabilizers don't maintain polysynthesis across families. Mohawk (Iroquoian) has noun incorporation for discourse-pragmatic reasons~-- incorporated nouns are non-referential \parencite{mithun1984}. A single Mohawk word like \textit{Washakotya'tawitsherahetkvhta'se} encodes what English requires a full clause for: `he made the thing that one puts on one's body ugly for her'~-- i.e., `he ruined her dress' \parencite[40]{baker1996}. Chukchi (Chukotko-Kamchatkan) has incorporation with different constraints and different discourse functions. The surface similarity~-- complex words~-- masks heterogeneous routes. \enquote{Polysynthetic} is a typological region label, useful for description but not for explanation: it doesn't name a mechanism-maintained kind.

The three cases fail for different reasons~-- reflexive stabilizers (academic register), historical rather than homeostatic maintenance (Indo-European), heterogeneous routes to surface similarity (polysynthetic). The HPC framework distinguishes these failure modes. That's the payoff of explicit diagnostics: you can say \emph{why} something doesn't qualify, not just that it doesn't.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Predictions and disconfirmers}
\label{sec:13:predictions}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

The diagnostics generate falsifiable predictions beyond the case studies. Weakening a stabilizer should reduce cluster covariance before norms re-stabilize; for constructions, downsampling training data to 25\% should degrade PR-AUC substantially if the bundle depends critically on frequency. Just as /y/ appears preferentially in larger vowel inventories, rare constructional variants should concentrate in corpora with larger constructicon repertoires. If a pooled category like \enquote{resultative} is genuinely \enquote{too fat}, stratifying into subtypes should restore projectibility for well-maintained local kinds. These tests operationalize the core claim: linguistic categories qualify as HPCs when they project via identifiable mechanisms.

%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 
\section{Looking forward}
\label{sec:13:forward}
%~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~--  ~-- 

This chapter has argued that the HPC explanatory strategy scales across linguistic levels. Phonemes, words, and constructions can all be homeostatic property clusters maintained by stabilizers. What differs is the coupling regime~-- transparent at the sound level, opaque at the word level, architectural at the construction level~-- and the stabilizer weighting that maintains each regime.

The payoff is twofold. First, predictive grip: the diagnostics force us to say in advance what counts as success and what would change our minds. Success isn't a rhetorical gloss (\enquote{striking regularity}) but concrete measures~-- slopes with uncertainty intervals, mass within bands, cross-corpus areas under curve, ablation deltas.

Second, an ontology with brakes: kinds are discovered through evidence rather than declared by fiat, and they are local equilibria (maintained by specific mechanisms in specific populations) rather than universal essences. That stance blocks overreach. Cross-linguistic umbrellas fail as single kinds because they pool heterogeneous mechanisms, bundling components that don't belong to the same causal whole. Thin proposals and complement classes lack the stabilizer base that projectibility requires. Many historical categories are united merely by descent rather than by active maintenance. And the zipper permits \term{mechanistic drift}: a category can remain historically continuous while its stabilizers shift. In between lie the categories that travel: their properties cohere because mechanisms keep them together. These show a cliquish stability~-- robust enough to support induction, even if perfect instance stability remains elusive.

The zipper metaphor returns for the final turn. Error shape diagnoses coupling: slips reveal transparent coupling; jams reveal architectural coupling; mis-tracking reveals loose coupling. Each error type tells you where the teeth failed to seat and, therefore, where to look for the stabilizers that normally keep them seating.

But one level has special status. Throughout the case studies in Part III~-- countability, definiteness, lexical categories~-- the categories clustered at the morphosyntactic level. That's where form--value coupling is both \emph{tight} and \emph{obligatory}. You can speak without using \mention{let alone}. In English, you can't speak without committing to number, tense, and definiteness.

Morphosyntax is the zone of maximum systematicity: the region of grammar where coupling is enforced, not optional. Chapter~\ref{ch:grammaticality-itself} asks what happens when we take this observation seriously. If grammaticality is what emerges when form--value coupling is obligatory, compositional, and learnable~-- then grammaticality itself is a kind.
