\chapter{The Social Stabilization of Kinds}
\label{ch:social-stabilization}

The previous chapters have treated the \term{stabilizer}---the mechanism that keeps the cluster tight---as an internal property of the speaker. The detector clicks; the coupling holds; the category persists.

But this individualist picture misses the most obvious fact about human language: it is shared. If I equate \term{grammaticality} with a coupling in \emph{my} head, and you equate it with a coupling in \emph{yours}, what guarantee do we have that we are talking about the same thing? If mechanisms are internal, why are categories public?

The answer lies in the messy reality of variation. In traditional formal theory, variation is often treated as noise---an irritating deviation from the pure signal of Competence. In the HPC framework, variation is not noise. It is the signature of a mechanism working at a different scale.

\section{The signal in the noise}
\label{sec:15:signal-in-noise}

Consider the \enquote{double copula} construction, a staple of spontaneous Anglo-American speech:

\ex\label{ex:double-copula-narrative}
\a The thing is is that we need to leave.
\b The problem is is the money.
\z

If you measure this construction against the \enquote{Standard English} cluster---the one enforced by copy-editors and schoolteachers---it looks like an error. It appears to be a stutter, a planning failure, or a chaotic blending of two syntactic frames. Under this lens, it degrades the category of the copula. It is entropy.

But if you measure it in a corpus of spontaneous speech, especially in planning-heavy contexts, it looks like a robust, high-frequency attractor. It has stable properties: it occurs predominantly with \mention{reason}, \mention{problem}, and \mention{thing}; it projects (forms like \mention{The catch is is...} are predictable); and it is maintained by communicative efficiency, signalling a focus structure or a restart.

So is it \enquote{grammatical}?

The question is ill-posed because it treats \enquote{English} as a single, flat population. If you pool all speakers and all contexts into one bucket, the double copula looks like a blurred edge---a 10\% probability event attached to the copula category. But the event isn't random. It is \term{conditioned}. In the context of spontaneous planning, its probability is high and stable. In the context of edited prose, its probability is near zero.

This suggests that the \term{kind} is not \enquote{English sentences}. The kind is \enquote{English sentences in context X}. The social variable is not an external \enquote{influence} on the grammar; it is a parameter of the grammar itself.

\section{The Bolt Factory}
\label{sec:15:bolt-factory}

To understand why this conditioning matters for the metaphysics of categories, we need a statistical metaphor.

Imagine two factories making bolts. Factory A makes 5mm bolts. Factory B makes 10mm bolts. Both factories are highly precise ($SD = 0.1mm$). If you walk into Factory A and measure the output, you see a tight, homeostatic cluster. If you walk into Factory B, you see a similarly tight cluster.

But suppose someone takes the bins from both factories, dumps them into a single pile, and asks you to measure the \enquote{Bolt} category.

You measure the pile. You calculate the mean: 7.5mm. You calculate the standard deviation: massive. You look at the distribution and see a wide, messy bimodal spread. You conclude that \enquote{bolt manufacturing is a high-variance process} and that the \enquote{Bolt} category is loose and ill-defined.

You would be wrong. The process is low-variance; you just failed to condition on the source.

Linguistic variation is a latent mixture problem. When we say \enquote{Subject-Verb Agreement is variable in English} because we see \mention{There's two men} alongside \mention{There are two men}, we are looking at the mixed bin.
Under standard formal conditions ($V_{standard}$), agreement is categorical.
Under casual spoken conditions ($V_{casual}$), \mention{there's} acts as an invariant presentative particle.

Both systems are tight. Both systems are homeostatic. The apparent \enquote{looseness} of the category comes from summing them together.

The \term{unconditioned probability} is the messy sum. The \term{conditioned probability} is the tight coupling. Mechanisms of homeostasis operate at the conditioned level. We align to \emph{the variety}, not the language.

\section{Three mechanisms of social stabilization}
\label{sec:15:three-mechanisms}

If the \enquote{mixed bin} is the wrong place to look for homeostasis, how do speakers un-mix the bin? They don't have labels on the bolts. They have to infer the source.

This inference isn't magic; it relies on three distinct mechanisms of social stabilization. In the technical literature, these often go by the names \term{Dialect}, \term{Register}, and \term{Discourse Community}. In the HPC framework, we can see them for what they are: stabilizer mechanisms that protect the cluster from drift. This mirrors \citet{khalidi2015-three-kinds}'s taxonomy of social kinds, specifically his \enquote{Type 2} kinds which depend on general attitudes for their existence but not on attitudes towards specific instances.

\subsection{Dialect: The factory setting}
\label{sec:15:dialect}

A \term{dialect} is the durable, socially anchored variety that a speaker carries across situations. It represents a baseline parameterisation.

Think of this as the \enquote{Factory Setting}. When you meet a speaker from a specific region or network, you load a set of priors. You assume that their vowel space, their lexical inventory, and their basic morphosyntactic constraints will remain relatively stable across the interaction.

This stabilization is crucial because it allows us to attribute variation to the \emph{person} rather than the \emph{system}. If a speaker consistently says \mention{bag} with a vowel that sounds like \mention{beg}, I don't conclude that the English vowel system has collapsed; I conclude that this speaker has a different parameter setting. The category /\ipa{Ã¦}/ remains stable because I have conditioned on the dialect.

\subsection{Register: The mode switch}
\label{sec:15:register}

A \term{register} is a situational slice of language use. It captures the systematic shift in probabilities driven by context rather than by the speaker's identity.

Think of this as the \enquote{Mode Switch}. We don't change our underlying grammar when we walk into a lecture hall or log onto Twitter; we re-weight the options. Formal writing is a \emph{stance}---a mode where we actively inhibit certain convenient forms (like the double copula or the \mention{get}-passive) and boost others (nominalizations).

The \term{Academic Register} discussed in Chapter 13 is the prime example. It is not a natural dialect acquired in childhood; it is a learned, inhibited stance maintained by gatekeeping mechanisms (editors, reviewers, teachers). It stabilizes the cluster by narrowing the channel. As \citet{pullum2019-normativity} argues, such normative rules are not mere external impositions but constitutive parts of the grammar's social ontology. They say: \enquote{In this room, we only use the nominalized subset.}

\subsection{Discourse Community: The source attribution}
\label{sec:15:community}

Perhaps the most powerful stabilizer is the \term{Discourse Community}. This corresponds to the \enquote{latent mixture component} in the statistical model: a cluster of speakers or sources that we group together.

This acts as the category's \enquote{immune system}. When a new or \enquote{weird} form appears, the community doesn't necessarily widen the category to accommodate it. Instead, we often \emph{partition} the input. We say, \enquote{Oh, that's tech-speak,} or \enquote{That's a Reddit thing.}

By assigning the deviant form to a specific sub-community, we protect the general category from drift. The \enquote{bolt} doesn't ruin our definition of typical bolts because we mentally tag it as \enquote{Factory B}. This source attribution allows English to host massive internal diversity without losing its structural coherence. The clusters stay tight because we keep the bins separate effectively.

Recent work by \citet{floyd2025-pragmatics} provides empirical backing for this specialized tracking. They find that \enquote{Social Conventions}---including the processing of irony, indirect requests, and conversational implicatures---form a distinct cognitive factor. This aligns with \citet{oconnor2021-conventionality}'s information-theoretic measure of conventionality: communities stabilize specific arbitrary choices not because they are optimal, but to solve coordination problems. The \enquote{immune system} polices these arbitrary boundaries to maintain the efficiency of the signalling game.

\section{Indexicality as the inverse function}
\label{sec:15:indexicality}

This framework gives us a rigorous definition of social meaning, or \term{indexicality}.

If \term{grammar} is the function that predicts form given a social context ($P(\text{Form} \mid \text{Social})$), then \term{social meaning} is simply the inverse function: predicting the social context given the form ($P(\text{Social} \mid \text{Form})$).

When you hear \mention{The thing is is...}, your brain runs the inverse calculation. It asks: \enquote{Under which condition is this form probable?} The answer comes back: \enquote{Spontaneous planning.} You index the speaker as being in a specific cognitive state.

When you hear \mention{It is posited that...}, the inverse function points to \enquote{Academic Stance.} You index the speaker as performing a specific social identity.

We are, as Clifford Geertz said, \enquote{meaning-seeking animals}. But as Chapter 13 argued, we seek different kinds of meaning at different levels. The social stabilization of kinds works because we are constantly running this inverse function, attributing every token to a source, a stance, or a setting.

\section{The dunes are real}
\label{sec:15:conclusion}

The Nominalist might look at this conditioned landscape and say: \enquote{See? There are no fixed categories, only shifting social sands. 'English' is a fiction; 'Grammaticality' is just a probability distribution that changes with the wind.}

The Realist replies: \enquote{No. The sand shifts, but the dunes are real.} As \citet{bach2016-social-kinds} argues, social categories like gender---and, we contend, grammar---are \term{natural kinds} even if they are not mind-independent \term{objective types}. Their reality consists in their causal power and their projectibility within the social system.

By acknowledging that categories are parameterised by varieties, we don't make them less real. We make them \emph{more precise}. A biological species is defined relative to an ecosystem. A polar bear is a robust kind in the Arctic; it is a failed kind in the Sahara.

Nominalism was a necessary corrective to essentialist overreach. But it threw out the baby with the bathwater. We can admit that categories are constructed~-- built by history, maintained by interaction, variable at the margins~-- without admitting they are arbitrary. As \citet{oconnor2019-games} demonstrates with evolutionary models of signaling games, stable kinds emerge from the requirements of successful action, even in the absence of pre-existing property clusters. They are \term{maintained kinds}. And because they are maintained by the necessity of coordination, they are real.

A linguistic category is likewise defined relative to a social ecology. The double copula is a robust kind in spontaneous speech; it is an error in the pages of \emph{Science}. To study linguistic kinds without studying social varieties is like studying biology without ecology. You might understand the anatomy, but you will never understand why the animal survives.
