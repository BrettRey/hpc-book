\chapter{What changes}
\label{ch:what-changes}

% TODO: Write chapter content
% NOTE: Chapter 6 (sec:6:what-framework-offers) references this chapter for agent-based modelling
%       as a methodological consequence of the maintenance view. See notes/chapter-feedback-deferred.md
%       for planned ABM content: testing basin dynamics, boundary cases, convergence vs homology, etc.

\section{The status of the framework}

What \emph{kind} of kind is an \term{HPC category}? It is a \term{second-order explanatory kind}: a kind whose members are themselves kinds, unified not by shared first-order properties but by a shared explanatory role and stabilization pattern. Its members are things like \term{species}, \term{chemical elements}, \term{phonemes}, and \term{constructions}~-- categories that support projectible generalizations, are stabilized by multiple partially independent mechanisms, and tolerate property variation without collapse.

What makes \term{HPC category} itself a kind is that these properties cluster reliably across domains. It is not a natural kind in the same sense as \term{gold}, nor a merely stipulative classificatory label, nor a purely philosophical artifact. It is a meta-level homeostatic cluster over explanatory practices.

This recursion is \emph{typed}, not flat. Compare \term{gene} (a kind whose instances are molecular entities) with \term{functional gene} (a kind whose instances are ways of carving interactions for explanation), or \term{model organism} (a kind whose instances are organisms plus institutional practices). None of these collapses because they occupy different explanatory grains. Likewise, \term{noun} is an HPC kind in English; \term{lexical category} is an HPC kind across languages; and \term{HPC category} is an HPC kind across scientific taxonomies.

Crucially, the higher-order kind is not stabilized by the same mechanisms as its members. HPC categories \emph{in the world} are stabilized by causal mechanisms, developmental pathways, and communicative coordination. The \term{HPC category} kind is stabilized by repeated success of explanation, methodological convergence across sciences, robustness under theory change, and the survival of the concept under critical scrutiny (against eliminativism or essentialism). Its homeostasis is epistemic and methodological rather than biological or physical.

This framing distinguishes the theory from a mere framework or model. Frameworks can be swapped without residue; HPC categories resist that. Once the pattern is identified~-- why strict definitions fail, why exceptions cluster~-- we can make reliable predictions about where gradience will appear, where sharp boundaries will re-emerge, and where eliminativist arguments will systematically overreach. That predictive success is exactly what licenses kindhood.

A natural objection is that if \term{HPC category} is itself an HPC kind, the theory is self-validating or circular. This would be true only if HPC theory claimed \emph{a priori} necessity. It does not. It makes a fallible empirical claim about the structure of successful scientific kinds. If HPC categories stopped supporting prediction, coordination, or explanation, the kind would dissolve~-- by its own lights. That is not circularity; it is reflexive risk.
\section{Overlap as principled}
\label{sec:15:overlap}

When physicists calculate the motion of a planet, they face a choice. They can treat the planet as a single coherent object, or as a vast aggregate of $10^{50}$ atoms. For the theory to be consistent, the answer must be the same either way.

Newton worried about this. As \textcite{barandes2024} notes, this mereological consistency constraint~-- the requirement that the laws work equally well for parts and for wholes~-- acts as a theoretical guardrail. It forces the inclusion of Newton's Third Law: for every internal action between particles, there must be an equal and opposite reaction. Without this, the internal forces wouldn't cancel out, and a composite object could accelerate itself just by the interaction of its parts. Mereology constrains physics.

Linguistics has no such guardrail.

Instead, we have a loose federalism. We divide the field into sub-disciplines~-- phonetics, phonology, morphology, syntax, semantics, pragmatics~-- and treat them as distinct territories. We talk about \enquote{interfaces} (the syntax--semantics interface, the phonology--morphology interface) as if they were national borders to be policed rather than contact zones to be mapped. We assume a tree-like structure: a phenomenon belongs to syntax \emph{or} semantics, but ideally not both.

The HPC framework suggests this picture is wrong.

If linguistic categories are homeostatic property clusters, then disciplinary subfields are too. \term{Psycholinguistics}, \term{Construction Grammar}, and \term{Experimental Semantics} are not mutually exclusive boxes. They are bundles of phenomena, methods, and theoretical commitments, stabilized by institutional mechanisms (journals, hiring lines, training pipelines). And crucially, these bundles overlap.

\subsection{Typed parthood}

The mistake is assuming that parthood is a single relation. In standard hierarchies, if $A$ is part of $B$, it's part of $B$ generally. But in scientific practice, parthood is \term{typed}.

A subfield can be part of linguistics in different ways:
\begin{itemize}
    \item \textbf{Phenomenon-part ($\leq_\textsc{phen}$)}: Its domain of inquiry is a subset of language (e.g., phonetics studies speech sounds).
    \item \textbf{Method-part ($\leq_\textsc{meth}$)}: Its tools are a subset of the field's toolkit (e.g., corpus linguistics uses distributional analysis).
    \item \textbf{Theory-part ($\leq_\textsc{thy}$)}: Its explanatory commitments inherit from a broader framework (e.g., Minimalism is a theoretical part of Generative Grammar).
\end{itemize}

Once we distinguish these types, the \enquote{boundary disputes} resolve into structural features.

Take \term{Computational Linguistics}. Is it part of linguistics? Methodologically, yes: it contributes formal and algorithmic tools. Theoretically, often no: its goals (engineering performance) diverge from the core explanatory project (cognitive realism). It is a method-part that is not always a theory-part.

Take \term{Construction Grammar}. It is a theoretical framework ($\leq_\textsc{thy}$) that claims all of morphosyntax as its phenomenon-domain ($\leq_\textsc{phen}$). This puts it in direct competition with Minimalism for the same territory.

Take the \term{syntax--semantics interface}. In the tree view, this is a border. In the typed-parthood view, it is a zone of \term{principled overlap}. Many linguistic phenomena cluster here because the mechanisms are bidirectional. Syntactic structure cues semantic interpretation (comprehension); semantic intent licenses syntactic choice (production). The two systems maintain each other. The overlap is not a messy intermediate zone to be purified; it is the engine of the system.

\subsection{Consequences for practice}

This re-framing has concrete consequences for how we work.

First, it explains \textbf{peer review friction}. When a paper on \enquote{experimental syntax} is reviewed, it often faces a double bind. Syntacticians (judging by $\leq_\textsc{thy}$) may find the theoretical contribution thin. Psycholinguists (judging by $\leq_\textsc{meth}$) may find the experimental design naive. The paper is attempting a fusion of two bundles. The friction isn't just grumpiness; it's a clash of validation criteria. Recognizing typed parthood allows editors to assign reviewers who are competent in the specific intersection being claimed.

Second, it validates \textbf{methodological pluralism}. If subfields are valid HPCs, then \enquote{pure} linguistics is just one bundle among many~-- usually the bundle that privileges introspective data and structural economy. Other bundles (corpus linguistics, sociolinguistics) privilege different stabilizers (usage data, social variation). These aren't failed attempts at pure linguistics; they are different cuts through the same multidimensional reality.

Finally, it recovers \textbf{intensional mereology}. Just as Newton asked what makes a planet a single object (internal forces cancelling out), we can ask what makes a subfield a genuine whole. Why does \term{Sociophonetics} exist as a stable cluster, while \term{Generative Phonetics} never quite cohered? Because the mechanisms aligned. Social variation turns out to be deeply entangled with phonetic detail (as we saw in Chapter~\ref{ch:register}). The phenomena cluster naturally.

The HPC framework doesn't just categorize our data. It categorizes us. And it suggests that the messy, overlapping map of modern linguistics is not a sign of immaturity, but an accurate reflection of a system where everything is braided.
