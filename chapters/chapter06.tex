\chapter{Projectibility and the good bet}
\label{ch:projectibility}

% SLOGAN: Categories earn their keep by supporting induction.
% Sticky sentence: "The mechanism projects even though the category, as traditionally defined, doesn't."
% See notes/book-slogans.md for the book-wide slogan strategy.

% Epigraph from p. 206 of the edition cited in references.bib
\epigraph{If there are not [pedicabs], Mr Tagomi thought, I would be well advised to retire to secluded place and kill myself.}{Philip K. Dick, \textit{The Man in the High Castle}}

Tagomi has slipped between worlds, and he needs to know which one he's in. Pedicabs exist in his home world but not in the other. He's betting his life on the projectibility of a single feature.

In your world, the stakes are lower but the logic is the same. You encounter \mention{car}. It takes determinatives, pluralises, functions as an argument. You've never seen \mention{pedicab}~-- but you bet it behaves likewise. You're usually right. The category \term{noun} lets you project from instances you've seen to instances you haven't. That's the bet, and it usually pays off.

Polish aspect offers a puzzle. Every textbook tells you: perfective aspect marks bounded events~-- completed, delimited, whole. Imperfective marks unbounded events~-- ongoing, habitual, incomplete. The definitions are centuries old, drilled into every language learner, refined in journal articles. They should work.

When computational models trained on those definitions try to predict which aspect Polish speakers actually use, they fail~-- 77\% accuracy for perfective, against 98\% for imperfective \citep{divjak2025learnability}. The definitions that have been taught for generations capture only half the system. Something is projectible about aspect; it just isn't what the textbooks say.

This chapter asks what makes a category projectible~-- worth betting on. The previous chapter established that grammatical categories are real, maintained by mechanisms rather than defined by essences. This chapter asks what we get in return. The answer is \term{projectibility}: the ability of a category to support inductive inference. Categories earn their keep by supporting induction. But which categories, and why?

For constructed categories~-- mathematical sets, legal statuses, programming constructs~-- the essentialist answer works: definitions support induction (§\ref{sec:2:where-essentialism-works}). Grammatical categories aren't constructed, so definitions aren't there to do the work. What, then, grounds the bet? The maintenance view answer: mechanisms. Categories support induction not because they're defined but because they're mechanistically grounded. The mechanisms that maintain the category also explain why its members resemble each other. Learning about one member tells you about others because the same mechanisms shaped both.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.npi-fragmentation.png}
\caption{Uniform label, jagged reality. The category \term{NPI} (negative polarity item) groups expressions that share sensitivity to negative contexts, but \citet{hoeksema2012} documents at least twelve distinct licensing patterns. No single mechanism maintains them as a kind; the label names a distributional class, not an HPC cluster.}
\label{fig:npi-fragmentation}
\end{figure}

The pattern shows up even in computational models trained without linguistic theory. \citet{decarlo2023} probed language models on negative polarity items (NPIs)~-- or \term{non-affirmative items} in \textit{CGEL}'s terminology~-- expressions like \mention{ever}, \mention{yet}, \mention{at all}, and \mention{lift a finger} that require licensing contexts like negation or questions. But these items don't license alike. Superlatives license \mention{ever}~-- \mention{the nicest person I've ever met}~-- but not \mention{lift a finger}: *\mention{the laziest person who would lift a finger}. The \term{NPI} class looks uniform, but \citet{hoeksema2012} documents at least twelve distinct licensing patterns across English NPIs~-- far more than the binary or ternary distinctions proposed by semantic theory. What clustering exists tracks lexical-semantic properties: minimizers pattern alike, temporal adverbs pattern alike, modal auxiliaries pattern alike. Models succeed at NPI prediction only to the extent they learn each item's distribution, not the category. The label groups items that share sensitivity to negative contexts; no mechanism maintains them as a kind.\footnote{\citeauthor{khalidi2013}'s (\citeyear{khalidi2013}) ``nodes in causal networks'' account would still count NPIs as causally grounded~-- they share semantic sensitivity to negative contexts. What they lack is the homeostatic mechanism that would make them an HPC kind. They're stable at equilibrium rather than dynamically maintained: balls sitting at the bottom of a trough, not tops that must be spun to stay upright.}

Contrast filler-gap constructions. \citet{boguraev2025} used causal interventions to test whether language models learn shared mechanisms across open interrogatives, relative clauses, and clefts. They do: a mechanism learned on embedded open interrogatives transfers to produce filler-gap behaviour in clefts. The structural dependency projects even when the surface constructions differ. The difference isn't arbitrary. Filler-gap is a structural mechanism maintained by parsing operations. NPI licensing is lexically specified, item by item. NPI is a distributional class; filler-gap is a mechanistic kind. The projectibility tracks the ontology.

This chapter develops the same contrast through Polish aspect. If textbook definitions made for good bets, the case would be settled in a paragraph.


\section{The definitional bet}
\label{sec:6:definitional-bet}

Slavic verbal aspect looks like a paradigm case of a grammaticalised binary. Every Polish verb bears aspectual marking: imperfective or perfective. The opposition is obligatory, pervasive, and ancient~-- codified in grammars for centuries, taught in every language classroom.

The textbooks offer crisp definitions. Imperfective presents an event as unbounded~-- ongoing, habitual, incomplete. Perfective presents it as bounded~-- a completed whole with temporal limits (Figure~\ref{fig:aspect-viewpoint}). The terminology varies (totality, resultativeness, telicity), but the core claim is the same: there's an invariant semantic content distinguishing the two aspects, and knowing that content should let you predict which aspect a speaker will choose.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{figures/6.aspect-viewpoint.png}
\caption{The textbook account of Slavic aspect. Imperfective presents the event from inside, as ongoing; perfective presents it from outside, as a completed whole. This is the \enquote{viewpoint} metaphor that has dominated aspectual theory for a century.}
\label{fig:aspect-viewpoint}
\end{figure}

This is essentialism applied to morphology. The definitions are the essence; the essence determines behaviour. Learn the essence, and you can project: knowing what perfective \emph{means} should tell you when to use it.

But the prediction fails. If aspect has invariant semantic content, then a model that knows that content should predict aspectual usage. \citet{divjak2025learnability} tested exactly this.

They built three computational models of Polish verb usage:
\begin{itemize}
    \item A \emph{lemma-concrete} model that learns cue--outcome associations without assuming aspect exists as a category at all.
    \item An \emph{aspect-concrete} model that learns aspect from usage cues~-- distributional patterns in the input.
    \item An \emph{aspect-abstract} model that learns aspect from the semantic labels proposed in the theoretical literature~-- boundedness, totality, resultativeness.
\end{itemize}

The aspect-abstract model is the textbook view formalised. If the invariant meanings are real, this model should win.

It doesn't.

On corpus data, the aspect-abstract model performs reasonably~-- 87\% accuracy \citep{divjak2025learnability}. But accuracy hides an asymmetry. The model predicts imperfective well: 98\% correct. It predicts perfective poorly: only 77\%~-- you lose the bet nearly one time in four. The semantic invariants that aspectologists have proposed for a century~-- the definitions on which projectibility supposedly depends~-- capture only half the system.

More damaging: when validated against native-speaker judgments in a gap-filling task, the aspect-abstract model performs \emph{worse} than the simpler models. Native speakers' preferences align better with a model that doesn't even use the aspect category than with one that does. The lemma-concrete model~-- the one that treats each verb individually, without abstracting to aspect~-- best predicts which forms humans prefer.

This is a failure of definitional projectibility. The category exists; the usage is systematic; but the definitions don't project to behaviour. Knowing what \enquote{perfective} supposedly \emph{means} doesn't reliably tell you when Polish speakers will \emph{use} it.


\section{The mechanistic alternative}
\label{sec:6:mechanistic-alternative}

Why does the textbook view fail? \citet{divjak2024aspect} provide the answer.

Their corpus study of Polish aspect reveals a usage landscape strikingly different from the textbook picture.

First, lexical bias is the norm. About 90\% of Polish verbs strongly prefer one aspect~-- greater than 90\% of their tokens appear in the preferred form. Only 11\% of aspectual pairs are genuinely equiprobable. The textbook suggestion that speakers \enquote{choose} aspect based on how they view the event applies to a small minority of cases.

Second, tense carries most of the signal. A simple model using just the superlemma (verb identity) and three-way tense distinction (past, present, future) achieves F1 scores of 0.95 for imperfective and 0.90 for perfective~-- the perfective asymmetry persists, just smaller. Aspect is largely predictable from tense, not from semantic viewpoint.

Third, context cues appear where needed. Temporal adverbs and other contextual markers show up reliably only with the 11\% of verbs that lack lexical bias. The system is informationally efficient: redundant cues don't clutter unambiguous cases.

Finally, the landscape is already shaped~-- like a riverbed cut by the water that flows through it. For most verbs, learning the verb means entering a channel that use keeps cutting deeper. The category isn't applied at utterance; the same flow that carved it maintains it.

This reframes the question worth asking. Instead of \enquote{what does aspect mean?}~-- a question that invites ever more refined invariant definitions~-- we ask \enquote{what maintains the aspectual patterns speakers produce?} That question is open, investigable, and already yielding answers: distributional signatures, acquisition dynamics, lexical entrenchment. The textbook view isn't wrong; it's asking a question whose answer can't be found by the methods it uses. The mechanism view doesn't replace it~-- it explains why it worked as well as it did, and what it was missing.


Now the maintenance view snaps into focus. Why can a Polish speaker project aspectual behaviour to unfamiliar verbs? Not by applying a definition. The definitions~-- boundedness, totality~-- predict only imperfective, and even then imperfectly. What projects is something different: the cue--outcome structure that learners extract from the input.

Consider: you've learned \mention{robić} (impf) / \mention{zrobić} (pf)~-- `do', `accomplish'. You encounter an unfamiliar verb \mention{pływać}~-- `swim'. How do you know that \mention{przepływać} will be perfective?

The textbook answer: you apply the semantic definition of perfectivity~-- the event is bounded, complete, telic~-- and infer that \mention{przepływać} (`swim across', `complete the crossing') satisfies those criteria.

But as we've seen, the semantic definition predicts poorly. Worse, it predicts perfective worse than imperfective~-- exactly wrong for the case at hand.

The mechanism-based answer: You've learned that certain prefixes, in certain tense contexts, pattern with perfective. You've learned that verbs of motion typically have strong aspectual biases carried by morphological material. You project not from a definition but from a web of cue--outcome associations maintained across your linguistic experience.

This is projectibility grounded in mechanism rather than definition (Figure~\ref{fig:aspect-mechanism}). The category \term{perfective} exists~-- you can introspect about it, metalinguistic discourse depends on it~-- but its psycholinguistic reality needn't rest on invariant semantic content. The good bet is on the consistency of the distributional patterns that maintain it.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.aspect-mechanism.png}
\caption{The mechanism-based view of aspectual projectibility. Instead of applying semantic definitions, learners extract cue--outcome associations~-- morphological patterns, tense contexts, lexical biases~-- that allow prediction of novel forms. The question this answers is not \enquote{what does aspect mean?} but \enquote{what maintains aspectual patterns?} (Percentages are schematic; actual weights vary by verb and context.)}
\label{fig:aspect-mechanism}
\end{figure}


\section{Labels aren't mechanisms}
\label{sec:6:labels-mechanisms}

Here's where the story takes a surprising turn. \citet{divjak2025learnability} found that the best model~-- the one that most closely matches native-speaker preferences~-- is the one that doesn't use the category \term{aspect} at all.

The lemma-concrete model~-- the one that treats each verb individually, without abstracting to aspect~-- predicts human behaviour better than the aspect-aware models. The statistical evidence is overwhelming: the probability that the aspect-aware models are actually better is effectively zero.\footnote{AIC 3,891 for lemma-concrete versus 3,954 for aspect-concrete and 4,037 for aspect-abstract; evidence ratios in the $10^{13}$ to $10^{17}$ range~-- numbers so large that the conclusion is beyond reasonable doubt.}

What does this mean for the ontological status of aspect? Here we need to separate three things:

\begin{enumerate}
    \item \emph{Is there a stable pattern that linguists call ``aspect''?} Yes. The corpus regularities, speaker agreement, and reliable acquisition all point to a real, socially shared, historically stable clustering.
    \item \emph{Do the traditional semantic definitions project to usage?} Not reliably~-- especially for perfective. That's a failure of \emph{definitional} projectibility, not automatically a failure of aspect as such.
    \item \emph{Is the abstract binary label psychologically intermediate in the production system?} The lemma-concrete result suggests: maybe not. The best causal story may live at a finer grain.
\end{enumerate}

The apparent contradiction~-- ``aspect looks real'' versus ``aspect doesn't project''~-- dissolves once we see what exactly failed. What failed is the textbook essence. What may also have failed is the assumption that speakers need an explicit aspect representation as a mediating variable. What did \emph{not} fail is the existence of stable, learnable, intersubjectively shared aspectual patterning.

This is almost the cleanest possible maintenance-view win. The category label tracks a real cluster. But that cluster is maintained by a bundle of lower-level mechanisms: lexeme-specific entrenchment, tense-conditioned expectations, prefixal cueing. Projectibility belongs to that bundle, not to the invariant semantic paraphrases. Polish aspect is real as a stable pattern, but the projectible unit is smaller than the label. The mechanism projects; the label names the emergent alignment of those mechanisms without explaining it.

Put differently: \term{aspect} names the pattern; it doesn't do the work. You can project aspectual behaviour \emph{without} representing \enquote{aspect} as such~-- because what you're really projecting are cue--outcome associations that happen to have an aspectual signature. The lemma-specific patterns don't preclude aspect as a generalisation; they ground it. What speakers know isn't \emph{either} verbs \emph{or} aspect but a multi-level network where both coexist~-- the general emergent from the particular.

This resolves the puzzle of naming. We call it \term{aspect} because of its history; Polish aspect is the genealogical descendant of a system that may once have fit the definitions better. But mechanistic drift happens. A category can remain historically continuous while its causal underpinnings shift. A label can remain genealogically appropriate but be synchronically misleading about what projects. Think of a volcanic island. The volcano builds the island over millennia, but eventually goes dormant. Coral colonises the flanks; soil accumulates; vegetation takes root. The island persists~-- not because the volcano is still active, but because new mechanisms have taken over: reef-building, soil formation, root networks. Calling it a \enquote{volcanic island} is genealogically correct; the volcano did the initial work. But it's synchronically misleading: what maintains the island now is coral and roots, not magma. Polish aspect is like this. The opposition was carved by semantic-temporal distinctions that may once have been the primary mechanism. But the volcano has gone dormant. Now what maintains the pattern~-- what makes it projectible~-- is lexeme-specific cue structure, not semantic essence. The label names the island, not the volcano.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.island-volcano.png}
\caption{Mechanistic drift: a volcanic island. The volcano built the island but is now dormant. What maintains the island today~-- coral reefs, root networks, soil formation~-- differs from what created it. Polish aspect is analogous: the semantic-temporal distinctions that may once have been the primary mechanism have gone dormant. What maintains aspectual patterns now is lexeme-specific cue structure. The label names the island, not the volcano.}
\label{fig:island-volcano}
\end{figure}

The cross-linguistic term \term{aspect} functions as a comparative concept; within Polish, it names a historically inherited pattern whose contemporary projectibility is anchored in lexeme-specific cue structures rather than the textbook semantic essence. Labels aren't definitions, and labels aren't mechanisms. Calling this opposition \term{aspect} risks reifying a historically entrenched label whose textbook semantics no longer track the mechanisms that actually maintain usage. It is best treated as the name of an emergent clustering, not the explanatory unit that makes it project.


\section{Generalising the lesson}
\label{sec:6:generalising-lesson}

Polish aspect illustrates a general lesson of the maintenance view. Polish has a grammatical opposition traditionally called aspect; what these results challenge is the assumption that the textbook characterisation of that opposition is the mechanism that makes it projectible. Definitional characterisations can fail projectibility even when the categories they describe are descriptively real. Aspect has been defined for centuries, but those definitions fail to predict usage. By contrast, mechanism-based accounts succeed where definitions fail: the same system becomes predictable once you attend to the distributional structure~-- lexical bias, tense context, morphological cues~-- rather than the semantic essence.

This separation reveals that the category and the mechanism need not coincide. \term{Aspect} is a useful label picking out a real pattern, but the psychological reality of that pattern may be a network of cue--outcome associations, not a represented binary. The mechanism lives below the category; the projectibility comes from the mechanism. This is HPC without category reification: clusters maintained by mechanisms, labels applied by analysts.

The failure is diagnostic. When a category fails to project~-- when its definition doesn't predict behaviour~-- that's evidence that the proposed characterisation mislocates the mechanisms. The category remains descriptively real; what fails is the assumption that its textbook semantic essence is the locus of projectibility.


Polish aspect is a worked example, not an isolated curiosity. The pattern~-- definitional characterisations that fail to project, mechanism-based descriptions that succeed~-- appears across grammatical domains.

\citet{ambridge2020} found that the causative alternation (\mention{break the vase} vs *\mention{laugh the man}) is predicted by a continuous semantic dimension (directness of causation) across five typologically unrelated languages. The semantic definitions of verb classes don't work; the mechanism (sensitivity to causal directness) does. Strikingly, a model trained on five languages predicts native-speaker judgments in a sixth (Balinese) without exposure. The mechanism projects cross-linguistically; the definitional verb classes don't.

\citet{saldana2022} showed that morphological syncretism patterns are learned better when syncretic cells share semantic similarity~-- not when they share features in a definitional sense. The learnability gradient tracks similarity, not category membership. What projects is the similarity structure, not the feature system.

\citet{chi2020} demonstrated that grammatical relations (subject, object) emerge spontaneously in multilingual BERT~-- trained without any symbolic grammar~-- and transfer across languages. A probe trained only on English successfully identifies grammatical relations in French. The categories exist, but defining grammatical roles isn't what produces them; distributed learning over functional pressures is. The mechanism projects cross-linguistically; the formal definitions are epiphenomenal.

These aren't the only examples. Chapter~\ref{ch:word-classes} develops the case for word classes in detail. The upshot: projectibility is the empirical test for mechanistic grounding. When a category supports reliable induction, that's evidence that the mechanisms are real. When it doesn't, something about the proposed characterisation is off.

\section{The epistemic payoff}
\label{sec:6:epistemic-payoff}

The aspect case shows that even a descriptively real category can fail to project if its definition misaligns with its maintaining mechanisms. This misalignment clarifies a classic problem in the philosophy of science.

Liu Cixin's turkey parable captures the problem of induction with dark precision:

\begin{quote}
Every morning on a turkey farm, the farmer comes to feed the turkeys. A scientist turkey, having observed this pattern to hold without change for almost a year, makes the following discovery: \enquote{Every morning at eleven, food arrives.} On the morning of Thanksgiving, the scientist announces this law to the other turkeys. \citep[ch.~6]{liu2008}
\end{quote}

The turkey's law is perfectly confirmed by all available evidence. The problem isn't the evidence; it's that the law isn't grounded in mechanism. The farmer's purpose~-- invisible to the turkey~-- determines when the correlation breaks. Had the turkey understood \emph{why} food arrives (fattening for slaughter), it would have predicted its own demise rather than its next meal.

Nelson Goodman's \term{grue} problem makes the same point in philosophical dress. Goodman's riddle: emeralds examined before time $t$ are green; emeralds examined after $t$ are blue. Define \term{grue} as \enquote{green if examined before $t$, blue otherwise}. Every emerald we've ever observed is grue. So why don't we project \term{grue} to unexamined emeralds?

Goodman's own answer invoked entrenchment: \term{green} is projectible because it's been projected successfully in the past. \term{Grue} isn't because it hasn't. The circularity is deliberate~-- projectibility is bootstrapped from track record.

The maintenance view offers a different answer, or rather an elaboration. \term{Green} is projectible because emeralds share a mechanism that produces greenness: chromium traces interact with light in stable ways. There's no mechanism that produces grueness; there's nothing about emeralds that makes them switch from green to blue at time $t$. Projectibility tracks mechanism, not just predicational habit.

For grammatical categories, the same logic applies. \term{Noun} is projectible because mechanisms like acquisition, entrenchment, and functional pressure keep nominal properties clustering together. A pseudo-category like \term{nerboun} (noun if acquired before age 5, verb otherwise) isn't projectible because no mechanism produces that pattern~-- there's nothing about language acquisition that would cause a switch at age 5.

A category can look like a good bet~-- its definition correlates with usage, its label is entrenched~-- and still turn out to be a turkey.

\subsection{Is projectibility interest-relative?}
\label{sec:6:interest-relativity}

\citet{craver2009} and \citet{onishi2022} argue that any mechanism-based account inherits context-dependence. Which mechanism you attend to, at what level of abstraction, with what boundaries~-- all depend on your explanatory goals. If so, the maintenance view answer to Goodman looks circular: a category is projectible relative to the mechanism you're interested in, and the mechanism you're interested in is whichever one makes the category projectible.

The key distinction is between choosing a level because it answers your question, and choosing a level because it flatters your category. A pedicab can be explained by engineering (frame geometry, gear ratios) or by physics (forces, friction, momentum). Both levels are real; both describe genuine causal structure. Your question selects the level. But the causal structure at that level determines whether your answer is correct. Interest picks the question; it doesn't fabricate the mechanism that answers it.

This is precisely what went wrong with the turkey. Its interest was survival, but it coarse-grained at the wrong level: time of day rather than the farmer's calendar. The correlation was real at one level (11 AM $\rightarrow$ food) but collapsed at another (Thanksgiving $\rightarrow$ slaughter). The turkey's interest didn't invent the mechanisms; it just selected the wrong one to track.

For grammatical categories, the same logic applies. If your question is ``what triggers perfective here?'' the answer lives at the cue-structure level, not the semantic-definition level. Both levels exist; the semantic level just doesn't answer the production question. The aspect case shows the stakes: if your goal is to predict corpus distributions, the textbook mechanism (semantic boundedness) is the wrong one~-- it predicts imperfective well and perfective poorly. If your goal is to predict native-speaker gap-filling, the lemma-concrete mechanism is the right one~-- it outperforms aspect-aware models. The prediction either succeeds or fails. That's the empirical constraint on which mechanism matters.

Conventionalism can't explain why some mechanisms predict and others don't. The maintenance view can: the mechanisms that predict are the ones that actually maintain the cluster. Interest selects among real causal structures; it doesn't invent them. This is what \citet{carrollparola2024} mean by emergence: coarse-grained descriptions that support accurate predictions despite discarding micro-level information. The key is coarse-graining \emph{in the right way}~-- throwing away arbitrary information destroys predictability, but discarding the right information preserves it.

Once interests are fixed by a task, we can ask how strongly different categories support that task. This is the next implication of mechanistic grounding: projectibility comes in degrees.

\subsection{Degrees of projectibility}
\label{sec:6:degrees-projectibility}

Not all categories are equally projectible. The framework expects a gradient, and the evidence supports it.

At one extreme: high-frequency, highly entrenched categories where the mechanisms are strong and consistent. English determinatives are a case: a closed class, stable across speakers, predictable in distribution. Learn \mention{each} and you can project to \mention{every} with high confidence. The mechanisms (entrenchment, functional specificity) are tight enough that the category approaches definitional coherence~-- not because there's a definition, but because the mechanisms are so strong that they produce uniform clustering.

At the other extreme: low-frequency, loosely maintained categories where the mechanisms are variable or in flux. Nonce formations, idiolectal forms, constructions undergoing change~-- these are less projectible because the mechanisms haven't stabilised. Knowing about one instance tells you less about others.

The middle ground is where the action is. Within a language, synchronically, major open classes~-- nouns, verbs, adjectives~-- are projectible on average but variable at the margins. You can project from typical nouns to novel nouns with high confidence; you can project from \mention{fun} to other adjective-noun boundary cases with less. The mechanisms are strong enough to produce robust clustering at the core but not strong enough to determine the periphery.

The prediction is testable: core category members~-- high-frequency, prototypical, functionally central~-- should elicit consistent judgments; peripheral members~-- low-frequency, boundary-straddling, functionally ambiguous~-- should elicit variable ones. The variance isn't noise; it's the signature of weak entrenchment.

Recent experimental work confirms the pattern. In grammaticality judgments for Dutch syntax, peripheral structures are correctly identified only 57\% of the time (SD $\approx$ 0.27), while core structures are correctly identified 90\% of the time (SD $\approx$ 0.09)~-- the variance triples at the periphery \citep{favier2021}. Similarly for syntactic variants indexed to verb frequency: low-frequency verbs elicit higher acceptance of violations (a fourfold increase in error rates: 6.58\% vs.\ 1.58\%), because weak entrenchment permits wider variation in what speakers treat as grammatical \citep{sassenhagen2018}. In morphology, the pattern is starker still: high-frequency English adjectives elicit near-unanimous agreement on comparative form, while low-frequency and nonce adjectives split speakers \citep{grazianoking2005}. Box-and-whisker plots of acceptability ratings for Polish syntactic variants show the same signature: the whiskers widen dramatically as verb frequency drops (Figure~\ref{fig:divjak-boxplots}).

% TODO: Permission pending from Wiley/Cognitive Science for this figure
\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.divjak-boxplots.png}
\caption{Box-and-whisker plots showing verb reliance on a construction by acceptability rating, split by verb frequency quartile. In the lowest frequency quartile (top left), the relationship between reliance and acceptability is noisy; in higher frequency quartiles, the relationship becomes clearer and variance decreases. Reproduced from \citet{divjak2017}; permission pending.}
\label{fig:divjak-boxplots}
\end{figure}

This is what the maintenance view predicts. Where mechanisms are strong and consistent, judgments converge; where mechanisms are weak or variable, judgments diverge. The variance tracks the strength of the causal structure. Projectibility isn't all-or-nothing; it's graded by entrenchment.



We can now answer the question that opened the chapter. Why should learning about one instance tell us anything about others?

Because the same mechanisms that shaped the instance you learned are shaping the instances you haven't. Categories maintained by consistent mechanisms produce consistent members. The consistency underwrites induction.

This is the epistemic payoff~-- what the good bet wins. HPC kinds are categories you can learn from, not because they have definitions but because they have causal structure. The mechanism that makes a word a noun also makes other nouns. The mechanism that biases a verb toward perfective also biases similar verbs. The mechanism that entrains a speaker to one usage pattern entrains the same speaker to related patterns.

Projectibility isn't metaphysically guaranteed. Categories can fail to project if their proposed characterisation doesn't match the maintaining mechanisms~-- as aspect-abstract fails. Categories can fail to project if the mechanisms are too weak or too variable~-- as nonce formations fail. But where the mechanisms are real and consistent, projectibility follows.

This is what makes grammatical categories worth having. Not that they carve nature at the joints in some eternal sense~-- language changes, categories evolve. But that they support the inferences that make language learnable, usable, discussable. Categories earn their keep by supporting induction. That's the test of mechanism: does learning about instances let you project to the kind? If yes, the mechanisms are real. If no, look elsewhere for the causal structure.


% TODO: Transition to Chapter 7 on the full mechanistic story
The label names the island, not the volcano. But we've talked about mechanisms as if they were self-explanatory. They aren't. What exactly maintains the island? What processes stabilise the clustering, ensure that new instances resemble old ones, transmit the pattern across speakers and generations? The next chapter opens the black box. We'll trace the mechanisms in detail~-- acquisition, entrenchment, alignment, transmission, functional pressure~-- and ask what each contributes to the stability of linguistic kinds. Only then can we ask: under what conditions do mechanisms fail?
