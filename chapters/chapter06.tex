\chapter{Projectibility and the good bet}
\label{ch:projectibility}

% SLOGAN: Categories earn their keep by supporting induction.
% Sticky sentence: "The mechanism projects even though the category, as traditionally defined, doesn't."
% See notes/book-slogans.md for the book-wide slogan strategy.
% LEVELS CHECK (2025-12-07): Verified no conflation of diachronic/synchronic, population/individual, emergent/constituent. The volcano metaphor is explicitly flagged as diachronic (see developmental asymmetry note). Interest-relativity section distinguishes explanatory levels from ontological ones.

% Epigraph from p. 206 of the edition cited in references.bib
\epigraph{If there are not [pedicabs], Mr Tagomi thought, I would be well advised to retire to secluded place and kill myself.}{— Philip K. Dick, \textit{The Man in the High Castle} (1962)}

Mr.~Tagomi has slipped between worlds, and he needs to know which one he's in. Pedicabs exist in his home world but not in the other. He's betting his life on the projectibility of a single feature.

In your world, the stakes are lower but the logic is the same. You encounter \mention{car}. It takes determinatives, pluralizes, functions as an argument. You've never seen \mention{pedicab}~-- but you bet it behaves likewise. You're usually right. The category \term{noun} lets you project from instances you've seen to instances you haven't. That's the bet, and it usually pays off.

Polish aspect offers a puzzle. Every textbook tells you: perfective aspect marks bounded events~-- completed, delimited, whole. Imperfective marks unbounded events~-- ongoing, habitual, incomplete. The definitions are centuries old, drilled into every language learner, refined in journal articles. They should work.

When computational models trained on those definitions try to predict which aspect Polish speakers actually use, they project imperfectly~-- 77\% accuracy for perfective, against 98\% for imperfective \citep{divjak2025learnability}. The definitions that have been taught for generations capture only half the system. Something is projectible about aspect; it just isn't what the textbooks say.

This chapter asks what makes a category projectible~-- worth betting on, and whether the same category can be projectible for one purpose but not another. The previous chapters argued that many linguistic categories are real, maintained by mechanisms rather than defined by essences. Grammatical categories are the central testbed in this book, but the same question arises for phoneme contrasts and for social categories like academic register and politeness systems. This chapter asks what we get in return. The answer is projectibility: the ability of a category to support inductive inference. Categories earn their keep by supporting induction. But which categories, for which purposes, and why?

The next two chapters develop two diagnostics for mechanism-maintained kinds. This chapter addresses \term{projectibility}: does the category support induction? Can you learn about one member and reliably bet on others? Chapter~\ref{ch:stabilizers} addresses \term{perturbation sensitivity}: what maintains the cluster, and what happens when the maintenance fails? The two diagnostics are complementary. Projectibility tests whether the category earns its keep; perturbation sensitivity reveals the causal structure that makes it do so. Chapter~\ref{ch:failure-modes} then shows how these diagnostics separate genuine HPCs from thin, fat, and negative classes~-- labels without the causal structure to back them up.

For constructed categories~-- mathematical sets, legal statuses, programming constructs~-- the essentialist answer works: definitions support induction (§\ref{sec:2:where-essentialism-works}). Most linguistic categories aren't constructed, so definitions aren't there to do the work. What, then, grounds the bet? The maintenance view answer: mechanisms. Categories support induction not because they're defined but because they're mechanistically grounded. The mechanisms that maintain the category also explain why its members resemble each other. Learning about one member tells you about others because the same mechanisms shaped both.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.npi-fragmentation.png}
\caption{Uniform label, jagged reality. The category \term{NPI} (negative polarity item) groups expressions that share sensitivity to negative contexts, but \citet[30]{hoeksema2012} documents twelve distinct licensing patterns. No single mechanism maintains them as a kind; the label names a distributional class, not an HPC cluster.}
\label{fig:npi-fragmentation}
\end{figure}

Before looking at a complex success, consider a failure (Figure~\ref{fig:npi-fragmentation}). The label \term{NPI} (negative polarity item) groups expressions like \mention{ever}, \mention{yet}, and \mention{lift a finger} that require licensing in negative contexts~-- but \citet[30]{hoeksema2012} documents twelve distinct licensing patterns across English NPIs. Models succeed at NPI prediction only to the extent they learn each item's distribution, not the category. The label names a distributional class; no mechanism maintains it as a kind.

This chapter develops an operational criterion for distinguishing distributional classes from homeostatic kinds~-- and applies it to Polish aspect.


\subsection{Unpacking the framework}
\label{sec:6:slogan}

Chapter~\ref{ch:kinds-without-essences} compressed the maintenance view into a slogan: \emph{profile, stabilized by mechanisms, projectible relative to purposes}. This chapter unpacks each component and tests them against Polish aspect.

The three parts track three levels of analysis:
\begin{itemize}
    \item \textbf{Profile}~-- the observable surface. Properties cluster; members resemble each other. This is what you observe.
    \item \textbf{Stabilized by mechanisms}~-- the metaphysics. Something keeps the cluster together: acquisition, entrenchment, functional pressure, social enforcement. Without mechanisms, clustering is coincidental.
    \item \textbf{Projectible relative to purposes}~-- the epistemology and pragmatics. The category supports induction, but only for questions the mechanisms underwrite. A syntactician and a semanticist may have different right-sized categories for overlapping extensions.
\end{itemize}

The framework guards against three confusions. First, treating categories as mere conventions (ignoring the mechanisms). Second, treating projectibility as absolute rather than field-relative (ignoring purpose). Third, treating mechanism and projectibility as the same thing (conflating metaphysics with epistemology). The remainder of the chapter applies each piece to a test case.


\section{The definitional bet}
\label{sec:6:definitional-bet}

Slavic verbal aspect looks like a paradigm case of a grammaticalized binary. Every Polish verb bears aspectual marking: imperfective or perfective. The opposition is obligatory, pervasive, and ancient~-- codified in grammars for centuries, taught in every language classroom.

The textbooks offer crisp definitions. Imperfective presents an event as unbounded~-- ongoing, habitual, incomplete. Perfective presents it as bounded~-- a completed whole with temporal limits (Figure~\ref{fig:aspect-viewpoint}). The terminology varies (totality, resultativeness, telicity), but the core claim is the same: there's an invariant semantic content distinguishing the two aspects, and knowing that content should let you predict which aspect a speaker will choose.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{figures/6.aspect-viewpoint.png}
\caption{The textbook account of Slavic aspect. Imperfective presents the event from inside, as ongoing; perfective presents it from outside, as a completed whole. This is the \enquote{viewpoint} metaphor that has dominated aspectual theory for a century.}
\label{fig:aspect-viewpoint}
\end{figure}

This is essentialism applied to morphology. The definitions are the essence; the essence determines behaviour. Learn the essence, and you can project: knowing what perfective \emph{means} should tell you when to use it.

But the prediction fails. If aspect has invariant semantic content, then a model that knows that content should predict aspectual usage. \citet{divjak2025learnability} tested exactly this.

They built three computational models of Polish verb usage:
\begin{itemize}
    \item A \emph{lemma-concrete} model that learns cue--outcome associations without assuming aspect exists as a category at all.
    \item An \emph{aspect-concrete} model that learns aspect from usage cues~-- distributional patterns in the input.
    \item An \emph{aspect-abstract} model that learns aspect from the semantic labels proposed in the theoretical literature~-- boundedness, totality, resultativeness.
\end{itemize}

The aspect-abstract model is the textbook view formalised. If the invariant meanings are real, this model should win.

It doesn't.

On corpus data, the aspect-abstract model performs reasonably~-- 87\% accuracy \citep{divjak2025learnability}. But accuracy hides an asymmetry. The model predicts imperfective well: 98\% correct. It predicts perfective poorly: only 77\%~-- you lose the bet nearly one time in four. The semantic invariants that aspectologists have proposed for a century~-- the definitions on which projectibility supposedly depends~-- capture only half the system. Why this direction? Likely because perfective is more lexically heterogeneous: perfective verbs are marked by a variety of prefixes, each with its own distributional profile, and they appear in a narrower range of tense frames. Imperfective is closer to a default, less marked, more uniform. The asymmetry isn't random; it tracks where the semantic definition aligns with distributional reality (imperfective) and where it doesn't (perfective).

More damaging: when validated against native-speaker judgments in a gap-filling task, the aspect-abstract model performs \emph{worse} than the simpler models. Native speakers' preferences align better with a model that doesn't even use the aspect category than with one that does. The lemma-concrete model~-- the one that treats each verb individually, without abstracting to aspect~-- best predicts which forms humans prefer.

This is a failure of definitional projectibility. The category exists; the usage is systematic; but the definitions don't project to behaviour. Knowing what \enquote{perfective} supposedly \emph{means} doesn't reliably tell you when Polish speakers will \emph{use} it. (A moderate reader might object that the textbook definitions are simplistic models, not metaphysical essences~-- that their failure is a failure of \emph{that} model, not of semantic-level explanation generally. Fair enough. But even treating definitions as models rather than essences, the projective power lies in distributional cue structure and lexeme-level entrenchment. Semantic paraphrase plays at best a partial, uneven role.)


\section{The mechanistic alternative}
\label{sec:6:mechanistic-alternative}

Why does the textbook view fail? \citet{divjak2024aspect} provide the answer.

Their corpus study of Polish aspect reveals a usage landscape strikingly different from the textbook picture.

First, lexical bias is the norm. About 90\% of Polish verbs strongly prefer one aspect~-- greater than 90\% of their tokens appear in the preferred form. Only 11\% of aspectual pairs are genuinely equiprobable. The textbook suggestion that speakers \enquote{choose} aspect based on how they view the event applies to a small minority of cases.

Second, tense carries most of the signal. A simple model using just the superlemma (verb identity) and three-way tense distinction (past, present, future) achieves F1 scores of 0.95 for imperfective and 0.90 for perfective~-- the perfective asymmetry persists, just smaller. Aspect is largely predictable from tense, not from semantic viewpoint.

Third, context cues appear where needed. Temporal adverbs and other contextual markers show up reliably only with the 11\% of verbs that lack lexical bias. The system is informationally efficient: redundant cues don't clutter unambiguous cases.

Finally, the landscape is already shaped~-- like a riverbed cut by the water that flows through it. For most verbs, learning the verb means entering a channel that use keeps cutting deeper. The category isn't applied at utterance; the same flow that carved it maintains it.

This reframes the question worth asking. Instead of \enquote{what does aspect mean?}~-- a question that invites ever more refined invariant definitions~-- we ask \enquote{what maintains the aspectual patterns speakers produce?} That question is open, investigable, and already yielding answers: distributional signatures, acquisition dynamics, lexical entrenchment. The textbook view isn't wrong; it's asking a question whose answer can't be found by the methods it uses. The mechanism view doesn't replace it~-- it explains why it worked as well as it did, and what it was missing.


Now the maintenance view snaps into focus. Why can a Polish speaker project aspectual behaviour to unfamiliar verbs? Not by applying a definition. The definitions~-- boundedness, totality~-- predict only imperfective, and even then imperfectly. What projects is something different: the cue--outcome structure that learners extract from the input.

Consider: you've learned \mention{\ipa{robić}} (impf) / \mention{\ipa{zrobić}} (pf)~-- `do', `accomplish'. You encounter an unfamiliar verb \mention{\ipa{pływać}}~-- `swim'. How do you know that \mention{\ipa{przepływać}} will be perfective?

The textbook answer: you apply the semantic definition of perfectivity~-- the event is bounded, complete, telic~-- and infer that \mention{\ipa{przepływać}} (`swim across', `complete the crossing') satisfies those criteria.

But as we've seen, the semantic definition predicts poorly. Worse, it predicts perfective worse than imperfective~-- exactly wrong for the case at hand.

The mechanism-based answer: You've learned that certain prefixes, in certain tense contexts, pattern with perfective. You've learned that verbs of motion typically have strong aspectual biases carried by morphological material. You project not from a definition but from a web of cue--outcome associations maintained across your linguistic experience.

This is projectibility grounded in mechanism rather than definition (Figure~\ref{fig:aspect-mechanism}). The category \term{perfective} exists~-- you can introspect about it, metalinguistic discourse depends on it~-- but its psycholinguistic reality needn't rest on invariant semantic content. The good bet is on the consistency of the distributional patterns that maintain it.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.aspect-mechanism.png}
\caption{The mechanism-based view of aspectual projectibility. Instead of applying semantic definitions, learners extract cue--outcome associations~-- morphological patterns, tense contexts, lexical biases~-- that allow prediction of novel forms. The question this answers is not \enquote{what does aspect mean?} but \enquote{what maintains aspectual patterns?} (Percentages are schematic; actual weights vary by verb and context.)}
\label{fig:aspect-mechanism}
\end{figure}


\section{Labels aren't mechanisms}
\label{sec:6:labels-mechanisms}

Here's where the story takes a surprising turn. \citet{divjak2025learnability} found that the best model~-- the one that most closely matches native-speaker preferences~-- is the one that doesn't use the category \term{aspect} at all.

The lemma-concrete model~-- the one that treats each verb individually, without abstracting to aspect~-- predicts human behaviour better than the aspect-aware models. The statistical evidence is overwhelming: the probability that the aspect-aware models are actually better is effectively zero.\footnote{AIC 3,891 for lemma-concrete versus 3,954 for aspect-concrete and 4,037 for aspect-abstract; evidence ratios in the $10^{13}$ to $10^{17}$ range~-- numbers so large that the conclusion is statistically compelling.}

What does this mean for the ontological status of aspect? Here we need to separate three things:

\begin{enumerate}
    \item \emph{Is there a stable pattern that linguists call ``aspect''?} Yes. The corpus regularities, speaker agreement, and reliable acquisition all point to a real, socially shared, historically stable clustering.
    \item \emph{Do the traditional semantic definitions project to usage?} Not reliably~-- especially for perfective. That's a failure of \emph{definitional} projectibility, not automatically a failure of aspect as such.
    \item \emph{Is the abstract binary label psychologically intermediate in the production system?} The lemma-concrete result suggests: maybe not. The best causal story may live at a finer grain.
\end{enumerate}

The apparent contradiction~-- ``aspect looks real'' versus ``aspect doesn't project''~-- dissolves once we see what exactly failed. What failed is the textbook essence. What may also have failed is the assumption that speakers need an explicit aspect representation as a mediating variable. What did \emph{not} fail is the existence of stable, learnable, intersubjectively shared aspectual patterning.

This is almost the cleanest possible maintenance-view demonstration. The category label tracks a real cluster. But that cluster is maintained by a bundle of finer-grained mechanisms: lexeme-specific entrenchment, tense-conditioned expectations, prefixal cueing. Projectibility belongs to that bundle, not to the invariant semantic paraphrases. Polish aspect is real as a stable pattern, but the projectible unit is smaller than the label. The mechanism projects; the label names the emergent alignment of those mechanisms without explaining it.

Put differently: \term{aspect} names the pattern; it doesn't do the work. You can project aspectual behaviour \emph{without} representing \enquote{aspect} as such~-- because what you're really projecting are cue--outcome associations that happen to have an aspectual signature. The lemma-specific patterns don't preclude aspect as a generalisation; they ground it. What speakers know isn't \emph{either} verbs \emph{or} aspect but a multi-level network where both coexist~-- the general emergent from the particular. This answers the objection that a lemma-level model leaves no room for the category: the category exists as an emergent alignment, even if processing happens at a finer grain. The island is real even though the coral does the maintaining.

This resolves the puzzle of naming. We call it \term{aspect} because of its history; Polish aspect is the genealogical descendant of a system that may once have fit the definitions better. But mechanistic drift happens. A category can remain historically continuous while its causal underpinnings shift. A label can remain genealogically appropriate but be synchronically misleading about what projects. Think of a volcanic island. The volcano builds the island over millennia, but eventually goes dormant. Coral colonises the flanks; soil accumulates; vegetation takes root. The island persists~-- not because the volcano is still active, but because new mechanisms have taken over: reef-building, soil formation, root networks. Calling it a \enquote{volcanic island} is genealogically correct; the volcano did the initial work. But it's synchronically misleading: what maintains the island now is coral and roots, not magma. Polish aspect is like this. The opposition was carved by semantic-temporal distinctions that may once have been the primary mechanism. But the volcano has gone dormant. Now what maintains the pattern~-- what makes it projectible~-- is lexeme-specific cue structure, not semantic essence. The label names the island, not the volcano. (Note the developmental asymmetry: for a child acquiring Polish, the volcano was never active. Learners don't experience the historical shift; they experience only the coral reef~-- the current distributional cues. The ``mechanism drift'' is a diachronic observation about the collective system, not a stage in individual acquisition.)

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.island-volcano.png}
\caption{Mechanistic drift: a volcanic island. The volcano built the island but is now dormant. What maintains the island today~-- coral reefs, root networks, soil formation~-- differs from what created it. Polish aspect is analogous: the semantic-temporal distinctions that may once have been the primary mechanism have gone dormant. What maintains aspectual patterns now is lexeme-specific cue structure. The label names the island, not the volcano.}
\label{fig:island-volcano}
\end{figure}

The cross-linguistic term \term{aspect} functions as a \term{comparative concept}; within Polish, it names a historically inherited pattern whose contemporary projectibility is anchored in lexeme-specific cue structures rather than the textbook semantic essence. Labels aren't definitions, and labels aren't mechanisms. Calling this opposition \term{aspect} risks reifying a historically entrenched label whose textbook semantics no longer track the mechanisms that actually maintain usage. It is best treated as the name of an emergent clustering, not the explanatory unit that makes it project. But here's a constraint: genealogical continuity alone doesn't justify continued use of a label. The label is appropriate only if it still picks out a stable emergent pattern at some explanatory level. An island that has fully eroded, with no coral keeping it together, is no longer an island~-- and deserves no name.


\section{Generalising the lesson}
\label{sec:6:generalising-lesson}

Polish aspect illustrates a general lesson of the maintenance view. Polish has a grammatical opposition traditionally called aspect; what these results challenge is the assumption that the textbook characterization of that opposition is the mechanism that makes it projectible. Aspect has been defined for centuries, but those definitions fail to predict usage. By contrast, mechanism-based accounts succeed where definitions fail: the same system becomes predictable once you attend to the distributional structure~-- lexical bias, tense context, morphological cues~-- rather than the semantic essence.

This separation reveals that the category and the mechanism need not coincide. \term{Aspect} is a useful label picking out a real pattern, but the psychological reality of that pattern may be a network of cue--outcome associations, not a represented binary. The mechanism lives below the category; the projectibility comes from the mechanism. When a proposed characterization fails to project, that's diagnostic: it tells you the characterization doesn't track the mechanisms. This is HPC without category reification: clusters maintained by mechanisms, labels applied by analysts.


Polish aspect is a worked example, not an isolated curiosity. The pattern~-- definitional characterizations that fail to project, mechanism-based descriptions that succeed~-- appears across grammatical domains.

\citet{ambridge2020} found that the causative alternation (\mention{break the vase} vs *\mention{laugh the man}) is predicted by a continuous semantic dimension (directness of causation) across five typologically unrelated languages. The semantic definitions of verb classes don't work; the mechanism (sensitivity to causal directness) does. Strikingly, a model trained on five languages predicts native-speaker judgments in a sixth (Balinese) without exposure. The mechanism projects cross-linguistically; the definitional verb classes don't.

\citet{saldana2022} showed that morphological syncretism patterns are learned better when syncretic cells share semantic similarity~-- not when they share features in a definitional sense. The learnability gradient tracks similarity, not category membership. What projects is the similarity structure, not the feature system.

\citet{chi2020} demonstrated that grammatical relations (subject, object) emerge spontaneously in multilingual BERT~-- trained without any symbolic grammar~-- and transfer across languages. A probe trained only on English successfully identifies grammatical relations in French. The categories exist, but defining grammatical roles isn't what produces them; distributed learning over functional pressures is. The mechanism projects cross-linguistically; the formal definitions are epiphenomenal.

These aren't the only examples. Chapter~\ref{ch:lexical-categories} develops the case for word classes in detail. The upshot: projectibility is the empirical test for mechanistic grounding. When a category supports reliable induction, that's evidence that the mechanisms are real. When it doesn't, something about the proposed characterization is off.


\section{Field-relative projectibility}
\label{sec:6:field-relative}

We've established that projectibility tracks mechanism, not definition. But projectibility for whom? The same category can project well for one analytical purpose and poorly for another. This isn't perspectivalism~-- different views of the same thing. It's a claim about ontology: there are genuinely different HPCs that happen to overlap in extension, each projectible in its own domain.

\subsection{The tomato problem}
\label{sec:6:tomato}

Is a tomato a fruit or a vegetable? The question is undecidable only if you think there's one right answer.

A botanist classifies tomatoes as fruits~-- they develop from the ovary of a flowering plant and contain seeds. This classification projects: knowing that tomatoes are fruits lets the botanist predict ripening patterns, seed dispersal mechanisms, and responses to plant hormones. The category \mention{fruit} supports reliable induction for botanical purposes.

A chef classifies tomatoes as vegetables~-- savoury, used in main courses, paired with salt rather than sugar. This classification also projects: knowing that tomatoes are culinary vegetables lets the chef predict flavour pairings, cooking methods, and menu placement. The category \mention{vegetable} supports reliable induction for culinary purposes.

Neither classification is wrong. They're not even in conflict. They're \emph{different HPCs} that happen to have overlapping extensions. The botanist's \mention{fruit} and the chef's \mention{vegetable} are each maintained by mechanisms appropriate to their domain~-- reproductive biology for one, flavour chemistry and culinary tradition for the other. Each projects reliably within its field.

The tomato problem is a problem only if you assume projectibility is absolute~-- that a category either projects or doesn't, full stop. Once you recognize that projectibility is field-relative, the problem dissolves. What remains is the work of specifying which category projects for which purposes.

\subsection{Proper nouns and proper names}
\label{sec:6:proper-nouns-names}

Linguistics has its own tomatoes. Consider the distinction between \term{proper noun} and \term{proper name}.

A semanticist works with \term{proper names}: expressions that refer directly to individuals without descriptive content, that are rigid designators (picking out the same individual across possible worlds), and that create referential opacity (\enquote{Lois believes Superman can fly} doesn't entail \enquote{Lois believes Clark can fly}). These properties cluster because of the cognitive and communicative functions names serve: tracking individuals across contexts requires stable reference without shifting descriptive content.

A syntactician works with \term{proper nouns}: words that head nominal projections, resist articles in certain languages, trigger particular agreement patterns, and fill argument slots. These properties cluster because of distributional pressures: words that behave similarly in one syntactic environment tend to behave similarly in others.

The extensions overlap substantially~-- most expressions that are proper names are also proper nouns. But the overlapping extension doesn't mean they're the same category. They're different HPCs, maintained by different mechanisms, projectible for different purposes.

\begin{table}[t]
\centering
\caption{Two categories, overlapping extension}
\label{tab:proper-noun-name}
\begin{tabular}{lll}
\toprule
\textbf{Category} & \textbf{Field} & \textbf{What projects} \\
\midrule
Proper name & Semantics & rigid reference, opacity, individual-tracking \\
Proper noun & Syntax & heads NP, fills argument slot, triggers agreement \\
\bottomrule
\end{tabular}
\end{table}

A syntactician \emph{knows} that \mention{Brett} is a proper name. But that semantic fact doesn't project for syntactic purposes. What projects syntactically is the distributional chain: \mention{Brett} heads a nominal phrase $\rightarrow$ fills a subject slot $\rightarrow$ triggers third-person singular agreement. The syntactician can reliably predict that novel proper nouns will behave distributionally like familiar ones. The proper-name status is real but orthogonal to that prediction.

This isn't esoteric. Every introductory syntax course teaches students to distinguish \enquote{what a word means} from \enquote{how it behaves}. What hasn't been articulated is why this distinction exists: because meaning and behaviour are tracked by different mechanisms, and different mechanisms produce different HPCs. The field-relativity of projectibility explains why syntacticians can't just read off predictions from semantics, and vice versa.

\subsection{Why colour doesn't grammaticalise}
\label{sec:6:colour}

The proper-name case stays within linguistics -- two subfields carving the same extension differently. A starker example crosses domains entirely: colour.

Colour is maximally salient. Trichromatic vision evolved because colour predicts things that matter for survival: fruit ripeness, toxicity signals, mate health, camouflage. The warm/cool boundary shows categorical perception -- adults distinguish warm from cool colours faster than they distinguish within either category \citep{holmes2017}. Colour terms partition efficiently across languages, with the warm/cool split emerging early in colour-vocabulary evolution \citep{kay1978}. If any perceptual domain should grammaticalise, colour should.

It doesn't. Noun-classification systems regularly encode animacy, shape, and size -- but never colour. No documented language has verb agreement triggered by whether the subject is warm- or cool-coloured. The warm/cool distinction is robust, salient, and cross-linguistically stable in the lexicon. Yet it's entirely absent from closed-class morphology \citep{seifart2010}.

\citet{prasertsom2026} tested whether this gap reflects domain-specific constraints on grammar -- a hard-wired filter excluding colour from the set of possible grammatical features -- or something more general. Their experiments compared animacy-based and colour-based noun-class learning in an artificial language. Participants learned both, but animacy-based classes were learned better. More strikingly, when the input was ambiguous between animacy and colour as the classification basis, participants overwhelmingly inferred animacy -- 77.5\% generalised to animacy, nearly half of them categorically.

This bias isn't grammar-specific. In a non-linguistic sorting task, the same preference appeared: participants sorted images by animacy rather than colour, even when the experimenters manipulated within-category similarity to favour colour. The bias persisted across three stimulus sets designed to progressively disadvantage animacy.

What drives the asymmetry? Not salience -- colour is as perceptually salient as animacy. The answer lies in predictive structure. Knowing something is animate predicts a cluster of other properties: self-initiated motion, goal-directedness, organic composition, susceptibility to certain event roles. These predictions hold regardless of what specific entity you're considering. Knowing something is red predicts little beyond its surface appearance -- and what it does predict (ripeness, toxicity) is object-relative. Red means different things for apples, frogs, and traffic lights.

\citet{prasertsom2026} confirmed this computationally. They extracted word embeddings for 472 frequent physical nouns from child-directed speech and clustered them by animacy versus colour. Animacy-based clusters were more compact and more distinct; logistic classifiers learned animacy categories faster and generalised better to unseen nouns -- without any built-in knowledge of animacy. The distributional structure of language itself encodes the asymmetry.

This is purpose-relative projectibility across domains. Colour is projectible \emph{for ecological purposes}: predicting edibility, danger, health. The mechanisms stabilising colour categories are perceptual and action-guiding -- they evolved to support decisions about what to eat, avoid, or approach. But grammar serves different purposes: argument realisation, reference tracking, event-structure encoding. Animacy predicts properties relevant to those purposes; colour doesn't.

The upshot isn't that colour categories are fake or that grammatical categories are special. Both are HPCs, maintained by mechanisms appropriate to their domains. What differs is the domain of projectibility. Evolution gave us colour vision because colour projects for survival-relevant inferences. It didn't give us colour-based agreement because colour doesn't project for grammatical inferences. The same extension -- red things, warm-coloured things -- supports robust categorisation in one domain and fails to support it in another.

This extends the proper-name pattern. \term{Proper name} projects for semantic purposes; \term{proper noun} projects for syntactic purposes. \term{Warm-coloured} projects for ecological purposes; nothing projects it for grammatical purposes -- so nothing grammaticalises. The framework doesn't multiply categories recklessly; it asks what cluster of properties is maintained by what mechanisms, and whether that cluster projects for the questions you're asking. Chapter~\ref{ch:lexical-categories} returns to animacy in its analysis of noun/verb stability.


\subsection{Preview: Part III as demonstration}
\label{sec:6:preview-part-iii}

This pattern~-- overlapping extensions, distinct HPCs, field-relative projectibility~-- structures the case studies in Part~III.

Chapter~\ref{ch:countability} shows that \term{countability} decomposes into semantic individuation (boundedness, discrete enumeration) and morphosyntactic count-marking (plural inflection, quantifier selection). \mention{Furniture} individuates semantically~-- you can count chairs~-- but patterns morphosyntactically as mass. The semantic and morphosyntactic clusters are maintained by different mechanisms and project for different analytical purposes.

Chapter~\ref{ch:definiteness-and-deitality} shows that definiteness and deitality are distinct HPCs with overlapping extensions. \term{Definiteness}~-- identifiability, uniqueness, familiarity~-- projects for semantic purposes. \term{Deitality}~-- the morphosyntactic properties that pattern with definite articles~-- projects for syntactic purposes. The literature's confusion about \enquote{weak definites} and \enquote{generic definites} arises from treating these as one category when they're two.

Chapter~\ref{ch:lexical-categories} shows that the noun/verb contrast is crosslinguistically stable because both semantic and morphosyntactic mechanisms reinforce it, while adjective categories vary because the mechanisms don't align as tightly.

The framework doesn't multiply categories recklessly. It asks, for each analytical purpose: what cluster of properties is maintained by what mechanisms, and does that cluster project for the questions you're asking? Sometimes the answer is a familiar category; sometimes it's a refinement of one; sometimes it's a recognition that what looked like one category was two.

\subsection{The discipline: three checks}
\label{sec:6:three-checks}

The slogan~-- \emph{profile, stabilized by mechanisms, projectible relative to purposes}~-- maps onto three diagnostic checks:

\begin{enumerate}
    \item \textbf{Cluster check.} Does property covariance hold across samples and contexts? If the properties don't cluster, there's no profile to explain.
    \item \textbf{Homeostasis check.} Can we identify perturbations where the cluster reconstitutes (or fails)? If we can't, we haven't identified the mechanism.
    \item \textbf{Projectibility check.} Are there counterfactual-supporting inferences in new contexts? If learning about one member doesn't tell you about others, the category isn't earning its keep.
\end{enumerate}

Crucially, these checks can yield different answers for different fields. A category might pass all three for syntax and fail the projectibility check for semantics. That's not a defect of the framework~-- it's the framework working. The checks aren't absolute; they're indexed to purpose.

This discipline guards against two temptations. First, the essentialist temptation: treating one field's category as the \enquote{real} one and others as derivative. If proper names are semantically fundamental, proper nouns must be \enquote{just} the syntactic reflection of semantic reality. But the mechanisms are different; neither is derivative. Second, the nominalist temptation: treating categories as arbitrary conventions because different fields carve differently. But the carving isn't arbitrary; each field's categories are maintained by mechanisms appropriate to that field's explanatory goals.


\section{The epistemic payoff}
\label{sec:6:epistemic-payoff}

The aspect case shows that even a descriptively real category can fail to project if its definition misaligns with its maintaining mechanisms. This misalignment clarifies a classic problem in the philosophy of science.

Liu Cixin's turkey parable captures the problem of induction with dark precision:

\begin{quote}
Every morning on a turkey farm, the farmer comes to feed the turkeys. A scientist turkey, having observed this pattern to hold without change for almost a year, makes the following discovery: \enquote{Every morning at eleven, food arrives.} On the morning of Thanksgiving, the scientist announces this law to the other turkeys. \citep[ch.~6]{liu2008}
\end{quote}

The turkey's law is perfectly confirmed by all available evidence. The problem isn't the evidence; it's that the law isn't grounded in mechanism. The farmer's purpose~-- invisible to the turkey~-- determines when the correlation breaks. Had the turkey understood \emph{why} food arrives (fattening for slaughter), it would have predicted its own demise rather than its next meal.

Nelson Goodman's \mention{grue} problem makes the same point in philosophical dress. Goodman's riddle: emeralds examined before time $t$ are green; emeralds examined after $t$ are blue. Define \mention{grue} as \enquote{green if examined before $t$, blue otherwise}. Every emerald we've ever observed is grue. So why don't we project \mention{grue} to unexamined emeralds?

Goodman's own answer invoked entrenchment: \mention{green} is projectible because it's been projected successfully in the past. \mention{grue} isn't because it hasn't. The circularity is deliberate~-- projectibility is bootstrapped from track record.

This observation shaped a tradition. \citet{quine1969} argued that the success of induction presupposes natural kinds: we project properties because we assume the instances we've observed are \enquote{of a kind} with those we haven't. \citet{kornblith1993} went further, arguing that induction works precisely because natural kinds exist in the world~-- the clustering of properties in those kinds underwrites our ability to learn from experience. On this view, projectibility isn't just a pragmatic feature of our language; it's evidence that we've latched onto something real.

The maintenance view offers an elaboration. \term{Green} is projectible because emeralds share a mechanism that produces greenness: chromium traces interact with light in stable ways. There's no mechanism that produces grueness; there's nothing about emeralds that makes them switch from green to blue at time $t$. Projectibility tracks mechanism, not just predicational habit.

For linguistic categories, the same logic applies. \term{Noun} is projectible because mechanisms like acquisition, entrenchment, and functional pressure keep nominal properties clustering together. A pseudo-category like \mention{nerboun} (noun if acquired before age 5, verb otherwise) isn't projectible because no mechanism produces that pattern~-- there's nothing about language acquisition that would cause a switch at age 5.

A category can look like a good bet~-- its definition correlates with usage, its label is entrenched~-- and still turn out to be a turkey.

\subsection{Is projectibility interest-relative?}
\label{sec:6:interest-relativity}

\citet{craver2009} and \citet{onishi2022} argue that any mechanism-based account inherits context-dependence. Which mechanism you attend to, at what level of abstraction, with what boundaries~-- all depend on your explanatory goals. If so, the maintenance view answer to Goodman looks circular: a category is projectible relative to the mechanism you're interested in, and the mechanism you're interested in is whichever one makes the category projectible.

The key distinction is between choosing a level because it answers your question, and choosing a level because it privileges your category. A pedicab can be explained by engineering (frame geometry, gear ratios) or by physics (forces, friction, momentum). Both levels are real; both describe genuine causal structure. Your question selects the level. But the causal structure at that level determines whether your answer is correct. Interest picks the question; it doesn't fabricate the mechanism that answers it.

This is precisely what went wrong with the turkey. Its interest was survival, but it coarse-grained at the wrong level: time of day rather than time of year. The correlation was real at one level (11 AM $\rightarrow$ food) but collapsed at another (Thanksgiving $\rightarrow$ slaughter). The turkey's interest didn't invent the mechanisms; it just selected the wrong one to track.

For linguistic categories, the same logic applies. If your question is ``what triggers perfective here?'' the answer lives at the cue-structure level, not the semantic-definition level. Both levels exist; the semantic level just doesn't answer the production question. The aspect case shows the stakes: if your goal is to predict corpus distributions, or even to teach people to speak Polish, the textbook mechanism (semantic boundedness) is the wrong one~-- it predicts imperfective well and perfective poorly. If your goal is to predict native-speaker gap-filling, the lemma-concrete mechanism is the right one~-- it outperforms aspect-aware models. The prediction either succeeds or fails. That's the empirical constraint on which mechanism matters.

Conventionalism can't explain why some mechanisms predict and others don't. The maintenance view can: the mechanisms that predict are the ones that actually maintain the cluster. Interest selects among real causal structures; it doesn't invent them. This is what \citet{carrollparola2024} mean by emergence: coarse-grained descriptions that support accurate predictions despite discarding micro-level information. The key is coarse-graining \emph{in the right way}~-- throwing away arbitrary information destroys predictability, but discarding the right information preserves it.

\citet{lemeire2018} argues that no purely epistemic theory~-- one that defines natural kinds solely by their inductive usefulness~-- can account for naturalness. If all we require is that a category support successful predictions, what distinguishes a natural kind from a merely convenient grouping? The objection is serious, and it's what the maintenance view is designed to answer. Projectibility alone is too permissive; what's needed is the right \emph{kind} of projectibility~-- the kind that comes from genuine homeostatic mechanisms rather than accidental correlations. The turkey's law was projectible until Thanksgiving; a mechanism-grounded law would have predicted the farmer's purpose. The maintenance view doesn't abandon epistemic criteria; it requires that they be grounded in causal structure. Projectibility is evidence of mechanism, not a replacement for it.\footnote{\citeauthor{khalidi2013}'s (\citeyear{khalidi2013}) ``nodes in causal networks'' account illustrates the difference. NPIs, for instance, are causally grounded in one sense~-- they share semantic sensitivity to negative contexts. What they lack is the homeostatic mechanism that would make them an HPC kind. They're stable at equilibrium rather than dynamically maintained: balls sitting at the bottom of a trough, not tops that must be spun to stay upright.}

This gives us a robustness criterion for mechanistic kinds. A genuine mechanistic kind~-- as opposed to a convenient label~-- should exhibit \emph{learning transfer}, \emph{intervention stability}, and \emph{cross-context generalisation}. Train on one subset, test on another: does it transfer? Intervene on the mechanism: does the pattern shift as predicted? Apply to a new context: does the generalisation hold? Labels without mechanisms should fragment under these pressures; mechanisms should persist. The computational evidence in this chapter~-- lemma-concrete models transferring to unseen verbs, cue--outcome associations generalising across tense frames~-- is exactly this kind of robustness test. The realism isn't permissive (``whatever predicts is real''); it's constrained by stability under perturbation.

Once interests are fixed by a task, we can ask how strongly different categories support that task. This is the next implication of mechanistic grounding: projectibility comes in degrees. (Recall that field-relative projectibility~-- §\ref{sec:6:field-relative}~-- is a distinct point: the same extension can be carved by different HPCs for different fields. What follows concerns degrees of projectibility \emph{within} a single field.)

\subsection{Degrees of projectibility}
\label{sec:6:degrees-projectibility}

Not all categories are equally projectible. The framework expects a gradient, and the evidence supports it.

At one extreme: high-frequency, highly entrenched categories where the mechanisms are strong and consistent. English determinatives are a case: a closed class, stable across speakers, predictable in distribution. Learn \mention{each} and you can project to \mention{every} with high confidence. The mechanisms (entrenchment, functional specificity) are tight enough that the category approaches definitional coherence~-- the mechanisms are so strong that they produce uniform clustering.

At the other extreme: low-frequency, loosely maintained categories where the mechanisms are variable or in flux. Nonce formations, idiolectal forms, constructions undergoing change~-- these are less projectible because the mechanisms haven't stabilized. Knowing about one instance tells you less about others.

The middle ground is where the action is. Within a language, synchronically, major open classes~-- nouns, verbs, adjectives~-- are projectible on average but variable at the margins. You can project from typical nouns to novel nouns with high confidence; you can project from \mention{fun} to other adjective-noun boundary cases with less. The mechanisms are strong enough to produce robust clustering at the core but not strong enough to determine the periphery.

The prediction is testable: core category members~-- high-frequency, prototypical, functionally central~-- should elicit consistent judgments; peripheral members~-- low-frequency, boundary-straddling, functionally ambiguous~-- should elicit variable ones. The variance isn't noise; it's the signature of weak entrenchment.

Recent experimental work confirms the pattern. In grammaticality judgments for Dutch syntax, peripheral structures are correctly identified only 57\% of the time (SD $\approx$ 0.27), while core structures are correctly identified 90\% of the time (SD $\approx$ 0.09)~-- the variance triples at the periphery \citep[Table~2]{favier2021}. Similarly for syntactic variants indexed to verb frequency: low-frequency verbs elicit higher acceptance of violations (a fourfold increase in error rates: 6.58\% vs.\ 1.58\%), because weak entrenchment permits wider variation in what speakers treat as grammatical \citep{sassenhagen2018}. In morphology, the pattern is starker still: high-frequency English adjectives elicit near-unanimous agreement on comparative form, while low-frequency and nonce adjectives split speakers \citep{grazianoking2005}.

This is what the maintenance view predicts. Where mechanisms are strong and consistent, judgments converge; where mechanisms are weak or variable, judgments diverge. The variance tracks the strength of the causal structure. Projectibility isn't all-or-nothing; it's graded by entrenchment. Crucially, the variance isn't just about the items; it's about the speakers. Low-frequency forms are ``weakly entrenched'' only in aggregate~-- for any given form, some speakers have encountered it often, others rarely, others never. What looks like category fuzziness at the population level is actually speaker-by-speaker variation in experience \citep{dabrowska2012}. This reinforces the maintenance account: categories fail to project uniformly because the maintaining mechanisms haven't operated uniformly across the population.


\subsection{What the framework offers}
\label{sec:6:what-framework-offers}

The argument so far has been negative: traditional definitions don't ground projectibility; mechanisms do. But this raises a question for researchers who already study mechanisms. If you're already tracking entrenchment, distributional learning, alignment, or functional pressure, what does the maintenance view add? Isn't this just new terminology for what you were doing anyway?

The answer is that the framework offers something beyond the mechanisms themselves: an account of what the mechanisms are \emph{for}. Most mechanistic research is descriptive in a specific sense~-- it shows how patterns emerge, stabilize, and change. What it often lacks is an explicit ontology. Are the categories that emerge from these mechanisms \emph{real}, or are they convenient fictions? Are they features of speakers' minds, of the speech community, or merely of the analyst's framework? The maintenance view provides an answer: categories are real to the extent that they're maintained by consistent mechanisms. The mechanisms don't just produce the patterns; they \emph{constitute} the categories as natural kinds.

This matters for several reasons.

First, it legitimises mechanistic work as theory, not just description. A sceptic might object that studying entrenchment or alignment is interesting but atheoretical~-- mere data-gathering that falls short of explanation. The maintenance view says: no. The mechanisms \emph{are} the theory. Understanding how categories are maintained is understanding what makes them real. This is analogous to recognizing that natural selection isn't ``just'' a description of breeding patterns but the actual explanation of adaptation.

Second, it provides cross-camp coherence. Researchers studying entrenchment, alignment, distributional learning, and iterated transmission are often working in different sub-fields with different terminologies. The maintenance view offers a unifying frame: all are studying maintenance mechanisms for the same kind of category. This isn't eclecticism~-- it's convergence. Different instruments trained on the same phenomenon. The framework doesn't adjudicate between mechanisms; it says that \emph{whichever} mechanisms actually maintain the cluster are the ones that matter. The question becomes empirical: which mechanisms predict? Chapter~\ref{ch:what-changes} shows how agent-based modelling provides one way to test such predictions computationally.

Third, it reorients methodology. The maintenance view makes prediction the success criterion: does the mechanism predict behaviour? This changes what counts as evidence. Individual variation stops being noise to be averaged away and becomes signal: if different speakers show different patterns, that tells you something about how tightly the mechanisms are operating. The gradient nature of projectibility~-- strong at the core, weak at the periphery~-- is a feature of maintenance, not a defect of the category.

Fourth, it offers category realism without essentialism. Many researchers working with mechanisms are implicitly anti-realist about categories~-- they treat category labels as convenient shorthand, not as picking out real kinds. The worry is understandable: if there are no essences, what makes categories real? The maintenance view provides the missing piece. Categories are real \emph{because} of mechanisms, not despite lacking essences. The mechanisms do for categories what essences were supposed to do: explain why members resemble each other, why learning about one tells you about others, why the category is projectible. You don't need to choose between realism and mechanism; mechanism \emph{underwrites} realism.

Fifth, it clarifies the relationship between historical origin and synchronic maintenance. The volcanic island metaphor applies here: what built a category may not be what maintains it. Researchers studying grammaticalization, semantic drift, or language change often face a puzzle: if categories evolved for one reason, but now function differently, what's their current status? The framework says: study the current mechanisms. Whether or not the historical origin matches the current maintenance, it's the current mechanisms that determine projectibility. You can trace the genealogy without claiming that genealogy is destiny.

None of this requires abandoning existing research programmes. The mechanistic work continues; what changes is its framing. The maintenance view shows how categories can be both analyst-labelled and grounded in real causal structure. The work you're doing isn't preliminary; it's the payoff.

\bigskip

We can now answer the question that opened the chapter. Mr.~Tagomi needed to know which world he was in; learners of Polish need to know which verb form to use. Both rely on projectibility. Why should learning about one instance tell us anything about others?

Because the same mechanisms that shaped the instance you learned are shaping the instances you haven't. Categories maintained by consistent mechanisms produce consistent members. The consistency underwrites induction.

This is the epistemic payoff~-- what the good bet wins. HPC kinds are categories you can learn from, categories with causal structure. The mechanism that makes a word a noun also makes other nouns. The mechanism that biases a verb toward perfective also biases similar verbs. The mechanism that entrains a speaker to one usage pattern entrains the same speaker to related patterns.

Projectibility isn't metaphysically guaranteed. A proposed grouping can fail to project if its characterization doesn't match the maintaining mechanisms~-- as aspect-abstract fails. A proposed grouping can fail to project if the mechanisms are too weak or too variable~-- as nonce formations fail. In either case, the grouping isn't a category but a \term{class}~-- a label without the causal structure to back it up. But where the mechanisms are real and consistent, projectibility follows. That's the test: does learning about instances let you project to the kind? If yes, the mechanisms are real. If no, look elsewhere for the causal structure.


The label names the island, not the volcano. But we've talked about mechanisms as if they were self-explanatory. They aren't. What exactly maintains the island? What processes stabilize the clustering, ensure that new instances resemble old ones, transmit the pattern across speakers and generations? The next chapter opens the black box. We'll trace the mechanisms in detail~-- acquisition, entrenchment, alignment, transmission, functional pressure~-- and ask what each contributes to the stability of linguistic kinds. Only then can we ask: under what conditions do mechanisms fail?

Part~III then returns to field-relative projectibility with three extended case studies. Countability, definiteness, and word classes each demonstrate the pattern developed here: categories that decompose into semantic and morphosyntactic HPCs, maintained by distinct mechanisms, projectible for different analytical purposes. The framework isn't abstract philosophy; it's an operational tool for understanding why familiar categories behave as they do.
