% Chapter 7: The Stabilisers
% Complete rewrite 2025-12-08: biological explanatory style throughout

\chapter{The Stabilisers}
\label{ch:stabilisers}

\epigraph{The general rule would establish itself insensibly, and by slow degrees, in consequence of that love of analogy and similarity of sound, which is the foundation of by far the greater part of the rules of grammar.}{Adam Smith, \textit{Considerations Concerning the First Formation of Languages} (1761)}

This chapter answers the question that the previous three have been building toward: what keeps grammatical categories stable? Adam Smith saw part of the answer in 1761: grammatical rules \enquote{establish themselves insensibly, and by slow degrees.} What we can now add is the causal machinery~-- identifying which stabilising processes, operating at which timescales, produce that gradual consolidation. Rather than enumerate mechanisms abstractly, the chapter develops two case studies in depth: the emergence of new quotative markers and the licensing of independent relative \mention{whose}. Both show the same structure: a cluster of properties maintained by a braid of stabilisers, with causal depth, mereological structure, and reciprocal maintenance at every level. A deeper point emerges: the distinction between \enquote{category} and \enquote{mechanism} is perspectival, not ontological~-- mechanisms are themselves categories, maintained by further mechanisms, all the way down. The chapter closes with operational tests for mechanism claims, a discussion of what the framework commits us to, and a reminder that the maintenance view refactors existing research rather than replacing it.


\section{The cluster}
\label{sec:7:the-cluster}

Start where immunologists start: with the cluster.

When a biologist asks what a macrophage is, they don't look for a definition. They look for properties that tend to co-occur. A macrophage is picked out by a constellation: typical functions (phagocytosis, antigen presentation), marker profiles, morphologies, response tendencies, developmental origins. None of these is strictly necessary and sufficient. Some macrophages don't phagocytose; some share markers with dendritic cells; morphology varies with tissue context. But the properties cluster reliably enough to make the category useful~-- to make predictions about new instances, to design experiments, to coordinate research programmes.

This is exactly the situation for grammatical categories.

Take nouns. What properties tend to co-occur? Items we call nouns typically take determiners (\mention{the dog}, \mention{a problem}), pluralise (\mention{dogs}, \mention{problems}), function as heads of phrases in argument positions, refer to entities or entity-like abstractions, and enter into modification relations with adjectives. None of these is strictly necessary: \mention{cattle} doesn't pluralise; \mention{the honesty} is rare; names resist determiners in English; Mandarin nouns don't pluralise the way English nouns do. And yet typologists recognise something noun-like in both systems.

The question is not: what is the essence of noun-ness? We tried that. It generated boundary disputes and competing definitions but no stable resolution.

The question is: what keeps the cluster clustered? Not definition, but maintenance.

Before answering, a clarification about what kind of kinds we're discussing. Grammatical categories are neither fully mind-independent natural kinds~-- like chemical elements or biological species~-- nor purely conventional human kinds that exist only because we agree they do, like money or traffic laws. They occupy a middle position: real enough to support induction, socially embedded enough to change under pressure. The mechanisms that maintain them are cognitive, social, and physical. The clustering they produce is stable enough, cross-contextually robust enough, that predictions based on category membership reliably succeed. This is the position the chapter defends: grammatical categories are mechanism-maintained kinds whose reality is indexed to their inductive utility, not to definitional necessity.

A word on \enquote{mechanism} as this book uses it. In molecular biology, a mechanism is an organised causal complex with identifiable components: the ribosome, the spliceosome, the gene regulatory network. For grammatical categories, the stabilisers are less crisply bounded~-- they include processing biases, acquisition pathways, social indexing, transmission dynamics. But the constraint is the same: a mechanism posit earns its keep by specifying component processes whose interactions produce the target phenomenon. If you can't say what sub-processes combine to yield the clustering, and what would happen if one were disrupted, you don't yet have a mechanism~-- you have a label with causal pretensions. The term is elastic enough to span cognitive and social scales, but not so elastic that any correlation gets to call itself mechanistic.

A related term: \emph{stabiliser}. Where \enquote{mechanism} emphasises causal structure, \enquote{stabiliser} emphasises the functional role~-- what keeps the cluster clustered. A stabiliser is a mechanism insofar as it has causal depth, but the term foregrounds maintenance rather than mere causation. Something counts as a stabiliser if removing it would change the clustering~-- if the category would fragment, drift, or dissolve. A mere correlate~-- something that co-occurs with the category but doesn't contribute to its maintenance~-- is not a stabiliser. The distinction matters: the chapter will propose stabilisers and then test whether they're genuinely load-bearing or merely co-present.


\section{Stabilisers at multiple scales}
\label{sec:7:stabilisers-at-scales}

When immunologists ask what maintains a cell type, they don't point to a single cause. They narrate a multi-level story. The same style of explanation applies to grammatical categories.

A clarification about what kind of transfer this is. I'm not claiming homology~-- that grammatical categories are like cell types in the same way that mammalian limbs are like each other, sharing a common causal origin. I'm claiming analogy of explanatory form: the same \emph{style} of multi-level stabilisation story can be useful in both domains. Cell biologists ask what mechanisms maintain the macrophage phenotype; we ask what mechanisms maintain the noun category. The question structure is the same; the mechanisms themselves are domain-specific. This is methodological borrowing, not ontological equation. The biological parallel earns its keep if it makes linguistic phenomena more visible and testable~-- not if it implies that grammars are literally organisms.

What the biological template provides is visibility: it lets us see variation as activation rather than noise, boundaries as dynamic rather than definitional, and stability as achieved rather than given. Without this framing, gradient membership looks like failed classification; with it, gradient membership becomes evidence about which mechanisms are operating and where.

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}p{2.8cm}p{5.5cm}p{5.5cm}@{}}
\toprule
\textbf{Scale} & \textbf{Biology} & \textbf{Linguistics} \\
\midrule
Dynamical basins & \textbf{Gene regulatory networks} produce attractor states~-- configurations the cell tends to settle into. The basins are emergent from ongoing interaction and exist only as long as stabilising processes continue. & \textbf{Cognitive architectures and processing biases} produce attractor-like states. A construction frequent enough becomes entrenched~-- produced as a unit rather than assembled. This is dynamical, not definitional. \\
\addlinespace
Developmental trajectory & \textbf{Developmental lineage} constrains which basins are reachable. A cell's history matters: what precursors it passed through, what signals it received at critical windows. & \textbf{Acquisition pathways and learning biases} constrain what a speaker can learn. Order of acquisition matters. Early-learned patterns anchor later ones. Sensitive phases exist where input has disproportionate effect. \\
\addlinespace
Microenvironmental modulation & \textbf{Microenvironmental signalling}~-- local cytokines, tissue context~-- pushes cells into different regions of the same basin, producing variation within the type. & \textbf{Discourse context and pragmatic ecology} push tokens into different regions of the distributional space. Same category, different activation state. Variation is expected, not noise. \\
\addlinespace
Reciprocal feedback & \textbf{Functional feedback}: what the cell does alters its microenvironment, which sustains or shifts its state. The stabilisation is not one-way. & \textbf{Functional feedback}: what speakers do with categories alters input to the next generation, which alters what categories stabilise. Usage facilitates reconstruction; facilitated patterns shape usage. \\
\bottomrule
\end{tabular}
\caption{Multi-level stabilisation: biology and linguistics in parallel.}
\label{tab:stabiliser-parallel}
\end{table}

This is already a richer picture than \enquote{a noun is defined by such-and-such properties}. The definition tells you what the cluster looks like at a moment. The stabilising story tells you why it persists.


A caveat about the analogy. The four-level story is a heuristic, not a template. Different categories are maintained by different braids of mechanisms; the exact mapping varies. Quotatives, as we'll see, involve processing economy, social indexing, and transmission dynamics~-- mechanisms that cross-cut the four levels rather than mapping onto them one-to-one. The point is multi-level stabilisation, not exact correspondence. What the biological parallel provides is a style of explanation~-- look for mechanisms at multiple timescales, expect reciprocal feedback~-- not a fixed inventory.

The case studies that follow show how this works in practice~-- first for quotatives, then for filler-gap constructions. I'm choosing these two deliberately: one socially vivid (quotatives spread through youth networks), one more syntactic (filler-gap licensing depends on information structure). The same explanatory template operates at very different grain sizes. If the framework works for both, it's not just sociolinguistics with a new label.


\section{Variation as activation states}
\label{sec:7:variation-activation-states}

The immunologist's key move: variation within a category is not embarrassing fuzziness to be explained away. It's the expected signature of a kind that is maintained by context-sensitive mechanisms.

A macrophage in inflamed tissue shows different markers than a macrophage in healthy tissue. Both are macrophages. The difference is activation state~-- which signals the cell has received, which region of the phenotypic space it currently occupies. The category is real; the variation is real; both are explained by the stabilising dynamics.

Apply this to linguistic categories.

A worked example makes the point concrete. Consider \mention{fast}. In \mention{a fast car}, it's an adjective~-- attributive, modifying a noun. In \mention{she ran fast}, it's an adverb~-- modifying the verb, no \mention{-ly} suffix. Same lexeme, different syntactic behaviour, different category membership. Is \mention{fast} an adjective or an adverb?

The essentialist answer: it must be one or the other, or else homonymous (two lexemes, same form). The prototype answer: it's a gradient case, partly adjective, partly adverb, with no fact of the matter about which it ``really'' is.

The activation-state answer: \mention{fast} occupies a region of the state space where both adjectival and adverbial patterns are accessible. Which pattern activates depends on the syntactic frame. In attributive position, the frame activates adjectival agreement patterns (even in languages with overt agreement); in post-verbal position, the frame activates adverbial patterns. The category is real~-- adjectives and adverbs are distinct basins, maintained by different mechanisms. But \mention{fast} sits in an overlap region where the input signal (syntactic context) determines which basin the token falls into.

This reframes the \enquote{dual category} problem. The essentialist answer: it must be one or the other, or else homonymous (two lexemes, same form). The prototype answer: it's a gradient case, partly adjective, partly adverb, with no fact of the matter about which it \enquote{really} is. The maintenance answer, building on the dynamic discreteness of Chapter~\ref{ch:discrete-from-continuous}, is different. The question isn't which category \mention{fast} belongs to. The question is which mechanisms are activated by which inputs. In the adjective basin, the form takes comparison (\mention{faster}, \mention{fastest}) and attributive position; in the adverb basin, it takes post-verbal position and modifies verbs. Both are available; context determines activation. (A caution: \enquote{activation state} is a useful way of describing variability under stabilising pressures, not a new single-factor key. It's a description of the dynamics, not a replacement essence.)

Now generalise. Consider independent relative \mention{whose}~-- forms like \mention{a woman whose was straight} or \mention{those whose are not}. Is this construction grammatical in English? Textbook accounts say no: Hankamer and Postal's (1973) rejection was widely accepted. But attestations exist, stretching back to Middle English \autocite{reynolds2024whose}.

The immunologist's framing reinterprets the question. The construction may be grammatical~-- maintained by the same filler-gap mechanism that serves interrogatives and other relative constructions~-- but only under specific licensing conditions: contrastive parallelism, deictic anchoring, structural integration. In other conditions, the possessum isn't recoverable, and the construction crashes. The category boundary marks the region where pragmatic licensing determines whether the mechanism can succeed.

This is not a dodge. It's a prediction: constructions in licensing-dependent regions should show high inter-speaker variation, sensitivity to discourse context, and apparent paradigm gaps that aren't really gaps. Section~\ref{sec:7:filler-gap-whose} develops the case.

A clarification about two kinds of variation. Some apparent boundary cases are \emph{within-speaker} shifts~-- the same person using \mention{fast} adjectivally in one context and adverbially in another. These are activation-state differences: one grammar, multiple accessible patterns. Others are \emph{between-speaker} differences~-- not everyone has entrenched the same patterns to the same depth. (Independent relative \mention{whose} is an example: some speakers reject it no matter how well contextualised it is.) Speakers with different input histories, different literacy experiences, different interactional ecologies end up with different category boundaries. Both matter. The within-speaker variation shows that categories are context-sensitive; the between-speaker variation shows that they are experience-dependent. Neither is noise. Both are part of the data that a theory of category maintenance must explain.

Individual differences, then, aren`t just noise around the cluster; they're part of the ecology that determines which clusters become stable and which fail to consolidate. A category that stabilises only in speakers with particular exposure profiles is a different kind from one that stabilises uniformly. The former is maintained by mechanisms that not everyone encounters; the latter is maintained by mechanisms that operate across the population. The distinction is stabiliser-relevant.

The same framing applies to aspect in Polish. As §\ref{sec:6:mechanistic-alternative} showed, 90\% of verbs strongly prefer one aspect~-- they're deep in a single basin. The remaining verbs occupy shallower regions where contextual signals matter more. The verbs that require explicit contextual cues to disambiguate are the ones where entrenchment is weaker, where the tense-frame signal has more work to do. That's the activation-state picture applied to grammatical aspect.

The activation-state framing has neural consequences. If categories are maintained by interacting cues rather than definitions, then processing should track graded predictive fit, not all-or-none membership. This is precisely what event-related potentials are good at detecting: the N400 indexes semantic expectation (how well does this item fit the predicted context?), while the P600 indexes structural repair and category conflict (does the parser need to revise its initial commitment?). HPC predicts continuous sensitivity to cue convergence~-- the more cues align, the stronger the facilitation; the more they conflict, the larger the cost. Classical definitional categories predict sharper violation profiles: items either belong or they don't, and borderline cases should look like noisy members of a discrete class. Under HPC, borderline items should look like systematic mixtures of cue-weighting~-- intermediate or context-sensitive neural profiles, not random noise. That's a testable contrast.



\section{One case in depth: the emergence of new quotatives}
\label{sec:7:one-case}

Rather than enumerate mechanisms abstractly, let's trace the stabilising story for one category: the quotative marker.

Quotatives introduce reported speech, thought, gesture, or sound. The functional need to distinguish the narrator's voice from the character's is presumably as old as narrative itself. But when we look across typologically unrelated languages, we find a striking convergence in recent history: in the late twentieth century, new quotative forms emerged or expanded~-- forms with a distinctive profile that spread through similar populations and stabilised through similar mechanisms.

The English case is well documented, and the chronology reveals the dynamical logic: what emerges first, what locks in later, and which contexts serve as incubators.

\textcite{butters1982} first noted \mention{be like} in American English in 1982, observing its use to report unuttered thoughts: \mention{I was like, `Let me live, Lord'}. \textcite{ferrarabell1995} hypothesised that the form originated with first-person subjects and internal dialogue before expanding to third-person subjects and direct speech. The incubator was informal peer narrative~-- storytelling among friends, where enactment matters more than accuracy. By the mid-1990s, the form had spread beyond that niche. \textcite{tagliamontedarcy2004} tracked apparent-time data from Canadian English: in 1995, speakers aged 18--27 used \mention{be like} for 13\% of quotative tokens; by 2003, speakers aged 17--19 used it for 63\%~-- a fivefold increase in under a decade. The same cohort, re-sampled seven years later, showed \mention{be like} rising from 13\% to 31\% as they aged into their thirties \autocite{tagliamontedarcy2007}. This is not age-grading; it's real-time change, with each generation carrying its quotative inventory into adulthood. What began as a micro-regularity in peer narrative became a meso-level entrenchment in a generation's speech, and then a macro-level category expectation that shapes input to the next generation.

German shows a parallel trajectory. \textcite{golato2000} analysed \mention{und ich so} (`and I'm like') in video-recorded conversations, documenting its function in storytelling: introducing punchlines, sound effects, gestures, and verbal enactments~-- the same profile as English \mention{be like}. The form was attested in youth speech by the late 1990s \autocite{androutsopoulos1998} and has since become established among younger German speakers, though it remains more register-restricted than its English counterpart.

Japanese \mention{tte} (reduced from \mention{to itte}, `saying that') functions similarly: a phonologically light form that introduces reported speech, thought, or stance in informal narrative. The pattern extends to Turkish \mention{diye} (converb of \mention{demek}, `to say'), which has expanded from its older quotative functions into increasingly colloquial discourse contexts.

\textcite{buchstaller2014} synthesises the cross-linguistic evidence: the emergence of these innovative quotatives reflects independent development under similar functional pressures, rather than media-driven borrowing. Different sources, different structures, same functional niche, same stabilising dynamics.

This is not coincidence. It's convergent maintenance: independent forms, stabilised by the same mechanisms, producing the same category architecture.

\subsection{The quotative cluster}

What properties co-occur in these new quotatives? The distributional studies reveal a consistent profile.

\textbf{Non-lexical content.} These forms introduce material that goes beyond words: gesture, facial expression, tone of voice, inner monologue. \mention{And I was like} doesn't just report what someone said; it enacts the experience. \textcite{ferrarabell1995} noted that early \mention{be like} tokens disproportionately introduced internal states and non-lexicalised sounds~-- groans, sighs, exclamations~-- before expanding to verbatim-style direct speech. \textcite{golato2000} documented the same pattern for German \mention{so}: it turns reported speech into performance.

\textbf{First-person and present-tense preference.} The forms attach preferentially to first-person subjects and historical-present tense. \textcite{tagliamontedarcy2004} found that in their Toronto data, first-person contexts strongly favoured \mention{be like} over \mention{say}. When speakers narrate, they use these forms to bring the audience into the moment of the original event~-- the vivid first person, the historical present. This reflects a deeper cognitive mapping: the present--past distinction analogises to a close--distant split~-- in time, social relations, and likelihood.

\textbf{Youth association.} In every documented case, younger speakers lead adoption. The apparent-time data are consistent across studies: the highest rates of \mention{be like} appear among speakers under 30; rates decline sharply for speakers over 50 \autocite{tagliamontedarcy2004,tagliamontedarcy2007}. Young women, in particular, tend to be innovative adopters~-- a pattern consistent with the broader sociolinguistic finding that women often lead linguistic change from below \autocite{labov2001}.

\textbf{Register restriction.} The forms are discourse-conditioned: common in storytelling, informal speech, peer conversation; rare in formal registers~-- exactly where we find the so-called \enquote{historical present}. Even as \mention{be like} has spread across age cohorts, it remains suppressed in academic prose, institutional speech, and written genres. German \mention{so} is still more restricted~-- marked as adolescent, rarely encountered in broadcast media.

These properties cluster. A quotative that introduces vivid re-enactment, prefers first person and present tense, spreads through young speakers in informal contexts~-- this is a recognisable type, a cross-linguistically recurring profile.

To make the ecological logic overt: these innovative quotatives occupy a functional niche that older forms leave empty. The niche is \emph{approximate vivid re-enactment in informal narrative}~-- conveying gist, stance, and affect without committing to verbatim accuracy. \mention{Say} implies exact report; the new quotatives disclaim it. The niche opened because narrative speech needs enactment as much as report, and older quotatives didn't serve that function well. The stabilising pressures are the ones that keep any niche occupied: processing economy (light forms win under production pressure), functional fit (forms that serve communicative needs spread), social indexing (forms that mark in-group identity persist), and transmission dynamics (forms acquired in dense peer networks survive into the next generation). What would count as niche collapse? If another form arose that served approximate re-enactment better~-- lighter, more expressive, better indexed~-- the current quotatives would cede territory. We see hints of this already: in some varieties, \mention{be all} briefly competed with \mention{be like} before losing ground. The niche is stable, but the occupants are not guaranteed tenure.

The question is: why does this cluster cluster?

\subsection{Quotative stabilisers}

Why does this cluster persist? The answer lies in a braid of mechanisms, each contributing to the category's stability.

\textbf{Processing economy.} Quotatives of this type are structurally light. Japanese \mention{tte} is a phonologically reduced form of \mention{to itte} (`saying that'); the reduction removes syllables while preserving function. German \mention{so} is a single syllable. English \mention{be like} is syntactically minimal: copula plus predicative, no subordinator, no overt speech verb. Forms that reduce production cost under narrative pressure are used more frequently, entrenched more deeply, and survive transmission. Frequency here is not just a descriptive statistic~-- a count of how often something occurs~-- but a causal pathway: repeated processing of a form makes future processing easier, reduces articulatory effort, and creates expectations that bias subsequent production. The result is a feedback loop: light forms spread because they're easy; spreading makes them easier still. This is a general principle from usage-based linguistics: high-frequency forms resist analogical pressure and attract new tokens \autocite{bybee2006}.

\textbf{Expressive fit.} These quotatives fill a functional niche that older forms leave empty: introducing inner monologue, gesture, and attitude without committing the speaker to verbatim accuracy. \mention{She said} implies exact report; \mention{she was like} implies approximation, enactment, stance. \textcite{ferrarabell1995} documented this as the form's original semantic territory~-- internal states, non-lexicalised sounds~-- before it expanded to canonical direct speech. The looseness is functionally adaptive. Speakers need to convey gist, stance, affect~-- not transcript. Forms that serve communicative needs better than alternatives spread.

\textbf{Acquisition and cohort effects.} Children and adolescents acquire these forms in dense peer networks where the input is frequent, contextually salient, and socially marked. Panel data provide the critical evidence: the same Toronto speakers, tracked over seven years, showed \mention{be like} rising from 13\% to 31\% of quotative tokens as they aged from their twenties into their thirties \autocite{tagliamontedarcy2007}. This is not age-grading (using youth forms only when young); it's lifespan change. Speakers carry their adolescent inventory into adulthood, and their children hear it as ambient input. The result is a cohort effect: each generation's linguistic inventory reflects what was frequent in their formative years.

\textbf{Social indexing.} New quotatives index youth, informality, in-group membership. Using \mention{be like} signals that you are a certain kind of speaker, in a certain kind of register, with a certain kind of audience. This social value is not epiphenomenal; it's a stabiliser. As \textcite{Eckert2012} argues, social meaning is part of linguistic structure, not a by-product. Speakers maintain the form partly because it does identity work~-- marking solidarity, casualness, narrative immediacy. \textcite{buchstaller2014} found that attitudes toward \mention{be like} track age and gender: listeners perceive its users as younger and more socially attractive, even while rating them lower on status dimensions. The form is maintained partly \emph{because} of this indexical profile.

\textbf{Transmission dynamics.} The apparent-time pattern~-- younger speakers use \mention{be like} more~-- becomes a real-time change as each cohort ages. \textcite{tagliamontedarcy2004} showed that Canadian speakers aged 17--19 in 2003 used \mention{be like} for 63\% of quotative tokens, compared to 13\% for speakers of the same age in 1995. That's not two populations differing in age-graded behaviour; it's the S-curve of language change in progress. Forms that suit the demographic and interactional structure of transmission~-- peer-to-peer in adolescence, parent-to-child thereafter~-- survive and spread.

The quotatives case is a site where predictive processing and social indexing co-align, each reinforcing the other. The discourse routines of informal narrative make quotative contexts highly predictable~-- you know a quotative is coming before it arrives. That predictability encourages rapid uptake; rapid uptake feeds entrenchment; entrenchment makes the form even more predictable next time. Meanwhile, social indexing adds a parallel reinforcement loop: forms that mark in-group identity get used more in the high-frequency contexts where identity matters, which strengthens both the processing advantage and the social signal. The braid tightens because the strands pull in the same direction.

Here is the processing → stability bridge. Online processing pressures~-- prediction, retrieval ease, reduced production cost under repetition~-- preferentially reinforce some cluster features over others. The features that are easy to predict, easy to produce, and easy to retrieve are the ones that survive and spread. That selective reinforcement keeps the category coherent across time and speakers. Processing isn't just something that happens to categories; it's one of the mechanisms that maintains them.


\subsection{How deep do mechanisms go?}

The stabilisers just described~-- processing economy, expressive fit, social indexing, transmission dynamics~-- might look like endpoint explanations. But mechanisms have mechanisms. Each stabiliser can be decomposed causally (what underlies it?) and mereologically (what are its parts?). The decomposition reveals the multi-level architecture of category maintenance.

\subsubsection{Causal depth}

Take the robust finding that young women lead quotative innovation \autocite{labov2001,tagliamontedarcy2004}. This isn't a brute fact. It bottoms out in social-psychological structure.

Young women's peer networks tend to be denser and more multiplex than young men's \autocite{milroy1987}. Dense networks means more linguistic input, more accommodation pressure, faster entrenchment of shared forms. Multiplex ties~-- relationships serving multiple social functions~-- means more stakes in each interaction, more motivation to coordinate. When your interlocutor is also your classmate, neighbour, and confidante, you align more strongly than with a stranger.

But why dense networks in adolescence at all? Developmental psychology provides the next level down. Adolescence is the period of separation-individuation, when peer orientation overtakes parent orientation \autocite{erikson1968}. The social structure of schooling concentrates age-cohorts in prolonged daily contact~-- co-location plus time produces the network density that shapes linguistic input. Identity construction becomes primary: you need to differentiate from your parents while affiliating with your peers. Linguistic innovation serves both goals simultaneously~-- it marks in-group solidarity and out-group distinction.

Why these developmental facts? Evolutionary pressures on coalition formation. Cultural transmission of gender norms that make social reputation more costly for women. Economic structure that extends education and delays labour-market entry, prolonging the adolescent peer-intensive phase. At this level we've left linguistics for psychology, sociology, economics~-- but the causal chain is continuous: distal factors shape network structure, which shapes input frequency, which shapes entrenchment. \enquote{Young women lead quotative change} isn't a stipulation; it's the surface manifestation of a causal cascade that bottoms out in human developmental and social architecture.

A caution: this is a \emph{possible} depth path, not a confirmed one. The evidence requirements tighten as we descend levels. The sociolinguistic pattern (young women leading) is robust; the network-density explanation is well-supported; the developmental-psychology account is plausible but less directly tested; the evolutionary and economic claims are speculative. The framework permits depth without requiring it~-- what matters is that the mechanism at each level be genuinely explanatory, not that every level be equally confirmed. Readers who find the deeper levels overreaching can stop at network density without losing the main argument.

How far down should linguistic explanation go? Far enough to explain the clustering at the level we care about. For the quotative case, the clustering is grammatical: first-person preference, youth association, non-verbatim content. The mechanisms are social and cognitive: network density, identity work, processing pressure, entrenchment dynamics. We \emph{could} trace further~-- to neuroscience, to evolutionary biology~-- but the grammatical clustering is already explained. The framework is level-agnostic: it says look for mechanisms that produce clustering, without dictating which level to bottom out at.

\subsubsection{Mereological structure}

The same decomposition applies to parts, not just causes. \enquote{Transmission} sounds like a single mechanism, but it's a composite.

Production processes come first: lexical selection (choosing \mention{be like} over \mention{say}), which involves activating competitors, weighting by frequency, and filtering by context~-- register, addressee, narrative function. Then syntactic planning: slotting the copula and predicative into a quotative frame. Then phonetic realisation: the actual articulation of \mention{like}.

The signal bridges production and perception: acoustic properties, prosodic packaging (the characteristic intonation contour that marks enactment).

Perception processes follow: segmenting the stream, recognising words, parsing the construction, assigning category membership. Each is a sub-mechanism with its own structure~-- word recognition draws on frequency-weighted access, construction parsing draws on facilitated patterns, category assignment draws on distributional learning.

Each encounter updates the conditions for future production: encoding this token in context (acoustic trace, syntactic frame, pragmatic function, social co-occurrence~-- who said it, to whom, with what stance), facilitating future reconstruction of similar forms, strengthening form-function associations. The listener becomes a speaker whose lexical selection is now shifted slightly toward the form just heard.

Social processes interleave throughout: accommodation (matching the interlocutor), identity projection (signaling youth and informality), stance-taking (performing enactment rather than merely reporting). \textcite{pickering2004} model alignment as automatic priming; \textcite{Eckert2012} situates it in identity construction. Both are part of what \enquote{transmission} means.

The mereological lesson: even the mechanisms introduced in Chapter~\ref{ch:kinds-without-essences}~-- acquisition, entrenchment, alignment, functional pressure~-- are not atoms. They're composites with internal structure. When we say \enquote{transmission maintains the category}, we're compressing a multi-part process into a single term. The term is still explanatory~-- it picks out a real causal structure~-- but the structure is articulated, not monolithic.

\subsubsection{What this means for explanation}

The depth and structure of mechanisms matter for two reasons.

First, they reveal where intervention is possible. If transmission depends on particular memory processes, then anything that disrupts those processes~-- reduced input frequency, competing forms, register restriction~-- will weaken the mechanism. Knowing the parts tells you where the leverage points are. This is why Chapter~\ref{ch:failure-modes} on failure modes will matter: category dissolution happens when sub-mechanisms fail, and understanding which sub-mechanisms are failing requires knowing what they are.

Second, they connect linguistic explanation to the broader sciences. The causal depth that runs from \enquote{young women lead change} through network density to developmental psychology to evolutionary pressures is where linguistics fits into the larger picture. The maintenance view doesn't require every linguist to become a psychologist or evolutionary biologist. But it does make explicit that grammatical categories are maintained by mechanisms that ultimately ground in facts about human cognition, social structure, and history. The framework is continuous with the rest of science, not sealed off from it.

\subsubsection{Mechanisms as categories, categories as mechanisms}

A deeper point emerges from this decomposition.

If categories are projectible clusters stabilised by mechanisms, and if the mechanisms themselves are projectible clusters stabilised by further mechanisms, then mechanisms are categories. \enquote{Processing economy} is a category~-- it bundles properties (reduced forms, high frequency, resistance to analogical pressure) that cluster reliably because of underlying neural and memory constraints. \enquote{Social indexing} is a category~-- it bundles properties (youth association, in-group marking, register restriction) maintained by identity construction and network dynamics. The mechanisms we invoke to explain quotative stability are themselves HPC kinds, maintained by their own braids of stabilisers.

And the stabilisation is reciprocal.

Quotatives don't just \emph{use} processing economy~-- they \emph{maintain} it. Every time a speaker produces \mention{be like}, that token is input to the conditions that ground processing economy. The form's high frequency reinforces the facilitation that makes high-frequency forms easier to produce. The mechanism depends on the category for its continued operation just as the category depends on the mechanism.

The same reciprocity holds for social indexing. Social indexing isn't just a mechanism \emph{for} quotatives; quotatives are part of what \emph{constitutes} social indexing. The indexical field that makes youth-associated forms socially meaningful exists because forms like \mention{be like} circulate with those associations. Remove the quotatives and the indexical structure weakens. The category and the mechanism co-construct each other.

This is not a vicious circle. It's a self-organising dynamic~-- precisely the homeostatic structure that gives HPC kinds their stability. Categories shape what gets entrenched; entrenchment shapes which categories survive. Each stabilises the other.

A contrast case sharpens the point. Consider the traditional category \term{particle}~-- a wastebasket label for uninflected words that don't fit elsewhere: \mention{up} in \mention{look up}, \mention{to} in infinitives, \mention{not}, sentence-final \mention{eh}. Does this cluster survive a maintenance audit? The properties don't co-occur reliably: \mention{up} takes complements; infinitival \mention{to} doesn't; \mention{not} has scope properties shared by neither. There's no common acquisition pathway: children learn verb-particle constructions, infinitives, and negation at different times, through different input distributions. There's no processing signature: reaction-time studies don't show \enquote{particle} effects that generalise across subtypes. There's no transmission dynamic: speakers don't acquire \enquote{particle-hood} as a generalisable category; they acquire constructions that happen to contain uninflected words. Predictions trained on one subtype (verb-particles) fail to transfer to another (infinitival \mention{to}). The label exists; the mechanism-maintained kind doesn't. Failure of reciprocal maintenance looks exactly like this: the supposed category doesn't exercise a shared mechanism, and no shared mechanism makes the category projectible. Chapter~\ref{ch:failure-modes} develops such failure modes systematically; here, the contrast case shows that the quotative analysis isn't analogy-by-enthusiasm~-- it identifies genuine stabilisation that \term{particle} lacks.

The quotative category is also a mechanism in the larger kinds that contain it. Quotatives are part of what maintains \term{narrative discourse structure}~-- they enable the vivid re-enactment that makes storytelling work. They are part of what maintains \term{youth register}~-- the forms that index adolescent identity and solidarity. They are part of what maintains \term{informal speech} as a recognisable variety~-- the cluster of features that signals casualness, immediacy, peer context. And again, the stabilisation is reciprocal: narrative structure provides the discourse ecology in which quotatives function; youth register provides the social meaning that quotatives carry; informal speech provides the register niche that quotatives occupy.

So the hierarchy runs both ways. Downward: quotatives are maintained by mechanisms (processing, acquisition, social indexing, transmission), which are themselves maintained by deeper mechanisms (memory architecture, developmental psychology, network structure). Upward: quotatives are mechanisms in larger categories (narrative structure, youth register, informal speech), which are themselves mechanisms in still larger kinds (discourse genres, sociolinguistic repertoires, speech communities). And at every level, the stabilisation is bidirectional: each element both depends on and sustains the elements above and below it.

The distinction between \enquote{category} and \enquote{mechanism} is perspectival, not ontological. What counts as a category at one scale is a mechanism at another. What stabilises quotatives is stabilised by quotatives. The recursion is not infinite~-- it bottoms out in physics and tops out in the largest social formations~-- but within the range linguistics cares about, the structure is fractal: categories all the way down, mechanisms all the way up, reciprocal maintenance all the way through.


\subsection{Why the same profile across languages?}

This is the most telling fact. Japanese, Turkish, German, and English are not typologically close. They have different word-order properties, different morphological profiles, different sociolinguistic ecologies. Yet they converge on similar quotative innovations.

The temporal pattern is striking. In English, \mention{be like} was first attested in the US in 1982 \autocite{butters1982}, at least seven years before it appeared in any other variety \autocite{buchstaller2014}. It reached the UK by 1994 \autocite{andersen1996}, New Zealand and Canada by 1995 \autocite{baird2001,tagliamonteH1999}, Australia by 1997 \autocite{winter2002}. The form then appeared in outer-circle Englishes: Singapore, Hong Kong, Kenya, Jamaica, the Philippines. By the 2000s, it had global attestation across typologically diverse contact varieties.

One obvious hypothesis is media transmission. The `Valley Girl' stereotype, propelled into popular culture by Frank Zappa's 1982 song and subsequent Hollywood films, made \mention{be like} audible to millions. But \textcite{buchstaller2014} finds little evidence for straightforward media-driven borrowing. Speakers rarely associate \mention{be like} with media stereotypes; the form's linguistic conditioning varies across localities in ways inconsistent with uniform transmission; and the development pattern shows `transformation under transfer'~-- local adaptation of a form that arrived from elsewhere~-- rather than passive copying.

The stronger hypothesis is convergent development under similar functional pressures. The semantic-pragmatic sources for innovative quotatives~-- deictic markers, movement verbs, approximation expressions~-- recur across typologically unrelated languages \autocite{guldemann2008}. German recruits \mention{so} (a deictic), Japanese recruits \mention{tte} (a reduced quotative verb), Turkish recruits \mention{diye} (a converb), English recruits \mention{like} (an approximator). The sources differ, but the functional territory is the same: introducing vivid, non-verbatim re-enactment in informal narrative.

The convergence is not lexical; it's structural. The stabilising mechanisms are the same:

\begin{itemize}
   \item Processing pressure favours light forms.
   \item Discourse needs favour vague-reference quotatives.
   \item Social dynamics favour youth-indexed forms.
   \item Transmission dynamics favour high-frequency, contextually salient forms.
\end{itemize}

Wherever these mechanisms operate~-- and they operate everywhere humans tell stories to each other~-- the same type of quotative emerges. The category is not defined by a shared etymon or a universal grammar rule. It's stabilised by a convergent mechanism profile.

A caution about what convergence shows. Similar surface profiles suggest convergent \emph{problems}~-- similar functional pressures, similar communicative needs. They don't automatically demonstrate the same underlying stabilisers at the same relative weights. In one ecology, processing economy may dominate; in another, social indexing may do more work. German \mention{so} remains more register-restricted than English \mention{be like}, even though both serve the same niche~-- which suggests that the social-indexing pressures differ, even as the processing pressures align. Convergent profiles are evidence that the \emph{type} of mechanism is similar; the specific braid may still vary across ecologies.

This is what \enquote{same category across languages} means in the maintenance view: convergent stabilisation, the clustering that emerges when similar mechanisms operate under similar pressures. The convergence is predictable: if processing economy and expressive fit are universal~-- all humans favour light forms under production pressure, all humans need vague-reference quotatives for storytelling~-- then similar sociolinguistic dynamics will produce similar outcomes wherever they operate. But \enquote{similar outcomes} needn't mean identical mechanisms. The framework predicts family resemblance in the stabilising story, not clones.


\subsection{The wider ecology: colloquialisation and register shift}

There's a tempting further explanation. If similar quotatives emerged in multiple unrelated languages at roughly the same historical moment~-- the late twentieth century~-- perhaps a global trend toward informalisation opened ecological space for these forms to flourish.

The hypothesis deserves scrutiny, but it oversimplifies. Corpus-based studies document colloquialisation in English and some related varieties \autocite{biber1989,leech2009}, but not universally: Japanese and Korean have seen \emph{increased} honorific elaboration in some contexts \autocite{ide2005}, and Arabic and Turkish retain robust formal/informal distinctions. Even where colloquialisation occurs, formality persists in academic, legal, and medical registers \autocite{bibergray2016}. And the quotative case doesn't \emph{require} the hypothesis~-- the mechanisms enumerated above are sufficient.

The most defensible framing: colloquialisation is a shift in the \emph{selection environment}, not a distinct stabilising mechanism. In evolutionary biology, climate change is not a mechanism of evolution~-- mutation, selection, and drift are mechanisms~-- but it alters the selection pressures that determine which variants succeed. Likewise, colloquialisation changes the conditions under which the quotative mechanisms operate: which registers are widely heard, which indexical values carry social weight, how quickly innovations spread.

This framing makes a prediction: in environments where colloquialisation hasn't occurred, the same mechanisms should still operate~-- but in a narrower niche. German \mention{so} is more register-restricted than English \mention{be like}, consistent with a more modest colloquialisation trend in German public discourse. The mechanisms are the same; the scope of their product differs with the ecology.

Colloquialisation is real, where it occurs. It modulates the reach of stabilised forms. But it is not a named mechanism in the quotative story. It is the weather in which the mechanisms operate.

\subsection{Variation and activation}

Not all quotative tokens are equally stable. English \mention{be like} is deep in its basin for speakers under 50; for speakers over 70, \mention{say} may still dominate. This is not two categories; it's the same functional category in different activation states, conditioned by generational input.

Within a single speaker, \mention{be like} is activated in storytelling and suppressed in formal report. The form is there; the activation depends on discourse environment.

German \mention{so} is more restricted than English \mention{be like}~-- still marked as adolescent, still register-bound. This is a shallower basin~-- fewer stabilisers supporting the form, and consequently more sensitivity to environmental signal.

The activation-state picture predicts: forms in shallow basins should show higher inter-speaker variation, more register sensitivity, and faster historical flux. \mention{So} does; \mention{be like}, now entrenched across generations, doesn't.

We should expect, too, that \mention{be like} uptake is uneven across the population. Age cohorts differ; so do regions, social networks, and individual histories. The community-level stabilisation doesn't imply uniform speaker-level mastery. Some speakers have deeper entrenchment; others use the form rarely or not at all. This heterogeneity is not a failure of the category but part of its ecology~-- the population-level pattern emerges from aggregated individual trajectories, not from a single shared grammar.

\subsection{What if a mechanism were absent?}

A stress test: what if we removed each stabiliser in turn? If the braid is genuinely explanatory, no single strand should suffice.

If processing economy were the only stabiliser, we'd expect the shortest form to win regardless of discourse function. But \mention{say} is shorter than \mention{be like}, and it doesn't dominate.

If expressive fit were the only stabiliser, we'd expect any form that introduces vivid quotation to spread equally. But quotatives with pejorative associations, or unfashionable indexical value, don't spread even when they fit the discourse need.

If social indexing were the only stabiliser, we'd expect pure fashion effects: quotatives rising and falling with generational taste, cycling over a decade or two. But \mention{be like} has been stable for four decades, long past a typical lexical-fashion cycle.

If transmission were the only stabiliser, we'd expect all forms heard in childhood to survive. But archaic quotatives like \mention{quoth} or reduced variants that never gained social cachet don't persist.

The observed pattern~-- cross-linguistic convergence on light, expressive, youth-indexed, narratively deployed quotatives~-- requires the full braid. No single mechanism is sufficient.


\subsection{A contrast: same semantic territory, different architecture}

The framework should also predict divergence when ecologies differ. Consider evidentiality~-- the grammatical encoding of information source. Turkish and Japanese both mark the distinction between direct and indirect evidence. But they've built different architectures for it.

Turkish has a single, tightly grammaticalised suffix: \mention{-(I)mIş} marks indirect evidentiality (inference, hearsay, surprise), contrasting paradigmatically with \mention{-DI} for direct experience. The contrast is obligatory, prosodically integrated, and acquired early.

Japanese has a looser constellation: \mention{rashii} (inference from external signs), \mention{sōda} (hearsay), \mention{yōda} (appearance-based). These forms are syntactically semi-independent, optional rather than obligatory, and retain traces of their lexical sources. They are recruited not only for evidentiality but also for hedging and politeness~-- softening assertion in a culture where directness risks face-loss.

Why the difference? The mechanisms are the same: frequency, paradigmatic contrast, prosodic integration, functional need. But the \emph{ecology} differs. Turkish sits within an areal zone~-- the Balkans, Caucasus, Central Asia~-- where contact has amplified evidential grammaticalisation for centuries \autocite{aikhenvald2004}. Japanese evidentials do double duty, serving politeness as much as information source, which preserves their semi-lexical status.

Same semantic territory. Different category architecture. The mechanisms don't differ; the selection environment does. The ecology is the wind; the mechanisms are the sails.


\section{A second case: filler-gap and independent relative \mention{whose}}
\label{sec:7:filler-gap-whose}

The quotative case shows mechanisms maintaining a category from above~-- from the functional and social pressures that keep the clustering clustered. But a sceptic might wonder: is this just sociolinguistics dressed in HPC clothing? A second case answers that challenge by showing mechanisms maintaining a construction from below~-- from the cognitive processes that make it processable. After this case, the reader can say something they couldn't responsibly say after quotatives alone: the framework works for cognitive stabilisers, not just social ones.

\subsection{The filler-gap mechanism}

When you hear \mention{Which book did Mary say that John read \_\_?}, you track a displaced constituent: \mention{which book} is the filler, and the gap after \mention{read} is where it's interpreted. This filler-gap dependency spans clause boundaries, requires memory, and operates across surface variation~-- open interrogatives, relative clauses, clefts.

As mentioned in Chapter~\ref{ch:projectibility}, \citet{boguraev2025} used causal interventions to test whether language models learn a shared mechanism across these construction types. They do: a mechanism learned on embedded open interrogatives transfers to produce filler-gap behaviour in clefts. The structural dependency projects even when the surface constructions differ.

Mechanistic kindhood predicts exactly this. The filler-gap mechanism applies across surface variation~-- relative clauses, interrogatives, clefts. It is exercised every time a speaker produces or comprehends one of these constructions. Each construction reinforces the mechanism; the mechanism in turn makes each construction processable. The stabilisation is reciprocal.

\subsection{Independent relative \mention{whose}: a gap that isn't}

A case study deepens the point. \citet{hankamer1973whose} claimed that English lacks independent relative \mention{whose}~-- forms like \mention{a woman whose was straight} where the possessum is elided. Their constructed examples are indeed ungrammatical: \mention{*The guy whose you saw banging at the window...} fails. For fifty years, the construction was treated as a syntactic gap.

But the gap may be illusory. \citet{reynolds2024whose} documents attestations spanning seven centuries, from Middle English manuscripts to contemporary academic prose: \mention{a friend of whose had told us of the accident}; \mention{those whose are not}. The construction is rare~-- perhaps once in hundreds of millions of words~-- but attested in edited sources across registers.\footnote{The grammaticality judgments remain disputed. \textcite{reynolds2024whose} is a preprint, and native-speaker intuitions vary. The epistemic status is accordingly tentative: suggestive evidence that the mechanism is there, not conclusive proof.}

What maintains this construction despite its extreme rarity? The same mechanisms that maintain other filler-gap constructions~-- but operating under unusually stringent conditions.

\subsection{Filler-gap stabilisers}

\textbf{Filler-gap processing.} Independent relative \mention{whose} is a filler-gap construction. \mention{Whose} fills a gap in subject or complement position: \mention{a woman whose \_\_ was straight}. The displaced constituent must be tracked across clause structure and resolved at the gap site. This is the same cognitive operation that underlies relative clauses, open interrogatives, and clefts~-- the mechanism that Boguraev et al. showed transfers across construction types. Here, as with quotatives, mechanisms at different scales~-- cognitive, interactional, institutional~-- interact to maintain the construction.

The filler-gap mechanism is maintained by processing pressures. Incremental parsing requires tracking dependencies as they unfold; memory constraints favour local resolution; prediction mechanisms anticipate gap sites. These pressures apply every time a speaker processes a relative clause or an interrogative. The mechanism is exercised constantly, even if independent \mention{whose} is exercised rarely.

\textbf{Information structure.} But filler-gap processing alone isn't sufficient. Independent \mention{whose} faces an additional burden: the elided possessum must be recoverable. This is what \citet{reynolds2024whose} calls the \enquote{double anaphora} requirement~-- the hearer must simultaneously recover the possessor (from the relative clause antecedent) and the possessum (from discourse context).

Three information-structural configurations license this recovery:

\begin{itemize}
\item \textbf{Contrastive parallelism.} The possessum is established in a preceding clause, and the \mention{whose} clause contrasts with it: \mention{I knew someone whose greatest love affair was with objects, another whose was with books, and a third whose was with ideas.} The parallel structure keeps the possessum type (\mention{love affair}) maximally accessible.

\item \textbf{Deictic anchoring.} A demonstrative directly points to the possessum: \mention{The man whose these are hath gotten me with child.} Deixis removes the need for discourse-level recovery.

\item \textbf{Structural integration.} The possessum appears as head of the phrase containing \mention{whose}: \mention{a friend of whose had told us of the accident.} The oblique genitive construction provides the possessum explicitly.
\end{itemize}

These aren't arbitrary conditions. They're the configurations that satisfy the recoverability constraint~-- the same constraint that governs ellipsis generally. The information-structural mechanism is independent of the filler-gap mechanism, but both must be satisfied for the construction to succeed.

\textbf{Discourse ecology.} Why did identity-of-sense stranding emerge only in the 1990s, when identity-of-reference stranding has existed since Middle English? Not because the grammar changed, but because the discourse ecology changed.

Academic and journalistic prose favours list-like enumerations and explicit contrast sets: \mention{patients whose symptoms improved versus those whose didn't}. These registers build the contrastive parallelism that licenses possessum recovery. The construction became possible when the discourse patterns that license it became conventionalised in particular genres. The mechanism was always there; the licensing environment wasn't.

\textbf{Cross-linguistic convergence.} German and Japanese~-- despite radically different syntactic structures~-- show similar information-structural constraints on independent possessive relatives. A compact illustration:

\begin{quote}
\textbf{German:} \mention{Meins funktionierte, aber ich kenne jemanden, dessen nicht funktionierte.} (`Mine was working, but I know someone whose wasn't.')~-- licensed by contrastive parallelism.\\
\textbf{German:} *\mention{Die Person, dessen du vergessen hast, ist mein Cousin.} (`The person whose you forgot is my cousin.')~-- fails without parallelism.\\
\textbf{Japanese:} \mention{Watashi-no-wa ugoite-ita ga, ugoite-ina-katta hito-mo shitte-iru.} (`Mine was working, but I also know someone whose wasn't.')~-- licensed by contrastive parallelism.
\end{quote}

The pattern mirrors English exactly: stranding succeeds under contrastive parallelism and fails without it. The constraints are not language-specific accidents. They're consequences of how filler-gap processing interacts with discourse accessibility~-- and those interactions should be universal.

\subsection{Why the same constraints across languages?}

The convergence demands explanation. Why should German, Japanese, and English all require contrastive parallelism for possessum recovery?

The answer is that the mechanisms operate at a level deeper than language-specific syntax. Filler-gap processing is a consequence of incremental parsing under memory constraints~-- and all human languages are parsed incrementally under memory constraints. Discourse accessibility is a consequence of how information flows through attention~-- and attention operates similarly across languages. The recoverability constraint is a consequence of communicative pressure~-- hearers must be able to reconstruct what speakers elide, and that pressure applies everywhere. The evidence from three languages is suggestive, not conclusive, but the pattern is what the framework predicts.

The surface structures differ. German has case marking; Japanese is head-final; English has neither. But the underlying mechanisms~-- the processing pressures, the memory constraints, the communicative needs~-- are constants. The constraints on independent possessive relatives track those constants, not the surface variation.

The \mention{whose} case illustrates the chapter's central argument: a shared cognitive mechanism (filler-gap processing) operates under a specific constraint profile (information-structural licensing), and that profile recurs across typologically unrelated languages because the constraints track universal processing pressures, not language-specific syntax. The maintenance is reciprocal: filler-gap constructions exercise the processing mechanism that makes them possible, while the mechanism makes the constructions processable in turn. \enquote{Labels aren't mechanisms} means exactly this in practice: the label \enquote{ungrammatical} predicted nothing; the mechanism story predicts exactly when the construction succeeds and when it fails.

We should also expect the constraints to pattern with experience. Speakers with greater exposure to the contrastive-parallelism registers~-- academic prose, formal journalism~-- may find independent \mention{whose} more accessible than speakers without such exposure. That's a theory-driven expectation: the construction depends on licensing conditions that are themselves unevenly distributed. Differential mastery is not a defect of the grammar; it's a prediction of the maintenance view.

\subsection{Reciprocal maintenance}

The filler-gap case shows the same reciprocal structure as quotatives~-- and as the immunological analogy that opened the chapter. A cell type maintains the signalling environment that maintains the cell type; a construction maintains the processing mechanism that maintains the construction.

The filler-gap mechanism maintains the constructions by making them processable. Without the ability to track displaced constituents and resolve them at gap sites, relative clauses and interrogatives couldn't exist. The mechanism is a precondition for the constructions.

But the constructions maintain the mechanism by exercising it~-- that is, by providing the input that keeps the processing routine facilitated. Every relative clause, every interrogative, every cleft is input to the conditions that sustain filler-gap processing. The mechanism is real because it's kept alive by the constructions it serves.

The same applies to the information-structural constraints. Contrastive parallelism is a discourse pattern that exists independently of \mention{whose}. It's used for contrast sets generally, for enumeration, for rhetorical balance. But when speakers use \mention{whose} in contrastive contexts, they reinforce the association between contrastive parallelism and possessum recovery. The discourse pattern maintains the construction; the construction maintains the discourse pattern.

And the mechanism itself is a category~-- a cluster of properties (incremental parsing, dependency tracking, gap-filling) maintained by cognitive constraints, with sub-mechanisms all the way down.


\section{How to test whether a mechanism is real}
\label{sec:7:robustness-tests}

The biological approach gives us a natural framework for testing mechanistic claims. Not hand-waving that \enquote{entrenchment maintains the category}, but operational tests that distinguish genuine causal structure from convenient labels.

\textbf{Learning transfer.} If entrenchment is real, speakers who learn aspect marking from some verbs should generalise to new verbs in predictable ways. This is exactly what the Polish models show: training on one subset, testing on another, the predictions transfer. Learning transfer is evidence that the category boundaries track causal structure, not just filing conventions.

\textbf{Intervention stability.} If frequency-based entrenchment stabilises irregular forms, then manipulating frequency should shift the pattern. We can't easily do this experimentally for established languages, but we see it in acquisition studies: children under-exposed to irregulars regularise more. We see it in contact situations: languages in intense contact show accelerated regularisation as input frequencies change.

\textbf{Cross-context generalisation.} If the category is maintained by stable mechanisms, predictions should hold across contexts~-- different registers, different tasks, different populations. Labels without mechanisms should fragment: what works in careful speech should fail in casual speech; what works for Standard Polish should fail for dialectal Polish. The Polish aspect models show robustness across tense frames and lemma contexts. That's generalisation. That's robustness. That's mechanism.

These tests are what distinguish \enquote{I found a category} from \enquote{I found a mechanism that maintains a category}. The former is descriptive; the latter is explanatory.

A practical recipe, in prose: (1) Identify the cluster~-- what properties co-occur? (2) Propose stabilisers at two or three levels~-- cognitive, social, transmissional. (3) Derive at least one intervention or natural-experiment prediction~-- if we weaken this stabiliser, how should the clustering change? (4) Check whether the predicted reshaping is observed~-- in acquisition data, contact situations, or experimental manipulations. If the prediction holds, the stabiliser is load-bearing. If it fails, revise or discard. This is how mechanism claims earn their keep.

At this point the metaphors have to pay rent. The biological analogy is not evidence that language \emph{is} biology; it's a reminder that when definitions fail, mechanism-first inquiry is standard scientific practice. The \enquote{stabiliser} label is not a discovery; it's a way of organising claims that can be tested. If the tests fail, the metaphor was ornamental. If they succeed, the metaphor was doing inferential work.

A corpus-friendly corollary: if a stabiliser is real, the distributional cues for category membership should become tighter and more mutually predictive over time (or across registers where the stabiliser operates more strongly). That's a prediction you can test with historical corpus slices.

An individual-differences corollary: if a category is maintained by genuinely robust mechanisms, its diagnostics should be relatively resilient across speakers with different experience profiles. Where they're not~-- where speakers with different exposure histories show systematically different category boundaries~-- the gap itself is mechanistically informative. It tells you which stabilisers are experience-dependent and which operate more uniformly.

A processing corollary: if a category is maintained partly by expectation-based processing, then category-consistent cues should yield measurable facilitation~-- shorter reaction times, earlier eye-fixations, predictable ERP signatures~-- relative to matched category-inconsistent cues. And the size of that facilitation should track experience with the specific construction. That's where the ontology cashes out in experimental design.

The signature we'd accept as supportive evidence: category-consistent cue bundles should yield processing facilitation, and partial cue bundles should yield graded costs~-- not categorical cliff effects. If borderline items pattern as noisy exemplars of a discrete class, that's evidence for classical categories. If they pattern as systematic mixtures with context-sensitive profiles, that's evidence for HPC.


\section{Degrees of projectibility}
\label{sec:7:degrees-projectibility}

The stabilising story explains why projectibility comes in degrees.

A category deep in a single basin~-- that is, supported by multiple aligned stabilisers (entrenchment, transmission, functional pressure, social reinforcement), all pulling in the same direction~-- is strongly projectible. You can learn about nouns from a few exemplars and generalise reliably to new nouns. The mechanisms reinforce each other across timescales.

A category in an overlap region~-- where mechanisms pull in different directions, or where entrenchment is weak~-- is weakly projectible. Predictions work for typical cases but fail for edge cases. The degree of projectibility tracks the degree of mechanistic support.

A label with no mechanisms behind it is not projectible at all. A wastebasket category defined by what it's not~-- like the traditional \enquote{adverb} class, which groups manner adverbs, sentence adverbs, degree words, and conjuncts under one label~-- should fragment under the robustness tests. It does: predictions trained on manner adverbs don't generalise to sentence adverbs.

This is the operational content of \enquote{mechanism-maintained kinds}. Not a metaphor. A measurable property: how strongly do predictions transfer across novel instances, contexts, and populations?


\section{What this commits us to}
\label{sec:7:commitments}

If this picture is right, we're committed to some substantive claims.

The overarching commitment is a form of realism~-- but realism of a specific kind. We are not claiming that grammatical categories are mind-independent features of the universe, waiting to be discovered like chemical elements. We are claiming that they are stably discoverable because mechanisms make them reliable targets of inquiry. The category \term{noun} is real in the same sense that the category \term{tiger} is real: not because there is an essence that defines it, but because mechanisms of production and transmission keep properties clustering in ways that support induction. This is mechanism-grounded realism. It is compatible with the categories changing over time, varying across languages, and having fuzzy boundaries. What it is not compatible with is treating categories as arbitrary conventions that could have been otherwise with no cost to explanation.

\textbf{Process ontology.} Categories are not static objects. They're dynamically sustained patterns~-- standing waves, not sculptures. What exists is the stabilising process; the category is what the process makes legible.

\textbf{Population-distributed competence.} The target of explanation is not an ideal speaker's uniform grammar but a population-distributed competence profile. Different speakers, with different input histories, stabilise categories to different depths. The mechanisms are shared; the resulting category boundaries needn't be. This framing avoids smuggling in the idealisation that anti-essentialism is supposed to escape.

\textbf{Interventionist realism.} Kinds are real to the extent that tracking or manipulating them changes expectations. This is stronger than description: it says that category distinctions track causal structure, not just organise files.

\textbf{Reciprocal realism.} Mechanisms and categories co-construct each other. Categories shape what gets entrenched; entrenchment shapes what categories survive. This is not a vicious circle; it's a self-organising dynamic. The same style of feedback that immunologists model for cell states applies to grammatical categories.

\textbf{Variation as signal.} Differences across contexts, speakers, and registers are not noise. They're diagnostic~-- evidence about which region of the state space a token occupies, which activation state is active. The gradient nature of projectibility is a feature of maintenance, not a defect of the category.

\textbf{Cross-level coherence.} A category theory should deliver compatible predictions whether we analyse a phenomenon at the level of subpatterns, the construction, the category, or the wider system. If treating X as a bundle of micro-regularities yields different predictions than treating it as a member of a broader category, we've found something real: a heterogeneous grouping, a mislocated mechanism, or a label whose scope is historically inherited rather than causally grounded.

\textbf{Measurable metaphysics.} These claims have operational teeth. Entropy reduction, cross-context generalisation accuracy, inter-speaker agreement as a function of frequency and entrenchment~-- these are not hand-waving gestures toward mechanism. They're measurable properties of stabilised categories.


\section{Refactoring, not replacing}
\label{sec:7:refactoring}

A reminder of the pluralist posture established in §\ref{sec:4:payoffs}.

The quotative case study isn't meant to supersede Tagliamonte's variationist work or Buchstaller's cross-variety comparisons or Ferrara and Bell's functional analysis. That work provides the data~-- the apparent-time percentages, the first-person preferences, the global attestation timeline. The maintenance view provides a conceptual frame that makes the data cohere.

What the refactoring adds: an answer to \enquote{why this cluster?}~-- why these properties (first-person, youth, non-verbatim, informal) hang together rather than some other set. An answer to \enquote{what licenses comparison?}~-- why German \mention{so} and English \mention{be like} can be treated as instances of the same phenomenon despite different etyma. An answer to \enquote{what makes the pattern stable?}~-- why the quotative profile persists across generations rather than dissolving into noise.

The sociolinguists already had the patterns. The cognitivists already had the mechanisms. The typologists already had the parallels. What was missing was the ontology~-- the account of what grammatical categories actually \emph{are} that explains why the patterns, mechanisms, and parallels hold together. That's what the maintenance view offers. Not replacement. Refactoring.

A clarification for readers familiar with grammaticalisation theory. Grammaticalisation describes a family of historical pathways~-- how lexical items become grammatical markers, how meanings bleach, how forms reduce. The HPC framework doesn't replace that story; it answers a different question. Grammaticalisation tells you \emph{how} a form like \mention{be like} developed; HPC tells you \emph{why} the resulting cluster is stable and inductively projectible. The pathways are historical; the stability is mechanistic. Both are needed: one without the other leaves either the history unexplained or the synchronic coherence mysterious.

And a clarification for readers familiar with prototype theory. Yes, categories have cores and fringes. But the interesting explanation isn't \emph{that} they do; it's \emph{why} the cores tighten and the fringes wander across different experience ecologies. Prototype theory describes the shape; HPC explains why the shape is stable and why it varies where it does.


\section{The most telling facts}
\label{sec:7:failure-modes-preview}

A grammatical category is not a thing you find; it's a regime you maintain. Arguments over definitions are, at bottom, arguments over stabilisers.

And the most telling facts about categories live in their failure modes~-- where boundaries blur, where judgments diverge, where the stabilising dynamics show their seams.

But if categories are maintained, they can be undermaintained. The mechanisms can fail to cluster, or cluster too loosely, or cluster in ways that don't project.

The next chapter asks: how do we know when we don't have a kind?
