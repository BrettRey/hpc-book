% Chapter 7: Projectibility and the Good Bet (swapped from Ch 6 in projectibility-pivot branch)
% This is the pivot chapter: everything before tells you how categories are maintained; this chapter tells you what maintenance buys.
% SLOGAN: Categories are real because they're projectible. They're projectible because they're maintained.

\chapter{Projectibility and the good bet}
\label{ch:projectibility}

\epigraph{If there aren't [pedicabs], Mr Tagomi thought, I would be well advised to retire to secluded place and kill myself.}{— Philip K. Dick, \textit{The Man in the High Castle} (1962)}

Mr.~Tagomi has slipped between worlds, and he needs to know which one he's in. Pedicabs exist in his home world but not in the other. He's betting his life on the projectibility of a single feature.

This is the core of what a category is. Not a container. Not a definition. A licence to infer.

You encounter \mention{car}. It takes determinatives, pluralises, functions as an argument. You've never seen \mention{pedicab}~-- but you bet it behaves likewise. You're usually right. The category \term{noun} lets you project from instances you've seen to instances you haven't. That's the bet, and it usually pays off.

The previous chapter traced how categories are maintained: acquisition, entrenchment, alignment, functional pressure, transmission. Those mechanisms do real causal work. But the question remains: what do they buy you? Why does maintenance matter?

Here's the answer. Maintenance matters because it produces projectibility. And projectibility is what makes a category real.

This isn't a further property that HPCs happen to have. It's the point. A category just is whatever supports reliable inference across novel instances. The mechanisms don't maintain a cluster that then, as a bonus, turns out to be projectible. The mechanisms maintain projectibility directly. The cluster is the visible trace; the inferential role is the substance.

Peirce saw this a century ago: the meaning of a sign is the habit it produces~-- the inferences it licences. A category that doesn't support inference isn't a category at all; it's a filing label. What we've been calling \enquote{homeostasis} is what keeps the inference reliable. What we've been calling \enquote{the cluster} is the profile that the inference tracks.

The slogan, then:

\begin{quote}
\emph{Categories are real because they're projectible. They're projectible because they're maintained.}
\end{quote}

The rest of this chapter unpacks that claim. Polish aspect provides a worked example~-- a case where the textbook definition fails to project but the mechanisms succeed. Field-relative projectibility explains why different disciplines can carve the same extensions differently without either being wrong. And the epistemic payoff connects this framework to the deepest question in philosophy of science: what makes induction possible?

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.npi-fragmentation.png}
\caption{Uniform label, jagged reality. The category \term{NPI} (negative polarity item) groups expressions that share sensitivity to negative contexts, but \citet[30]{hoeksema2012} documents twelve distinct licensing patterns. No single mechanism maintains them as a kind; the label names a distributional class, not an HPC cluster.}
\label{fig:npi-fragmentation}
\end{figure}

Before looking at a complex success, consider a failure (Figure~\ref{fig:npi-fragmentation}). The label \term{NPI} (negative polarity item) groups expressions like \mention{ever}, \mention{yet}, and \mention{lift a finger} that require licensing in negative contexts~-- but \citet[30]{hoeksema2012} documents twelve distinct licensing patterns across English NPIs. Models succeed at NPI prediction only to the extent they learn each item's distribution, not the category. The label names a distributional class; no mechanism maintains it as a kind.


\subsection{Unpacking the framework}
\label{sec:7:slogan}

Chapter~\ref{ch:kinds-without-essences} compressed the maintenance view into a slogan: \emph{profile, stabilized by mechanisms, projectible relative to purposes}. That slogan has three parts, but they aren't coordinate. The first two serve the third.

\textbf{Profile} is what you observe. Properties cluster; members resemble each other. But clustering alone proves nothing~-- any two objects share infinitely many properties. The profile is a surface, not an explanation.

\textbf{Stabilized by mechanisms} is what makes the clustering non-accidental. Something keeps the cluster together: acquisition, entrenchment, functional pressure, transmission. Without mechanisms, clustering is coincidental~-- a grue-like artefact waiting to dissolve.

\textbf{Projectible relative to purposes} is the payoff. The category supports induction, but only for questions the mechanisms underwrite. A syntactician and a semanticist may have different right-sized categories for overlapping extensions~-- not because categories are arbitrary, but because different mechanisms stabilize different clusters for different inferential purposes.

The architecture, then: mechanisms produce projectibility; the profile is the trace they leave. Projectibility isn't a bonus feature of well-maintained categories. It's what maintenance is \emph{for}.

This framing guards against three confusions:

\begin{enumerate}
    \item \textbf{Nominalism}: treating categories as mere conventions (ignoring the mechanisms that make them non-arbitrary).
    \item \textbf{Absolutism}: treating projectibility as all-or-nothing (ignoring purpose-relativity).
    \item \textbf{Conflation}: treating mechanism and projectibility as the same thing. They aren't. Mechanism is metaphysics~-- what keeps the cluster clustered. Projectibility is epistemology~-- what inferences the cluster licenses. A category can be maintained without being projectible (if the mechanisms don't align with your question), and a pattern can seem projectible without being maintained (if you've mistaken correlation for causation).
\end{enumerate}

The remainder of this chapter applies these distinctions to Polish aspect~-- a case where the textbook characterization is maintained by tradition but doesn't project to usage, while the distributional structure projects reliably because it tracks the actual mechanisms.


\section{The definitional bet}
\label{sec:7:definitional-bet}

Slavic verbal aspect looks like a paradigm case of a grammaticalized binary. Every Polish verb bears aspectual marking: imperfective or perfective. The opposition is obligatory, pervasive, and ancient~-- codified in grammars for centuries, taught in every language classroom.

The textbooks offer crisp definitions. Imperfective presents an event as unbounded~-- ongoing, habitual, incomplete. Perfective presents it as bounded~-- a completed whole with temporal limits (Figure~\ref{fig:aspect-viewpoint}). The terminology varies (totality, resultativeness, telicity), but the core claim is the same: there's an invariant semantic content distinguishing the two aspects, and knowing that content should let you predict which aspect a speaker will choose.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{figures/6.aspect-viewpoint.png}
\caption{The textbook account of Slavic aspect. Imperfective presents the event from inside, as ongoing; perfective presents it from outside, as a completed whole. This is the \enquote{viewpoint} metaphor that has dominated aspectual theory for a century.}
\label{fig:aspect-viewpoint}
\end{figure}

This is essentialism applied to morphology. The definitions are the essence; the essence determines behaviour. Learn the essence, and you can project: knowing what perfective \emph{means} should tell you when to use it.

But the prediction fails. If aspect has invariant semantic content, then a model that knows that content should predict aspectual usage. \citet{divjak2025learnability} tested exactly this.

They built three computational models of Polish verb usage:
\begin{itemize}
    \item A \emph{lemma-concrete} model that learns cue--outcome associations without assuming aspect exists as a category at all.
    \item An \emph{aspect-concrete} model that learns aspect from usage cues~-- distributional patterns in the input.
    \item An \emph{aspect-abstract} model that learns aspect from the semantic labels proposed in the theoretical literature~-- boundedness, totality, resultativeness.
\end{itemize}

The aspect-abstract model is the textbook view formalised. If the invariant meanings are real, this model should win.

It doesn't.

On corpus data, the aspect-abstract model performs reasonably~-- 87\% accuracy \citep{divjak2025learnability}. But accuracy hides an asymmetry. The model predicts imperfective well: 98\% correct. It predicts perfective poorly: only 77\%~-- you lose the bet nearly one time in four. The semantic invariants that aspectologists have proposed for a century~-- the definitions on which projectibility supposedly depends~-- capture only half the system. Why this direction? Likely because perfective is more lexically heterogeneous: perfective verbs are marked by a variety of prefixes, each with its own distributional profile, and they appear in a narrower range of tense frames. Imperfective is closer to a default, less marked, more uniform. The asymmetry isn't random; it tracks where the semantic definition aligns with distributional reality (imperfective) and where it doesn't (perfective).

More damaging: when validated against native-speaker judgments in a gap-filling task, the aspect-abstract model performs \emph{worse} than the simpler models. Native speakers' preferences align better with a model that doesn't even use the aspect category than with one that does. The lemma-concrete model~-- the one that treats each verb individually, without abstracting to aspect~-- best predicts which forms humans prefer.

This is a failure of definitional projectibility. The category exists; the usage is systematic; but the definitions don't project to behaviour. Knowing what \enquote{perfective} supposedly \emph{means} doesn't reliably tell you when Polish speakers will \emph{use} it. (A moderate reader might object that the textbook definitions are simplistic models, not metaphysical essences~-- that their failure is a failure of \emph{that} model, not of semantic-level explanation generally. Fair enough. But even treating definitions as models rather than essences, the projective power lies in distributional cue structure and lexeme-level entrenchment. Semantic paraphrase plays at best a partial, uneven role.)


\section{The mechanistic alternative}
\label{sec:7:mechanistic-alternative}

Why does the textbook view fail? \citet{divjak2024aspect} provide the answer.

Their corpus study of Polish aspect reveals a usage landscape strikingly different from the textbook picture.

First, lexical bias is the norm. About 90\% of Polish verbs strongly prefer one aspect~-- greater than 90\% of their tokens appear in the preferred form. Only 11\% of aspectual pairs are genuinely equiprobable. The textbook suggestion that speakers \enquote{choose} aspect based on how they view the event applies to a small minority of cases.

Second, tense carries most of the signal. A simple model using just the superlemma (verb identity) and three-way tense distinction (past, present, future) achieves F1 scores of 0.95 for imperfective and 0.90 for perfective~-- the perfective asymmetry persists, just smaller. Aspect is largely predictable from tense, not from semantic viewpoint.

Third, context cues appear where needed. Temporal adverbs and other contextual markers show up reliably only with the 11\% of verbs that lack lexical bias. The system is informationally efficient: redundant cues don't clutter unambiguous cases.

Finally, the landscape is already shaped~-- like a riverbed cut by the water that flows through it. For most verbs, learning the verb means entering a channel that use keeps cutting deeper. The category isn't applied at utterance; the same flow that carved it maintains it.

This reframes the question worth asking. Instead of \enquote{what does aspect mean?}~-- a question that invites ever more refined invariant definitions~-- we ask \enquote{what maintains the aspectual patterns speakers produce?} That question is open, investigable, and already yielding answers: distributional signatures, acquisition dynamics, lexical entrenchment. The textbook view isn't wrong; it's asking a question whose answer can't be found by the methods it uses. The mechanism view doesn't replace it~-- it explains why it worked as well as it did, and what it was missing.


Now the maintenance view snaps into focus. Why can a Polish speaker project aspectual behaviour to unfamiliar verbs? Not by applying a definition. The definitions~-- boundedness, totality~-- predict only imperfective, and even then imperfectly. What projects is something different: the cue--outcome structure that learners extract from the input.

Consider: you've learned \mention{\ipa{robić}} (impf) / \mention{\ipa{zrobić}} (pf)~-- `do', `accomplish'. You encounter an unfamiliar verb \mention{\ipa{pływać}}~-- `swim'. How do you know that \mention{\ipa{przepływać}} will be perfective?

The textbook answer: you apply the semantic definition of perfectivity~-- the event is bounded, complete, telic~-- and infer that \mention{\ipa{przepływać}} (`swim across', `complete the crossing') satisfies those criteria.

But as we've seen, the semantic definition predicts poorly. Worse, it predicts perfective worse than imperfective~-- exactly wrong for the case at hand.

The mechanism-based answer: You've learned that certain prefixes, in certain tense contexts, pattern with perfective. You've learned that verbs of motion typically have strong aspectual biases carried by morphological material. You project not from a definition but from a web of cue--outcome associations maintained across your linguistic experience.

This is projectibility grounded in mechanism rather than definition (Figure~\ref{fig:aspect-mechanism}). The category \term{perfective} exists~-- you can introspect about it, metalinguistic discourse depends on it~-- but its psycholinguistic reality needn't rest on invariant semantic content. The good bet is on the consistency of the distributional patterns that maintain it.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.aspect-mechanism.png}
\caption{The mechanism-based view of aspectual projectibility. Instead of applying semantic definitions, learners extract cue--outcome associations~-- morphological patterns, tense contexts, lexical biases~-- that allow prediction of novel forms. The question this answers isn't \enquote{what does aspect mean?} but \enquote{what maintains aspectual patterns?} (Percentages are schematic; actual weights vary by verb and context.)}
\label{fig:aspect-mechanism}
\end{figure}


\section{Labels aren't mechanisms}
\label{sec:7:labels-mechanisms}

Here's where the story takes a surprising turn. \citet{divjak2025learnability} found that the best model~-- the one that most closely matches native-speaker preferences~-- is the one that doesn't use the category \term{aspect} at all.

The lemma-concrete model~-- the one that treats each verb individually, without abstracting to aspect~-- predicts human behaviour better than the aspect-aware models. The statistical evidence is overwhelming: the probability that the aspect-aware models are actually better is effectively zero.\footnote{AIC 3,891 for lemma-concrete versus 3,954 for aspect-concrete and 4,037 for aspect-abstract; evidence ratios in the $10^{13}$ to $10^{17}$ range~-- numbers so large that the conclusion is statistically compelling.}

What does this mean for the ontological status of aspect? Here we need to separate three things:

\begin{enumerate}
    \item \emph{Is there a stable pattern that linguists call ``aspect''?} Yes. The corpus regularities, speaker agreement, and reliable acquisition all point to a real, socially shared, historically stable clustering.
    \item \emph{Do the traditional semantic definitions project to usage?} Not reliably~-- especially for perfective. That's a failure of \emph{definitional} projectibility, not automatically a failure of aspect as such.
    \item \emph{Is the abstract binary label psychologically intermediate in the production system?} The lemma-concrete result suggests: maybe not. The best causal story may live at a finer grain.
\end{enumerate}

The apparent contradiction~-- ``aspect looks real'' versus ``aspect doesn't project''~-- dissolves once we see what exactly failed. What failed is the textbook essence. What may also have failed is the assumption that speakers need an explicit aspect representation as a mediating variable. What did \emph{not} fail is the existence of stable, learnable, intersubjectively shared aspectual patterning.

This is almost the cleanest possible maintenance-view demonstration. The category label tracks a real cluster. But that cluster is maintained by a bundle of finer-grained mechanisms: lexeme-specific entrenchment, tense-conditioned expectations, prefixal cueing. Projectibility belongs to that bundle, not to the invariant semantic paraphrases. Polish aspect is real as a stable pattern, but the projectible unit is smaller than the label. The mechanism projects; the label names the emergent alignment of those mechanisms without explaining it.

Put differently: \term{aspect} names the pattern; it doesn't do the work. You can project aspectual behaviour \emph{without} representing \enquote{aspect} as such~-- because what you're really projecting are cue--outcome associations that happen to have an aspectual signature. The lemma-specific patterns don't preclude aspect as a generalisation; they ground it. What speakers know isn't \emph{either} verbs \emph{or} aspect but a multi-level network where both coexist~-- the general emergent from the particular. This answers the objection that a lemma-level model leaves no room for the category: the category exists as an emergent alignment, even if processing happens at a finer grain. The island is real even though the coral does the maintaining.

This resolves the puzzle of naming. We call it \term{aspect} because of its history; Polish aspect is the genealogical descendant of a system that may once have fit the definitions better. But mechanistic drift happens. A category can remain historically continuous while its causal underpinnings shift. A label can remain genealogically appropriate but be synchronically misleading about what projects. Think of a volcanic island. The volcano builds the island over millennia, but eventually goes dormant. Coral colonises the flanks; soil accumulates; vegetation takes root. The island persists~-- not because the volcano is still active, but because new mechanisms have taken over: reef-building, soil formation, root networks. Calling it a \enquote{volcanic island} is genealogically correct; the volcano did the initial work. But it's synchronically misleading: what maintains the island now is coral and roots, not magma. Polish aspect is like this. The opposition was carved by semantic-temporal distinctions that may once have been the primary mechanism. But the volcano has gone dormant. Now what maintains the pattern~-- what makes it projectible~-- is lexeme-specific cue structure, not semantic essence. The label names the island, not the volcano. (Note the developmental asymmetry: for a child acquiring Polish, the volcano was never active. Learners don't experience the historical shift; they experience only the coral reef~-- the current distributional cues. The ``mechanism drift'' is a diachronic observation about the collective system, not a stage in individual acquisition.)

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/6.island-volcano.png}
\caption{Mechanistic drift: a volcanic island. The volcano built the island but is now dormant. What maintains the island today~-- coral reefs, root networks, soil formation~-- differs from what created it. Polish aspect is analogous: the semantic-temporal distinctions that may once have been the primary mechanism have gone dormant. What maintains aspectual patterns now is lexeme-specific cue structure. The label names the island, not the volcano.}
\label{fig:island-volcano}
\end{figure}

The cross-linguistic term \term{aspect} functions as a \term{comparative concept}; within Polish, it names a historically inherited pattern whose contemporary projectibility is anchored in lexeme-specific cue structures rather than the textbook semantic essence. Labels aren't definitions, and labels aren't mechanisms. Calling this opposition \term{aspect} risks reifying a historically entrenched label whose textbook semantics no longer track the mechanisms that actually maintain usage. it's best treated as the name of an emergent clustering, not the explanatory unit that makes it project. But here's a constraint: genealogical continuity alone doesn't justify continued use of a label. The label is appropriate only if it still picks out a stable emergent pattern at some explanatory level. An island that has fully eroded, with no coral keeping it together, is no longer an island~-- and deserves no name.


\section{Generalising the lesson}
\label{sec:7:generalising-lesson}

Polish aspect illustrates a general lesson of the maintenance view. Polish has a grammatical opposition traditionally called aspect; what these results challenge is the assumption that the textbook characterization of that opposition is the mechanism that makes it projectible. Aspect has been defined for centuries, but those definitions fail to predict usage. By contrast, mechanism-based accounts succeed where definitions fail: the same system becomes predictable once you attend to the distributional structure~-- lexical bias, tense context, morphological cues~-- rather than the semantic essence.

This separation reveals that the category and the mechanism need not coincide. \term{Aspect} is a useful label picking out a real pattern, but the psychological reality of that pattern may be a network of cue--outcome associations, not a represented binary. The mechanism lives below the category; the projectibility comes from the mechanism. When a proposed characterization fails to project, that's diagnostic: it tells you the characterization doesn't track the mechanisms. This is HPC without category reification: clusters maintained by mechanisms, labels applied by analysts.


Polish aspect is a worked example, not an isolated curiosity. The pattern~-- definitional characterizations that fail to project, mechanism-based descriptions that succeed~-- appears across grammatical domains.

\citet{ambridge2020} found that the causative alternation (\mention{break the vase} vs *\mention{laugh the man}) is predicted by a continuous semantic dimension (directness of causation) across five typologically unrelated languages. The semantic definitions of verb classes don't work; the mechanism (sensitivity to causal directness) does. Strikingly, a model trained on five languages predicts native-speaker judgments in a sixth (Balinese) without exposure. The mechanism projects cross-linguistically; the definitional verb classes don't.

\citet{saldana2022} showed that morphological syncretism patterns are learned better when syncretic cells share semantic similarity~-- not when they share features in a definitional sense. The learnability gradient tracks similarity, not category membership. What projects is the similarity structure, not the feature system.

\citet{chi2020} demonstrated that grammatical relations (subject, object) emerge spontaneously in multilingual BERT~-- trained without any symbolic grammar~-- and transfer across languages. A probe trained only on English successfully identifies grammatical relations in French. The categories exist, but defining grammatical roles isn't what produces them; distributed learning over functional pressures is. The mechanism projects cross-linguistically; the formal definitions are epiphenomenal.

These aren't the only examples. Chapter~\ref{ch:lexical-categories} develops the case for word classes in detail. The upshot: projectibility is the empirical test for mechanistic grounding. When a category supports reliable induction, that's evidence that the mechanisms are real. When it doesn't, something about the proposed characterisation is off.


\section{What projection is}
\label{sec:7:what-projection-is}

The cases above show that projectibility tracks mechanism, not definition. But we haven't yet said what projection actually \emph{is}: what happens when you encounter \mention{pedicab} and bet it behaves like \mention{car}.

Chapter~\ref{ch:from-problem-to-fix} introduced Peirce's answer. A sign has a form, an object, and an interpretant~-- the habit of inference it generates in its users. The interpretant isn't a gloss or a mental image; it's a disposition to act. The \enquote{real and living logical conclusion} of any sign is \enquote{that habit} \citep[CP~5.491]{peirce1931cp}~-- not a representation of what the sign means, but a readiness to behave.

Encounter a noun and you project: heads a phrase, takes determinatives, fills argument slots. That projection \emph{is} the interpretant. Not something you add to the category after decoding it; what the category consists in.

Peirce insisted that the content of such a disposition is a \term{would-be}: \enquote{no agglomeration of actual happenings can ever completely fill up the meaning of a `would-be'} \citep[CP~5.467]{peirce1931cp}. The meaning of \mention{hard} isn't a list of things that have resisted a knife; it's the conditional: this object \emph{would} resist a knife-edge. The meaning outruns any finite set of instances.

This is what makes projectibility more than a track record. A category is projectible not because it has been successfully projected in the past but because it sustains a would-be: a conditional disposition that holds across instances not yet encountered. The Polish case makes this concrete. The distributional cue structure sustains a would-be: encounter this prefix, in this tense frame, with this verb class, and you \emph{would} get perfective. The textbook definition states a would-be too~-- encounter a bounded event and you \emph{would} get perfective. Both are conditional. The difference is that one would-be is maintained by mechanisms and the other isn't. The definitional would-be misfires because the semantic characterisation doesn't track the mechanisms that produce usage.

But why can't we just say \enquote{mechanism} and leave Peirce aside? Because mechanism without mediation is correlation~-- and correlation is exactly what the turkey had. Properties can covary by accident (NPIs share sensitivity to negative contexts, but no mechanism maintains their co-occurrence as a kind). Correlation is brute, two-term connection. Projectibility requires a mediating element~-- the interpretant~-- that makes the relation general, conditional, and genuinely predictive. A sign doesn't just connect form to object (that would be a mere index). It connects them \emph{through} a habit that extends to instances not yet encountered. The habit is the mediating element that constitutes the relation as projective.

The mechanisms are themselves mediating structures. Peirce argued that \enquote{a general principle that is operative in the real world is of the essential nature of a Representation} \citep[CP~5.105]{peirce1931cp}. Laws aren't brute forces; they govern how particulars relate. Entrenchment isn't a collision; it's a pattern of reinforcement that governs how tokens are processed. Alignment isn't an impact; it's a feedback loop that governs how speakers converge. The mechanisms work through mediation, not through brute contact.

This yields the book's non-reductive position: mechanisms sustain habits, but habits aren't reducible to mechanisms. A habit is a would-be~-- a conditional disposition. The mechanism keeps the disposition reliable. Remove the mechanism and the habit degrades (the spinning top falls). But the habit isn't the mechanism any more than the spinning is the hand that spun. The Polish volcano case showed this: the semantic mechanism went dormant, but the category persists because other mechanisms took over. The habit outruns any particular mechanism that sustains it.

Habits don't just ride on signs; they reshape them. \enquote{Men and words reciprocally educate each other} \citep[CP~5.313]{peirce1931cp}. This is the reciprocal maintenance that Chapter~\ref{ch:stabilizers} documented: speakers sustain the signs that sustain the speakers' habits. Every use of \mention{be like} reinforces the processing and social conditions that make future uses likely. Peirce compressed a chapter's worth of mechanism into one sentence.

And the interpretant isn't merely mental. \enquote{Some plants take habits. The stream of water that wears a bed for itself is forming a habit} \citep[CP~5.492]{peirce1931cp}. Habit, for Peirce, extends beyond minds~-- to streams, populations, and (the present argument adds) languages. A riverbed is a habit; what maintains it is the water that carved it. A grammatical pattern is a habit; what maintains it is the usage that carved it.

Finally, because habits are conditional on circumstances, different circumstances generate different habits from the same form. A syntactician's training generates one interpretant from \mention{Brett} (distributional expectations, structural prediction); a semanticist's generates another (referential tracking, possible-world reasoning). Same sign, different conditions, different projections. This is field-relative projectibility in Peircean terms. The would-be is always indexed to conditions; there is no unconditional projection. The field~-- training, questions, analytical purposes~-- is part of the conditions that determine the would-be.

For any grammatical category, then, the triad identifies three things: the form cluster (distributional, morphosyntactic), the object (semantic construal), and the interpretant (the inferential habit that couples them). The case studies in Part~III apply this decomposition systematically.


\section{Field-relative projectibility}
\label{sec:7:field-relative}

The same category can project well for one analytical purpose and poorly for another. This isn't perspectivalism~-- different views of the same thing. It's a claim about ontology: there are genuinely different HPCs that happen to overlap in extension, each projectible in its own domain.

\subsection{The tomato problem}
\label{sec:7:tomato}

Is a tomato a fruit or a vegetable? The question is undecidable only if you think there's one right answer.

A botanist classifies tomatoes as fruits~-- they develop from the ovary of a flowering plant and contain seeds. This classification projects: knowing that tomatoes are fruits lets the botanist predict ripening patterns, seed dispersal mechanisms, and responses to plant hormones. The category \mention{fruit} supports reliable induction for botanical purposes.

A chef classifies tomatoes as vegetables~-- savoury, used in main courses, paired with salt rather than sugar. This classification also projects: knowing that tomatoes are culinary vegetables lets the chef predict flavour pairings, cooking methods, and menu placement. The category \mention{vegetable} supports reliable induction for culinary purposes.

Neither classification is wrong. They're not even in conflict. They're \emph{different HPCs} that happen to have overlapping extensions. The botanist's \mention{fruit} and the chef's \mention{vegetable} are each maintained by mechanisms appropriate to their domain~-- reproductive biology for one, flavour chemistry and culinary tradition for the other. Each projects reliably within its field.

The tomato problem is a problem only if you assume projectibility is absolute~-- that a category either projects or doesn't, full stop. Once you recognize that projectibility is field-relative, the problem dissolves. What remains is the work of specifying which category projects for which purposes.

\subsection{Proper nouns and proper names}
\label{sec:7:proper-nouns-names}

Linguistics has its own tomatoes. Consider the distinction between \term{proper noun} and \term{proper name}.

A semanticist works with \term{proper names}: expressions that refer directly to individuals without descriptive content, that are rigid designators (picking out the same individual across possible worlds), and that create referential opacity (\enquote{Lois believes Superman can fly} doesn't entail \enquote{Lois believes Clark can fly}). These properties cluster because of the cognitive and communicative functions names serve: tracking individuals across contexts requires stable reference without shifting descriptive content.

A syntactician works with \term{proper nouns}: words that head nominal projections, resist articles in certain languages, trigger particular agreement patterns, and fill argument slots. These properties cluster because of distributional pressures: words that behave similarly in one syntactic environment tend to behave similarly in others.

The extensions overlap substantially~-- most expressions that are proper names are also proper nouns. But the overlapping extension doesn't mean they're the same category. They're different HPCs, maintained by different mechanisms, projectible for different purposes.

\begin{table}[t]
\centering
\caption{Two categories, overlapping extension}
\label{tab:proper-noun-name}
\begin{tabular}{lll}
\toprule
\textbf{Category} & \textbf{Field} & \textbf{What projects} \\
\midrule
Proper name & Semantics & rigid reference, opacity, individual-tracking \\
Proper noun & Syntax & heads NP, fills argument slot, triggers agreement \\
\bottomrule
\end{tabular}
\end{table}

A syntactician \emph{knows} that \mention{Brett} is a proper name. But that semantic fact doesn't project for syntactic purposes. What projects syntactically is the distributional chain: \mention{Brett} heads a nominal phrase $\rightarrow$ fills a subject slot $\rightarrow$ triggers third-person singular agreement. The syntactician can reliably predict that novel proper nouns will behave distributionally like familiar ones. The proper-name status is real but orthogonal to that prediction.

This isn't esoteric. Every introductory syntax course teaches students to distinguish \enquote{what a word means} from \enquote{how it behaves}. What hasn't been articulated is why this distinction exists: because meaning and behaviour are tracked by different mechanisms, and different mechanisms produce different HPCs. The field-relativity of projectibility explains why syntacticians can't just read off predictions from semantics, and vice versa.

\subsection{Constituency and dependency}
\label{sec:7:constituency-dependency}

The same logic applies to rival syntactic formalisms. Phrase-structure grammars, like CGEL's, represent sentences as hierarchies of \term{constituent}s~-- noun phrases, verb phrases, clauses nested inside each other. Dependency grammars, like \citeauthor{gibson2025}'s (\citeyear{gibson2025}), represent sentences as networks of \term{dependency relation}s~-- subject-of, object-of, modifier-of~-- linking words directly without intermediate phrasal nodes.

The rivalry is old, but the maintenance view dissolves the \enquote{which is \emph{real}?} framing. Both formalisms track genuine structure, maintained by mechanisms, projectible for different purposes.

Constituency is maintained by substitution, movement, and coordination: expressions that can be pronominalized together, fronted together, or conjoined are grouped as constituents. Knowing that \mention{the cat} is a noun phrase lets you predict it can be replaced by \mention{it}, moved to topic position, or coordinated with \mention{the dog}. The category projects for questions about \emph{what groups with what}.

Dependency is maintained by processing constraints: working memory tracks which words await completion, and dependency length predicts reading time and comprehension difficulty \citep{gibson2000,futrell2020}. Knowing that a verb governs a distant subject lets you predict processing slowdown. The category projects for questions about \emph{what costs what}.

The extensions overlap~-- every sentence can be described both ways~-- but the HPCs are distinct. A syntactician asking \enquote{what can move together?} needs constituency. A psycholinguist asking \enquote{why is this sentence hard?} needs dependency. Neither formalism is epiphenomenal; each tracks mechanisms relevant to its questions. The debate is dissolved, not decided.

This fits naturally with what \textcite{carroll2016} calls \term{poetic naturalism}: a sparse naturalistic metaphysics paired with a permission structure for higher-level vocabularies. Poetic naturalism tells you when it's licit to treat a vocabulary as tracking something real~-- when the description captures a pattern that admits information-compressing, predictively useful summary, and when it coheres with descriptions at other grains \citep{dennett1991}. The HPC framework tells you one way those patterns stay put: by specifying the mechanisms that maintain the clustering. Constituency is real because substitution, movement, and coordination actively cluster the relevant properties; dependency is real because memory constraints actively shape the cluster. The poetry has plumbing.

\subsection{Why colour doesn't grammaticalise}
\label{sec:7:colour}

The constituency/dependency case and the proper-name case both stay within linguistics~-- different subfields or formalisms carving the same extensions differently. A starker example crosses domains entirely: colour.

Colour is maximally salient. Trichromatic vision evolved because colour predicts things that matter for survival: fruit ripeness, toxicity signals, mate health, camouflage. The warm/cool boundary shows categorical perception~-- adults distinguish warm from cool colours faster than they distinguish within either category \citep{holmes2017}. Colour terms partition efficiently across languages, with the warm/cool split emerging early in colour-vocabulary evolution \citep{kay1978}. If any perceptual domain should grammaticalise, colour should.

It doesn't. Noun-classification systems regularly encode animacy, shape, and size~-- but never colour. No documented language has verb agreement triggered by whether the subject is warm- or cool-coloured. The warm/cool distinction is robust, salient, and cross-linguistically stable in the lexicon. Yet it's entirely absent from closed-class morphology \citep{seifart2010}.

\citet{prasertsom2026} tested whether this gap reflects domain-specific constraints on grammar~-- a hard-wired filter excluding colour from the set of possible grammatical features~-- or something more general. Their experiments compared animacy-based and colour-based noun-class learning in an artificial language. Participants learned both, but animacy-based classes were learned better. More strikingly, when the input was ambiguous between animacy and colour as the classification basis, participants overwhelmingly inferred animacy~-- 77.5\% generalised to animacy, nearly half of them categorically.

This bias isn't grammar-specific. In a non-linguistic sorting task, the same preference appeared: participants sorted images by animacy rather than colour, even when the experimenters manipulated within-category similarity to favour colour. The bias persisted across three stimulus sets designed to progressively disadvantage animacy.

What drives the asymmetry? Not salience~-- colour is as perceptually salient as animacy. The answer lies in predictive structure. Knowing something is animate predicts a cluster of other properties: self-initiated motion, goal-directedness, organic composition, susceptibility to certain event roles. These predictions hold regardless of what specific entity you're considering. Knowing something is red predicts little beyond its surface appearance~-- and what it does predict (ripeness, toxicity) is object-relative. Red means different things for apples, frogs, and traffic lights.

\citet{prasertsom2026} confirmed this computationally. They extracted word embeddings for 472 frequent physical nouns from child-directed speech and clustered them by animacy versus colour. Animacy-based clusters were more compact and more distinct; logistic classifiers learned animacy categories faster and generalised better to unseen nouns~-- without any built-in knowledge of animacy. The distributional structure of language itself encodes the asymmetry.

This is purpose-relative projectibility across domains. Colour is projectible \emph{for ecological purposes}: predicting edibility, danger, health. The mechanisms stabilizing colour categories are perceptual and action-guiding~-- they evolved to support decisions about what to eat, avoid, or approach. But grammar serves different purposes: argument realisation, reference tracking, event-structure encoding. Animacy predicts properties relevant to those purposes; colour doesn't.

The upshot isn't that colour categories are fake or that grammatical categories are special. Both are HPCs, maintained by mechanisms appropriate to their domains. What differs is the domain of projectibility. Evolution gave us colour vision because colour projects for survival-relevant inferences. It didn't give us colour-based agreement because colour doesn't project for grammatical inferences. The same extension~-- red things, warm-coloured things~-- supports robust categorisation in one domain and fails to support it in another.

This extends the proper-name pattern. \term{Proper name} projects for semantic purposes; \term{proper noun} projects for syntactic purposes. \term{Warm-coloured} projects for ecological purposes; nothing projects it for grammatical purposes~-- so nothing grammaticalises. The framework doesn't multiply categories recklessly; it asks what cluster of properties is maintained by what mechanisms, and whether that cluster projects for the questions you're asking. Chapter~\ref{ch:lexical-categories} returns to animacy in its analysis of noun/verb stability.


\subsection{Preview: Part III as demonstration}
\label{sec:7:preview-part-iii}

This pattern~-- overlapping extensions, distinct HPCs, field-relative projectibility~-- structures the case studies in Part~III.

Chapter~\ref{ch:countability} shows that \term{countability} decomposes into semantic individuation (boundedness, discrete enumeration) and morphosyntactic count-marking (plural inflection, quantifier selection). \mention{Furniture} individuates semantically~-- you can count chairs~-- but patterns morphosyntactically as mass. The semantic and morphosyntactic clusters are maintained by different mechanisms and project for different analytical purposes.

Chapter~\ref{ch:definiteness-and-deitality} shows that definiteness and deitality are distinct HPCs with overlapping extensions. \term{Definiteness}~-- identifiability, uniqueness, familiarity~-- projects for semantic purposes. \term{Deitality}~-- the morphosyntactic properties that pattern with definite articles~-- projects for syntactic purposes. The literature's confusion about \enquote{weak definites} and \enquote{generic definites} arises from treating these as one category when they're two.

Chapter~\ref{ch:lexical-categories} shows that the noun/verb contrast is crosslinguistically stable because both semantic and morphosyntactic mechanisms reinforce it, while adjective categories vary because the mechanisms don't align as tightly.

Chapter~\ref{ch:proform-gender} traces the maintenance spectrum from semantically transparent to purely entrenched. English gender is designatum-driven~-- pronouns track perceived personhood. French gender is entrenchment-driven~-- antecedent form controls the pronoun with no semantic grounding. The same category label names different HPCs with different mechanisms.

Chapter~\ref{ch:the-category-zipper} then synthesizes the case studies, mapping how coupling tightness (§\ref{sec:8:coupling}) varies across the linguistic stack~-- from the hard-coupled phoneme to the loosely coupled grammatical category to the re-unified construction.

The framework doesn't multiply categories recklessly. It asks, for each analytical purpose: what cluster of properties is maintained by what mechanisms, and does that cluster project for the questions you're asking? Sometimes the answer is a familiar category; sometimes it's a refinement of one; sometimes it's a recognition that what looked like one category was two.

\subsection{The discipline: three checks}
\label{sec:7:three-checks}

The slogan~-- \emph{profile, stabilized by mechanisms, projectible relative to purposes}~-- maps onto three diagnostic checks:

\begin{enumerate}
    \item \textbf{Cluster check.} Does property covariance hold across samples and contexts? If the properties don't cluster, there's no profile to explain.
    \item \textbf{Homeostasis check.} Can we identify perturbations where the cluster reconstitutes (or fails)? If we can't, we haven't identified the mechanism.
    \item \textbf{Projectibility check.} Are there counterfactual-supporting inferences in new contexts? If learning about one member doesn't tell you about others, the category isn't earning its keep.
\end{enumerate}

Crucially, these checks can yield different answers for different fields. A category might pass all three for syntax and fail the projectibility check for semantics. That's not a defect of the framework~-- it's the framework working. The checks aren't absolute; they're indexed to purpose.

This discipline guards against two temptations. First, the essentialist temptation: treating one field's category as the \enquote{real} one and others as derivative. If proper names are semantically fundamental, proper nouns must be \enquote{just} the syntactic reflection of semantic reality. But the mechanisms are different; neither is derivative. Second, the nominalist temptation: treating categories as arbitrary conventions because different fields carve differently. But the carving isn't arbitrary; each field's categories are maintained by mechanisms appropriate to that field's explanatory goals.


\section{The epistemic payoff}
\label{sec:7:epistemic-payoff}

The aspect case shows that even a descriptively real category can fail to project if its definition misaligns with its maintaining mechanisms. This misalignment clarifies a classic problem in the philosophy of science.

Liu Cixin's turkey parable captures the problem of induction with dark precision:

\begin{quote}
Every morning on a turkey farm, the farmer comes to feed the turkeys. A scientist turkey, having observed this pattern to hold without change for almost a year, makes the following discovery: \enquote{Every morning at eleven, food arrives.} On the morning of Thanksgiving, the scientist announces this law to the other turkeys. \citep[ch.~6]{liu2008}
\end{quote}

The turkey's law is perfectly confirmed by all available evidence. The problem isn't the evidence; it's that the law isn't grounded in mechanism. The farmer's purpose~-- invisible to the turkey~-- determines when the correlation breaks. Had the turkey understood \emph{why} food arrives (fattening for slaughter), it would've predicted its own demise rather than its next meal.

Nelson Goodman's \mention{grue} problem makes the same point in philosophical dress. Goodman's riddle: emeralds examined before time $t$ are green; emeralds examined after $t$ are blue. Define \mention{grue} as \enquote{green if examined before $t$, blue otherwise}. Every emerald we've ever observed is grue. So why don't we project \mention{grue} to unexamined emeralds?

Goodman's own answer invoked entrenchment: \mention{green} is projectible because it's been projected successfully in the past. \mention{grue} isn't because it hasn't. The circularity is deliberate~-- projectibility is bootstrapped from track record.

This observation shaped a tradition. \citet{quine1969} argued that the success of induction presupposes natural kinds: we project properties because we assume the instances we've observed are \enquote{of a kind} with those we haven't. \citet{kornblith1993} went further, arguing that induction works precisely because natural kinds exist in the world~-- the clustering of properties in those kinds underwrites our ability to learn from experience. On this view, projectibility isn't just a pragmatic feature of our language; it's evidence that we've latched onto something real.

The maintenance view dissolves the circle. A habit isn't self-grounding; it's sustained by something. The stream's habit of flowing in a particular channel persists not because it has flowed there before but because water, gravity, and geology maintain it. \term{Green} is projectible not because it has been projected (Goodman's bootstrap) but because mechanisms sustain the would-be: chromium traces interact with light in stable ways; a visual system tuned by selection detects the reflectance. There's no mechanism that produces grueness~-- nothing about emeralds that would make them switch from green to blue at time $t$. Projectibility tracks mechanism, not predicational habit. Goodman saw the habit but not what sustains it.

For linguistic categories, the same logic applies. \term{Noun} is projectible because mechanisms like acquisition, entrenchment, and functional pressure keep nominal properties clustering together. A pseudo-category like \mention{nerboun} (noun if acquired before age 5, verb otherwise) isn't projectible because no mechanism produces that pattern~-- there's nothing about language acquisition that would cause a switch at age 5.

A category can look like a good bet~-- its definition correlates with usage, its label is entrenched~-- and still turn out to be a turkey.

\subsection{Is projectibility interest-relative?}
\label{sec:7:interest-relativity}

\citet{craver2009} and \citet{onishi2022} argue that any mechanism-based account inherits context-dependence. Which mechanism you attend to, at what level of abstraction, with what boundaries~-- all depend on your explanatory goals. If so, the maintenance view answer to Goodman looks circular: a category is projectible relative to the mechanism you're interested in, and the mechanism you're interested in is whichever one makes the category projectible.

The key distinction is between choosing a level because it answers your question, and choosing a level because it privileges your category. A pedicab can be explained by engineering (frame geometry, gear ratios) or by physics (forces, friction, momentum). Both levels are real; both describe genuine causal structure. Your question selects the level. But the causal structure at that level determines whether your answer is correct. Interest picks the question; it doesn't fabricate the mechanism that answers it.

This is precisely what went wrong with the turkey. Its interest was survival, but it coarse-grained at the wrong level: time of day rather than time of year. The correlation was real at one level (11 AM $\rightarrow$ food) but collapsed at another (Thanksgiving $\rightarrow$ slaughter). The turkey's interest didn't invent the mechanisms; it just selected the wrong one to track.

For linguistic categories, the same logic applies. If your question is ``what triggers perfective here?'' the answer lives at the cue-structure level, not the semantic-definition level. Both levels exist; the semantic level just doesn't answer the production question. The aspect case shows the stakes: if your goal is to predict corpus distributions, or even to teach people to speak Polish, the textbook mechanism (semantic boundedness) is the wrong one~-- it predicts imperfective well and perfective poorly. If your goal is to predict native-speaker gap-filling, the lemma-concrete mechanism is the right one~-- it outperforms aspect-aware models. The prediction either succeeds or fails. That's the empirical constraint on which mechanism matters.

Conventionalism can't explain why some mechanisms predict and others don't. The maintenance view can: the mechanisms that predict are the ones that actually maintain the cluster. Interest selects among real causal structures; it doesn't invent them. This is what \citet{carrollparola2024} mean by emergence: coarse-grained descriptions that support accurate predictions despite discarding micro-level information. The key is coarse-graining \emph{in the right way}~-- throwing away arbitrary information destroys predictability, but discarding the right information preserves it.

\citet{lemeire2018} argues that no purely epistemic theory~-- one that defines natural kinds solely by their inductive usefulness~-- can account for naturalness. If all we require is that a category support successful predictions, what distinguishes a natural kind from a merely convenient grouping? The objection is serious, and it's what the maintenance view is designed to answer. Projectibility alone is too permissive; what's needed is the right \emph{kind} of projectibility~-- the kind that comes from genuine homeostatic mechanisms rather than accidental correlations. The turkey's law was projectible until Thanksgiving; a mechanism-grounded law would've predicted the farmer's purpose. The maintenance view doesn't abandon epistemic criteria; it requires that they be grounded in causal structure. Projectibility is evidence of mechanism, not a replacement for it.\footnote{\citeauthor{khalidi2013}'s (\citeyear{khalidi2013}) ``nodes in causal networks'' account illustrates the difference. NPIs, for instance, are causally grounded in one sense~-- they share semantic sensitivity to negative contexts. What they lack is the homeostatic mechanism that would make them an HPC kind. They're stable at equilibrium rather than dynamically maintained: balls sitting at the bottom of a trough, not tops that must be spun to stay upright.}

This gives us a robustness criterion for mechanistic kinds. A genuine mechanistic kind~-- as opposed to a convenient label~-- should exhibit \emph{learning transfer}, \emph{intervention stability}, and \emph{cross-context generalisation}. Train on one subset, test on another: does it transfer? Intervene on the mechanism: does the pattern shift as predicted? Apply to a new context: does the generalisation hold? Labels without mechanisms should fragment under these pressures; mechanisms should persist. The computational evidence in this chapter~-- lemma-concrete models transferring to unseen verbs, cue--outcome associations generalising across tense frames~-- is exactly this kind of robustness test. The realism isn't permissive (``whatever predicts is real''); it's constrained by stability under perturbation.

Once interests are fixed by a task, we can ask how strongly different categories support that task. This is the next implication of mechanistic grounding: projectibility comes in degrees. (Recall that field-relative projectibility~-- §\ref{sec:7:field-relative}~-- is a distinct point: the same extension can be carved by different HPCs for different fields. What follows concerns degrees of projectibility \emph{within} a single field.)

\subsection{Degrees of projectibility}
\label{sec:7:degrees-projectibility}

Not all categories are equally projectible. The framework expects a gradient, and the evidence supports it.

At one extreme: high-frequency, highly entrenched categories where the mechanisms are strong and consistent. English determinatives are a case: a closed class, stable across speakers, predictable in distribution. Learn \mention{each} and you can project to \mention{every} with high confidence. The mechanisms (entrenchment, functional specificity) are tight enough that the category approaches definitional coherence~-- the mechanisms are so strong that they produce uniform clustering.

At the other extreme: low-frequency, loosely maintained categories where the mechanisms are variable or in flux. Nonce formations, idiolectal forms, constructions undergoing change~-- these are less projectible because the mechanisms haven't stabilized. Knowing about one instance tells you less about others.

The middle ground is where the action is. Within a language, synchronically, major open classes~-- nouns, verbs, adjectives~-- are projectible on average but variable at the margins. You can project from typical nouns to novel nouns with high confidence; you can project from \mention{fun} to other adjective-noun boundary cases with less. The mechanisms are strong enough to produce robust clustering at the core but not strong enough to determine the periphery.

The prediction is testable: core category members~-- high-frequency, prototypical, functionally central~-- should elicit consistent judgments; peripheral members~-- low-frequency, boundary-straddling, functionally ambiguous~-- should elicit variable ones. The variance isn't noise; it's the signature of weak entrenchment.

Recent experimental work confirms the pattern. In grammaticality judgments for Dutch syntax, peripheral structures are correctly identified only 57\% of the time (SD $\approx$ 0.27), while core structures are correctly identified 90\% of the time (SD $\approx$ 0.09)~-- the variance triples at the periphery \citep[Table~2]{favier2021}. Similarly for syntactic variants indexed to verb frequency: low-frequency verbs elicit higher acceptance of violations (a fourfold increase in error rates: 6.58\% vs.\ 1.58\%), because weak entrenchment permits wider variation in what speakers treat as grammatical \citep{sassenhagen2018}. In morphology, the pattern is starker still: high-frequency English adjectives elicit near-unanimous agreement on comparative form, while low-frequency and nonce adjectives split speakers \citep{grazianoking2005}.

This is what the maintenance view predicts. Where mechanisms are strong and consistent, judgments converge; where mechanisms are weak or variable, judgments diverge. The variance tracks the strength of the causal structure. Projectibility isn't all-or-nothing; it's graded by entrenchment. Crucially, the variance isn't just about the items; it's about the speakers. Low-frequency forms are ``weakly entrenched'' only in aggregate~-- for any given form, some speakers have encountered it often, others rarely, others never. What looks like category fuzziness at the population level is actually speaker-by-speaker variation in experience \citep{dabrowska2012}. This reinforces the maintenance account: categories fail to project uniformly because the maintaining mechanisms haven't operated uniformly across the population.


\subsection{What the framework offers}
\label{sec:7:what-framework-offers}

The argument so far has been negative: traditional definitions don't ground projectibility; mechanisms do. But this raises a question for researchers who already study mechanisms. If you're already tracking entrenchment, distributional learning, alignment, or functional pressure, what does the maintenance view add? Isn't this just new terminology for what you were doing anyway?

The answer is that the framework offers something beyond the mechanisms themselves: an account of what the mechanisms are \emph{for}. Most mechanistic research is descriptive in a specific sense~-- it shows how patterns emerge, stabilize, and change. What it often lacks is an explicit ontology. Are the categories that emerge from these mechanisms \emph{real}, or are they convenient fictions? Are they features of speakers' minds, of the speech community, or merely of the analyst's framework? The maintenance view provides an answer: categories are real to the extent that they're maintained by consistent mechanisms. The mechanisms don't just produce the patterns; they \emph{constitute} the categories as natural kinds.

This matters for several reasons.

First, it legitimises mechanistic work as theory, not just description. A sceptic might object that studying entrenchment or alignment is interesting but atheoretical~-- mere data-gathering that falls short of explanation. The maintenance view says: no. The mechanisms \emph{are} the theory. Understanding how categories are maintained is understanding what makes them real. This is analogous to recognizing that natural selection isn't ``just'' a description of breeding patterns but the actual explanation of adaptation.

Second, it provides cross-camp coherence. Researchers studying entrenchment, alignment, distributional learning, and iterated transmission are often working in different sub-fields with different terminologies. The maintenance view offers a unifying frame: all are studying maintenance mechanisms for the same kind of category. This isn't eclecticism~-- it's convergence. Different instruments trained on the same phenomenon. The framework doesn't adjudicate between mechanisms; it says that \emph{whichever} mechanisms actually maintain the cluster are the ones that matter. The question becomes empirical: which mechanisms predict? Chapter~\ref{ch:what-changes} shows how agent-based modelling provides one way to test such predictions computationally.

Third, it reorients methodology. The maintenance view makes prediction the success criterion: does the mechanism predict behaviour? This changes what counts as evidence. Individual variation stops being noise to be averaged away and becomes signal: if different speakers show different patterns, that tells you something about how tightly the mechanisms are operating. The gradient nature of projectibility~-- strong at the core, weak at the periphery~-- is a feature of maintenance, not a defect of the category.

Fourth, it offers category realism without essentialism. Many researchers working with mechanisms are implicitly anti-realist about categories~-- they treat category labels as convenient shorthand, not as picking out real kinds. The worry is understandable: if there are no essences, what makes categories real? The maintenance view provides the missing piece. Categories are real \emph{because} of mechanisms, not despite lacking essences. The mechanisms do for categories what essences were supposed to do: explain why members resemble each other, why learning about one tells you about others, why the category is projectible. You don't need to choose between realism and mechanism; mechanism \emph{underwrites} realism.

Fifth, it clarifies the relationship between historical origin and synchronic maintenance. The volcanic island metaphor applies here: what built a category may not be what maintains it. Researchers studying grammaticalization, semantic drift, or language change often face a puzzle: if categories evolved for one reason, but now function differently, what's their current status? The framework says: study the current mechanisms. Whether or not the historical origin matches the current maintenance, it's the current mechanisms that determine projectibility. You can trace the genealogy without claiming that genealogy is destiny.

None of this requires abandoning existing research programmes. The mechanistic work continues; what changes is its framing. The maintenance view shows how categories can be both analyst-labelled and grounded in real causal structure. The work you're doing isn't preliminary; it's the payoff.

\bigskip

We can now answer the question that opened the chapter. Mr.~Tagomi needed to know which world he was in; learners of Polish need to know which verb form to use. Both rely on projectibility. Why should learning about one instance tell us anything about others?

Because the same mechanisms that shaped the instance you learned are shaping the instances you haven't. Categories maintained by consistent mechanisms produce consistent members. The consistency underwrites induction.

This is the epistemic payoff~-- what the good bet wins. HPC kinds are categories you can learn from, categories with causal structure. The mechanism that makes a word a noun also makes other nouns. The mechanism that biases a verb toward perfective also biases similar verbs. The mechanism that entrains a speaker to one usage pattern entrains the same speaker to related patterns.

Projectibility isn't metaphysically guaranteed. A proposed grouping can fail to project if its characterization doesn't match the maintaining mechanisms~-- as aspect-abstract fails. A proposed grouping can fail to project if the mechanisms are too weak or too variable~-- as nonce formations fail. In either case, the grouping isn't a category but a \term{class}~-- a label without the causal structure to back it up. But where the mechanisms are real and consistent, projectibility follows. That's the test: does learning about instances let you project to the kind? If yes, the mechanisms are real. If no, look elsewhere for the causal structure.


The label names the island, not the volcano. But if categories are maintained, they can also fail to be maintained~-- or be maintained too loosely, or in ways that don't project.

The next chapter asks: how do we know when we don't have a kind~-- when what we're tracking is a label or a short-lived fashion rather than a mechanism-maintained cluster? What does failure look like, and what does it teach us about the categories that succeed?


Part~III then returns to field-relative projectibility with three extended case studies. Countability, definiteness, and word classes each demonstrate the pattern developed here: categories that decompose into semantic and morphosyntactic HPCs, maintained by distinct mechanisms, projectible for different analytical purposes. The framework isn't abstract philosophy; it's an operational tool for understanding why familiar categories behave as they do.

\textsc{Definiteness thread.} This chapter's field-relative projectibility principle predicts that definiteness generalizations should be projectible for semanticists studying identifiability and uniqueness, while deitality generalizations should be projectible for syntacticians studying \mention{there}-resistance and partitive licensing~-- but only where the stabilizer stories match. Register shift (e.g., legal versus colloquial) may reveal where the clusters decouple: weak definites and generic definites are predicted sites. The prediction would be falsified if a single unified projectibility claim held across all analytical purposes without stabilizer-specific scoping.
