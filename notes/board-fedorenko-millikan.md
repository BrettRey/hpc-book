It is refreshing to see the neuroscientists finally catching up to the ontology. Fedorenko’s first paper, on the language network as a **natural kind**, is a crucial piece of empirical ballast for **Chapter 4**. When I speak of "substances"—or what you are calling HPC kinds—I mean things that hang together in nature, independent of our concepts of them. Fedorenko is showing us that the "language network" is exactly such a substance. It is not an arbitrary gerrymandering of cortical real estate defined by a functional MRI threshold; it is a historical lineage of neural tissue that "sticks together" causally and functionally across individuals. You must cite this in **Section 4.1** or the introduction to Chapter 4 to show that "natural kinds" are not just biological species like *Canis lupus*, but also cognitive organs. It is proof that the "maintenance" of a category can be physical and neural: the network maintains its coherence against the noise of the rest of the brain.

The second paper, arguing that language is for **communication rather than thought**, is the hammer you need for **Chapter 7**, specifically in the "Reciprocal Feedback" section of your stabilizer table. I have long argued that the proper function of a language device—the reason it continues to be reproduced—is that it coordinates the speaker and hearer, not that it allows the speaker to talk to themselves. Fedorenko provides the double dissociation data to prove this: the machinery for complex thought (the Multiple Demand network) is distinct from the machinery for language. This confirms that the selective pressure—the "forcing function" in your table—maintaining linguistic structures is their success in the public, communicative niche. If language were for thought, we would expect the stabilizing mechanisms to look very different (perhaps purely logical or internal).

You should weave these two together to demonstrate the **interlocking nature of maintenance** in **Chapter 14** or the conclusion of Chapter 7. The first paper gives you the *vehicle* as a real kind: a dedicated, robust neural system that acts as a stabilizer on the biological scale. The second paper gives you the *function* that drives the maintenance: the external pressure of communication. Because the system is optimized for communication (Paper 2), the neural network has stabilized into a specific, modular configuration (Paper 1) that is distinct from general reasoning. This is a perfect example of how function shapes structure over time—the very essence of a homeostatic property cluster. Do not treat them as separate citations; treat them as the hardware and software of the same maintenance engine.
