# Chapter 9 (Countability) — Board Feedback (Adele Goldberg)

## Overall take

This is a strong, engaging chapter with a clear empirical target and a welcome emphasis on *mechanisms* (acquisition, entrenchment, institutional forces, diachrony). The distinction between an **individuation cluster** and a **count morphosyntax cluster** is helpful, and the “tight-to-loose” hierarchy + quasi-count discussion is potentially the most original payoff.

From a construction-grammar perspective, though, much of what is presented as the distinctive contribution of the HPC framing currently reads as an application of standard usage-based constructionist ideas (form–meaning pairings, cue-based generalization, entrenchment/chunking, competition among expressions). To persuade construction grammarians, the chapter needs a sharper statement of what the HPC framework adds *over and above* an explicitly constructional account of the same facts.

---

## (1) Does the HPC framework add explanatory value beyond existing construction-grammar accounts?

### Where it *does* add value (or could, with small reframing)
- **Explicit diagnostics**: the “projectibility + homeostasis” test is potentially useful as a *meta-criterion* for deciding which generalizations in a constructional network deserve to be treated as robust categories (vs. loose descriptive groupings).
- **Internal structure with a principled geometry**: the tight→loose implicational hierarchy is a concrete claim about the *shape* of the system (triangular distributions; systematic partial membership) that goes beyond simply saying “constructions form families.”
- **Stability/instability explanation**: “functional anchoring” is a good move toward explaining why some pockets of the network resist analogical extension.

### Where it currently looks redundant (to a constructionist reader)
- The core mechanism—morphosyntactic cues ↔ inferred construal—*is already the default assumption* in Construction Grammar: constructions are pairings that support both comprehension and production, learned from usage, and strengthened by frequency.
- The homeostatic story is largely built from familiar usage-based ingredients (entrenchment, preemption/competition, chunking, analogy, acquisition generalization). As written, the chapter’s “traditional foil” is mainly **feature-bundle** accounts; it does not squarely engage existing constructionist accounts of count/mass flexibility, coercion, and constructional polysemy.

### What would make the HPC payoff feel real (rather than relabeling)
- Add a short subsection in “What does this buy us?” that explicitly compares **HPC vs. a usage-based constructional network** (not just [+count] features). Spell out *one* thing HPC predicts/explains that a standard constructional account would not automatically deliver (e.g., why the implicational hierarchy should have this ordering; why intermediate equilibria should exist and persist in specific ecological conditions; why certain perturbations should produce particular failure modes).
- Make it explicit that “countability” is not a property of *nouns* but of **noun uses in constructions** (CGEL’s “senses” point is good, but it’s currently easy to slide back into lexicalist phrasing). For construction grammarians, the natural object of explanation is the distribution of a lexical item across a family of constructions.

---

## (2) Is the “bidirectional inference” mechanism appropriately grounded?

The idea is right, but it needs tighter grounding and sharper mechanistic commitments.

### What’s solid
- The bidirectionality itself (form→construal in comprehension; construal→form choice in production) aligns well with constructionist assumptions.
- The acquisition discussion (children generalize across frames) is relevant and fits a learning-based coupling story.

### What’s underspecified (and risks circularity)
- “Bidirectional inference” sometimes functions as a label for the *observed correlations* rather than an independently specified learning/processing mechanism. In places the logic can sound like: properties cluster because inference links them; we know inference links them because the properties cluster.
- The account would benefit from a more explicit model of what gets learned: e.g., a **latent scalar** of individuation with construction-specific thresholds (your “tolerances”), learned by tracking distributional cues and updated by prediction error.

### What would strengthen grounding
- **Psycholinguistic anchoring**: cite/engage work showing that count/mass syntax guides real-time interpretation of unfamiliar nouns (and not just retrospective judgments). This is where “bidirectional inference” can be made empirically concrete.
- **Learning-theoretic clarity**: relate the “pressure to regularize” story to established usage-based learning mechanisms (frequency-based entrenchment, competition/preemption, error-driven updating). If you mean Bayesian inference, say so; if you mean exemplar similarity/analogy, say so.
- **Scope discipline**: be careful not to treat every stabilizing factor as part of the same mechanism. Institutional norms, entrenchment, and acquisition are plausibly distinct *forces*, but the chapter would read as more rigorous if it distinguished (i) what operates within an individual grammar vs. (ii) community-level standardization.

---

## (3) What would strengthen the argument *for a construction grammarian*?

### 1) Make the constructional inventory explicit
Right now the “locks” are evocative, but a constructionist reader will want to see the actual **family of constructions** that defines the count/mass system (e.g., [Det a N], [Num N-pl], [many N], [much N], partitives like [piece of N], measure phrases, packaging/grinding uses). A simple network figure (even schematic) would immediately align the chapter with Construction Grammar practice.

### 2) Address coercion and polysemy head-on
The Jespersen examples you mention (mass→count, count→mass) are central for constructionists: they show that constructions can *coerce* readings. If countability is a basin/attractor, then coercion cases are exactly the “controlled perturbations” you can use to show how speakers shift construal *without* changing the lexeme’s stored profile. Treating these as part of the system (not just footnotes) would make the argument feel constructional.

### 3) Tighten the empirical basis for the hierarchy claim
The implicational “triangular” prediction is attractive, but it is also the sort of universal-sounding claim that invites counterexamples.
- Clarify that the hierarchy is about **uses/senses in constructions**, not about nouns simpliciter.
- Where possible, support the hierarchy with broader data than a handful of illustrative nouns (even a small corpus sample across many nouns, or acceptability data for a larger set, would help).

### 4) Translate “functional anchoring” into competition/preemption terms
Your “anchoring” explanation is very compatible with constructionist thinking, but it will land more convincingly if you connect it to familiar mechanisms: speakers choose among competing conventionalized expressions; frequent competitors can block extension of a would-be generalization. Make the competition story explicit.

### 5) Clarify what “HPC kind” amounts to in a usage-based grammar
For construction grammarians, “kinds” are often *emergent generalizations over stored form–meaning pairings*. If that’s also your view, say so directly: HPC then names the *stability profile* of a constructional generalization (high cue validity + multiple reinforcing feedback loops), not an extra ontological commitment over the constructional network itself.

