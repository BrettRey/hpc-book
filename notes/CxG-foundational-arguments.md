# Construction Grammar's foundations: argued or assumed?

The short answer is nuanced: CxG theorists provide **substantive arguments** for their foundational claims, but these arguments are primarily **empirical and methodological** rather than philosophical derivations from first principles. The form-meaning pairing thesis is largely **definitional** at its core but supported by parsimony arguments; the uniformity thesis ("all the way down") receives **explicit argumentation**, though critics contend these foundations may be unfalsifiable.

## The symbolic thesis functions partly as definition, partly as discovery

The claim that constructions are form-meaning pairings operates at two levels in CxG literature. At the foundational level, it is essentially **definitional**—inherited from Saussurean semiotics and the sign-based tradition. Goldberg (1995) explicitly states this is "the basic tenet inherited from Fillmore & Kay," not something she derives independently. Langacker's Cognitive Grammar makes the same move: grammar is "symbolic in nature" where a symbol is "the pairing between a semantic structure and a phonological structure."

However, CxG theorists provide **substantive supporting arguments** beyond mere stipulation. The most powerful is Goldberg's "implausible verb senses" argument: if meaning came only from lexical items, we would need to posit that *sneeze* has a three-argument sense 'X causes Y to move Z by sneezing' to account for "He sneezed the napkin off the table." No language encodes such meanings in simple morphemes. This parsimony argument shows that **attributing meaning to constructions avoids theoretical implausibility**.

Fillmore, Kay, and O'Connor's foundational 1988 "let alone" paper provides the original empirical justification. They demonstrate that formal idioms are simultaneously productive, syntactically rule-governed, AND have idiosyncratic semantic-pragmatic properties—properties that "no current formal approach to grammar" could accommodate. The argument is that compositional semantics cannot predict meaning, pragmatics cannot be modularly separated from syntax, and the same notation needed for idioms must extend to regular patterns.

The Carlson, Fábregas & Putnam (2021) critique in *Frontiers* identifies a genuine problem: Generative Grammar's functional categories **also** pair meanings with structures. As Adger (2012) puts it, "no empirical argument can be made on the basis of claims that semantics attaches to structures rather than words, given that both CxG and GenG allow this." The symbolic thesis may be **less discriminating** than CxG theorists suggest.

## The uniformity thesis receives explicit but contested argumentation

The claim that "it's constructions all the way down" (Goldberg 2006: 18)—that there is no principled lexicon/grammar distinction—is where CxG theorists provide their **most explicit arguments**, though these remain contested.

Croft's "Radical Construction Grammar" (2001) offers the strongest argumentative structure through three interconnected claims. First, his **cross-linguistic variation argument**: typological evidence shows putatively universal categories (Noun, Verb, Subject, Object) are not consistent across languages. English, Big Nambas, and Japanese treat property-denoting words entirely differently, undermining the "building block" model of universal categories. Second, his **distributional analysis argument**: if categories are defined by distribution, and distributional analysis across constructions yields different category extensions, then selecting only certain constructions as "tests" constitutes "methodological opportunism." Third, his **circularity argument**: the building-block model says constructions are defined by categories, while distributionalism says categories are defined by constructions—accepting both is circular.

Fillmore's original work frames this as the **continuum argument**: idioms, semi-productive patterns, and fully productive rules form a cline, and "there is no sense in treating the constructions of a language as belonging to qualitatively different categories on the basis of their degree of productivity." The 1988 paper argues explicitly that "the machinery needed for describing the so-called minor or peripheral constructions... will have to be powerful enough to be generalized to more familiar structures."

Goldberg advances a **parallels argument**: words and grammatical patterns share properties—both can be lexically filled or abstract, compositional to variable degrees, polysemous, learned from input, and organized in inheritance hierarchies. She treats this as justifying a unified representation.

## Cognitive science provides independent grounding—with caveats

CxG's strongest justificatory move may be its appeal to broader cognitive science, which provides **independent motivation** for both foundational claims.

Langacker explicitly grounds Cognitive Grammar in "psychological plausibility" and "domain-general cognitive abilities." Usage-based theory (Bybee, Tomasello) identifies specific cognitive processes—**categorization, chunking, rich memory storage, analogy, cross-modal association**—that are documented independently of language and can explain how constructions emerge from experience. Tomasello's acquisition research demonstrates children acquire language through general cognitive abilities (intention-reading, pattern-finding) rather than innate grammar, with **item-based constructions** preceding abstraction.

Exemplar theory provides particularly strong support for the uniformity thesis. If linguistic knowledge consists of stored exemplars clustered by similarity, with abstract categories emerging from exemplar clouds, there is no principled distinction between "lexical" and "grammatical" storage—both are exemplar-based. Prototype theory (Rosch, Lakoff) shows linguistic categories exhibit graded structure like non-linguistic categories, with experimental evidence that abstract constructions like the transitive show prototype effects (Ibbotson et al. 2012).

**However, critics identify gaps**. Adger cites Yang's work on Zipfian distributions showing "a conservative, usage-based learner of the sort envisaged by Goldberg will never generalize from item combinations to productive rules." Hoffmann (2020) notes neurolinguistic evidence of "distinct neurophysiological responses being elicited by lexical items and combinatorial constructions"—potentially challenging the continuum claim at the neural level.

## Critics expose the stipulative-empirical ambiguity

The most pointed meta-theoretical critique comes from Bert Cappelle's (2024) "Can Construction Grammar Be Proven Wrong?" He argues CxG faces serious **falsifiability problems**: individual constructions may be difficult to falsify experimentally, and no clear "crucial test" exists that would falsify CxG as a theory. This echoes the concern that CxG can accommodate any data by postulating new constructions.

Adger's generativist critique cuts deeper. He argues usage-based CxG "provides no way of stating general constraints on the organization of linguistic information... hence there is, in effect, no theory of language." The **constraint problem**—explaining why languages don't exhibit logically possible but unattested patterns—remains inadequately addressed.

Goldberg's 1995 definition is revealing: "C is a CONSTRUCTION iff C is a form-meaning pair such that some aspect of form or meaning is not strictly predictable from component parts." Critics note this risks being **self-fulfilling**—defining constructions into existence wherever irregularity is found. This is not automatically problematic (scientific concepts often start definitionally), but it places the burden on demonstrating **empirical consequences**.

Internal CxG debates further complicate matters. Van Trijp (2015) identifies "a fundamental rift between practitioners touching upon the role of grammar itself." Sign-Based Construction Grammar (Sag) requires formal constraints and type hierarchies; Radical Construction Grammar (Croft) demands typological validation; Goldbergian CxG emphasizes processing and acquisition. These variants make different epistemological commitments.

## The philosophical grounding remains underspecified

Notably absent from CxG literature is **deep philosophical derivation** of these foundations. The field draws on Wittgensteinian meaning-as-use and anti-essentialism, emergentist philosophy of mind, and rejection of modularity—but these connections are often implicit rather than rigorously developed.

The strongest philosophical case comes from Langacker's argument that grammar "reduces to patterns for the structuring and symbolization of conceptual content"—rejecting the autonomy of syntax as philosophically unmotivated. But this is more a negative argument (autonomy is unjustified) than positive grounding (why form-meaning pairings must be primitive).

CxG theorists might respond that **empirical adequacy is itself justification**—that demonstrating constructions handle data better than alternatives is all the justification needed. This pragmatic stance is consistent with functionalist methodology but leaves the meta-theoretical status of foundations ambiguous.

## Assessment: productive hypotheses rather than proven theorems

The overall picture that emerges is nuanced. CxG's foundational claims are **neither mere assumptions nor rigorously derived theorems**, but rather **productive research hypotheses** supported by:

- **Parsimony arguments**: Unified treatment avoids implausible lexical proliferation
- **Empirical demonstrations**: Formal idioms and acquisition patterns fit the framework
- **Methodological arguments**: Consistent application of distributional analysis yields construction-specific categories
- **Cognitive plausibility**: Domain-general processes documented independently can explain construction learning

| Claim | Status | Primary justification type |
|-------|--------|---------------------------|
| Form-meaning pairings | Definitional + supported | Parsimony, avoiding circularity |
| Uniformity thesis | Explicitly argued | Typological, methodological, parallels |
| Cognitive grounding | Well-supported | Independent cognitive research |
| Philosophical derivation | Underspecified | Implicit appeals to anti-essentialism |

The field's honest self-assessment might be Goldberg's implicit stance: "These foundations have proven empirically productive and cognitively plausible, avoiding problems that plague alternatives, and therefore should be adopted"—rather than "These foundations follow necessarily from first principles."

## Conclusion: justified but not derived

For someone working in the CGEL framework with a functionalist orientation, the critical question is whether CxG's arguments should be persuasive. The answer depends on what counts as justification. CxG provides **substantive empirical and methodological arguments** that go well beyond mere stipulation. The "let alone" paper, Croft's typological arguments, and the cognitive science grounding constitute genuine theoretical work.

However, **philosophical derivation is largely absent**. The form-meaning pairing thesis is taken as axiomatic from semiotic tradition; the uniformity thesis is argued via parsimony and empirical fit rather than necessity. Critics legitimately note that falsifiability criteria remain underspecified and that the constraint problem persists.

The most sophisticated reading is that CxG's foundations represent **well-motivated working assumptions** that have proven empirically productive, supported by converging evidence from acquisition, processing, and typology, and grounded in broader cognitive science—but they remain open to revision if strong counterevidence emerges. This is arguably appropriate scientific practice, though it differs from presenting these claims as self-evident truths or logical necessities.