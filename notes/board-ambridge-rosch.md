# Rosch on Ambridge (2020) and where to engage

Ambridge’s “radical exemplar” position sits closer to prototype theory than his rhetoric sometimes suggests. Prototype theory was never a commitment to *stored* definitions; it was an empirical claim about category structure and use: graded membership, family resemblance, and privileged “basic” grains that support inference and naming. A fully exemplar-based learner can still exhibit prototype effects (centrality, typicality gradients, cue validity) because those effects can fall out of the distribution of remembered instances. So, in your framing, the real point of contact is: **prototype structure is compatible with exemplar storage**, and the dispute is about whether any abstractions are *psychologically represented* versus *emergent summaries* of exemplars.

That distinction matters for HPC, because “no stored abstractions” is not the same as “no real kinds.” Prototype work already encouraged separating (i) how categories are *described* (shorthand labels like NOUN/VERB), (ii) how they are *implemented* in cognition (exemplars, summaries, schemas, mixtures), and (iii) why certain grains are *stable and inductively useful* (correlated features/relations plus pressures for cognitive economy). In other words: Ambridge is right to resist essences and rigid definitions; he overreaches when he treats the absence of explicit representations as evidence that the category is merely an epiphenomenal convenience. Your HPC contribution can be cast as: prototype-like graded structure is expected; what needs explaining is the **stability, projectibility, and grain** of that structure.

The honeycomb analogy is useful only if you state its limits. It nicely conveys “global regularity without a centralized blueprint,” which aligns with your maintenance emphasis; but it can mislead by implying that patterns that are emergent at the system level are therefore absent from individual cognition. Bees still have local rules and constraints that make hexagons likely; likewise, human learners have biases, memory limits, attention, and communicative alignment that can yield both exemplar effects and genuine generalizations. If you use the analogy, I would explicitly translate it into your terms: the “hexagon” corresponds to an attractor/regularity that is *maintained by local mechanisms*, not a proof that no abstractions of any sort exist.

For impact, engage Ambridge in **Chapter 4** as a foil in the essentialism–prototype–“radical exemplar” landscape, because that is where readers decide what problem HPC is solving. A short, crisp box could say: prototype theory gets you graded structure; radical exemplar is one way to implement it; HPC asks a different question—what makes the clusters real and stable—and answers via maintenance. Then return to Ambridge more substantively in **Chapter 5** when you enumerate candidate mechanisms: exemplar storage, similarity, analogical generalization, entrenchment, and alignment can be presented as plausible *homeostatic* processes. If you can only afford one sustained engagement, put it in Chapter 4 (to shape the reader’s map early) and let Chapter 5 refer back to it when you cash out the mechanistic details.
