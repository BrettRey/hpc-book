# Advisory Board Feedback: Chapter 11 (Word Classes)
## Ben Ambridge

**On word classes as HPC kinds:**

This chapter has considerable empirical weight. The claim that word classes emerge through acquisition and entrenchment—not as innate categories—sits squarely on ground my lab has occupied for two decades. You're right to foreground learning data.

**Experimental evidence for learned status:**

The critical evidence remains the same: children don't acquire word classes via unambiguous distributional cues. Nouns and verbs occupy overlapping syntactic slots; the distinction hardens through exposure and repetition. Our work on verb argument structure (and crucially, *overgeneralization errors*) shows entrenchment operates iteratively. Young children over-regularize *goed*, *breaked*—not because rules are rules, but because high-frequency exemplars create gravitational wells. As entrenchment increases, the basin deepens and irregular forms stabilise. That's mechanism-talk, not rule-talk. This supports your HPC framing: a property cluster (morphophonological form, argument patterns, semantics) maintained by iterated exposure and usage frequency.

**Entrenchment gradients across categories:**

Here's where the book should be explicit: entrenchment is *graded*, and word classes show it. Closed-class items (prepositions, determinatives) reach asymptotic stability faster than open-class (nouns, verbs, adjectives). Why? Frequency: closed classes saturate the input quickly. But also *structural role*: grammatical items have high cumulative contingency—they appear in more contexts, triggering more exemplars per token. This makes them more robust to perturbation. Conversely, adjectives (your adverb problem) occupy looser distributional niches and compete with adverbials. Less frequent, less anchored → slower entrenchment → more cross-linguistic variation. The Adjective Problem isn't architectural flaw; it's entrenchment asymmetry.

**Production/comprehension asymmetries:**

Don't overlook the asymmetry data. Comprehension precedes production; children understand argument structure before deploying it productively. This staggered entrenchment is diagnostic. It shows the category isn't "built in"—it's *constructed* through differential stabilisation of comprehension before action. That's your mechanism at work.

**Verdict:** Chapter 11 should drive this point harder: word classes *look* natural because entrenchment is deep. That's exactly what HPC kinds should do.
