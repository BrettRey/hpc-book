# Chapter 11 Feedback: Braided Categories and Multiple Proper Functions
*Ruth Millikan*

Your pronoun/focus-modifier puzzle is exactly the right kind of case for teleosemantics—but it reveals something deeper about how linguistic categories can wear multiple functional masks.

## Unified Function or Braided Ones?

The question you're dancing around: Can a category have *one* proper function that generates multiple distributional consequences? Or does the braiding itself—deixis, binding, alternative-quantification—signal genuinely *distinct* proper functions, merely unified by surface similarity?

I'd push toward the latter. If proper functions are what the evolutionary/learning history selects for, then "determiner resistance" isn't *itself* the proper function; it's a *downstream consequence* of three separate functional regimes. Each has its own learning history:

- **Deixis** (saturation via context): proper function to anchor reference to demonstrative space
- **Binding** (saturation via variable): proper function to create bound-variable dependencies  
- **Alternative-ranging** (saturation via question domain): proper function to establish quantificational scope over alternatives

Each mechanism trains speakers differently. Each has different failure modes. A deictic pronoun learned as contextual anchor will *resist* determiners because adding one violates the functional specification. An interrogative learned as a variable over alternatives will resist them for orthogonal reasons—the alternatives *are* the restrictor.

So: one surface fact (determiner resistance), three proper functions. The category is *braided* because speakers have grammaticalized three functional paths into a single distributional pattern. That's your HPC story—the stability comes from maintaining all three mechanisms in alignment, not from reducing them to one.

## The Interrogative Puzzle and Teleosemantics

This is the thorniest case, and it matters most. Interrogatives aren't deictic—context doesn't do the work. They're not simple anaphors either—there's no prior antecedent. Yet they resist determiners exactly as their cousins do.

In teleosemantics, content is fixed by what the sign was *selected for doing*. So: what was a \mention{wh}-word in the interrogative position selected for? 

Not "saturation via context." Rather: **saturation via constraint on the quantifier domain**. The question *"Who did you see?"* uses *who* to ask which individual from the set of contextually available agents. The proper function is to *delineate alternatives*, not to refer to one of them.

This is why *the who* sounds wrong—not because it's redundant (context already pins it down), but because you're trying to impose external restriction on something that's already a functional restrictor. The impropriety is functional, not semantic.

Here's what excites me: this shows that **referential saturation comes in kinds**. The HPC clustering of "pronoun" (or \mention{wh}-words) isn't unified by a single saturation mechanism; it's unified by *saturation of different types achieving the same grammatical consequence*. 

That's a genuine insight into why HPC categories can appear unified while their underlying mechanisms diverge.

## Fat Categories and Proper Functions

Adverbs. The wastebasket. You're right to flag this as the negative case.

What *would* be the proper function of an adverb? Unlike nouns (selection for reference to individuals) or verbs (selection for asserting events/states), adverbs have no unified functional pedigree. They're recruited for:

- Manner modification (from adjectives; proper function inherited)
- Frequency modification (from quantifiers; different proper function)
- Speaker commitment (evidential function; something else entirely)
- Clausal modification (scope and grounding; heterogeneous again)

A category with no unified proper function isn't an HPC *kind*—it's a garbage-collection bin. The distributional coherence is real (adverbs pattern together in certain contexts), but there's no principled reason they should. The "proper function" of being an adverb is just "whatever wasn't noun, verb, or adjective."

That's not a category to stake projectibility on. It's a residue.

The interesting question for Chapter 11: Can you show that nouns, verbs, and adjectives *do* have unified proper functions across their clustering, while adverbs demonstrably don't? That would ground your claim about word-class architecture not at the level of distributional properties, but at the level of *what they were linguistically selected to do*.

That framing shifts the whole chapter's center of gravity. It's not just about clustering patterns—it's about the proper functions those patterns serve.
