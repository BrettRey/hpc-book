1) Mechanism-braiding and categorical universals. I take universality of lexical categories (N, V, A) to follow from syntactic architecture and functional scaffolding, not from a semantic essence. On my view, the distinctions are tied to positions in the functional spine (N needing D to be argumental, V projecting aspect/argument structure), so universals track structure. The braiding story supports this: determiner resistance can arise from deixis, binding, or alternatives, yet still yield a stable distribution. That means a category can be structurally uniform while semantically heterogeneous. It challenges naive essentialism about “pronoun” or “\mention{wh}-word,” but it does not undermine universals; it explains why structurally defined types reappear cross-linguistically even when the semantic path to them differs. If anything, it offers a mechanism for why universals are resilient: different inputs converge on the same syntactic role and are then reinforced by acquisition and usage.

2) Generativist analysis of the interrogative puzzle. In a Minimalist account, interrogative wh-items carry a [wh]/[Q] feature and are licensed by the C-system. The wh-expression either occupies D itself or checks features with a null D, so an overt determiner is incompatible: D is already filled or its features are already valued. This predicts why which behaves like a determiner in some languages: it merges in D, so another determiner is excluded by head competition. Semantically, wh introduces a set of alternatives, and a Q-operator binds that set; syntactically, operator status is encoded in the feature system that triggers movement or in-situ licensing. Thus alternatives-based saturation is real, but its grammatical reflex is feature checking and head occupancy, which explains determiner resistance without adding a special semantic stipulation.

3) Shared ground between HPC and formal features. Both frameworks treat distributions as stabilized by mechanisms rather than as arbitrary conventions. Formal features are the grammar-internal coding of those stabilizers; HPC narrates the external causal ecology that makes the coding reliable (acquisition, discourse, processing, transmission). The braiding story is the bridge: semantic pressures like referential saturation become entrenched as stable feature bundles (e.g., D licensed without an overt article; [wh]/[pro] configurations), and those bundles become learnable cues for category induction. Features yield crisp diagnostics (agreement, selection, movement), while HPC supplies the causal story for why those diagnostics cluster and stay projectible across generations of learners. So HPC can be read as a realist foundation for why feature clusters are projectible, while the feature system gives the precise implementation inside grammar.
