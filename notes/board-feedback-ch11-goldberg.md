# Board Feedback: Chapter 11 (Word Classes)
**Reviewer:** Adele Goldberg
**Date:** December 25, 2025

This chapter tackles a foundational issue: the stability of major word classes versus the variability of minor ones. While I appreciate the HPC framework’s focus on "mechanisms" over "essences," as a constructionist, I need to see how this integrates with what we know about how learners actually generalize.

### 1. How constructions stabilize word class membership
You argue that nouns and verbs are stable HPCs because they represent "architectural equilibrium." I would frame this more explicitly: word classes are emergent generalizations over the argument structure constructions they inhabit. A word isn't "born" a verb; it is *coerced* into that category by successfully appearing in the V-slot of the Transitive Construction or the Intransitive Motion Construction.

The mechanism of stability here is **distributional consistency**. The "noun-hood" of a word is reinforced every time it appears in a determination slot (e.g., *the X*). If HPC is the theory of the cluster, constructions are the primary *stabilizers* that maintain the cluster's boundaries. I’d like to see Chapter 11 explicitly map "mechanisms" to specific high-frequency constructional schemas that anchor these categories.

### 2. What does HPC add beyond Construction Grammar?
CxG already treats categories as radial sets with prototypes (e.g., "give" as the prototype for the Ditransitive). We acknowledge gradience. The value add of HPC, potentially, is providing a causal explanation for *why* certain clusters (N/V) are cross-linguistically robust attractors while others (Adj/Adv) are not.

If HPC can show that Noun/Verb stability arises from a "standing wave" of converging cognitive and communicative pressures—biological biases for object/action individuation conspiring with discourse needs—that strengthens the Construction Grammar position. It moves us from "these are the patterns we see" to "these are the causal forces that make these patterns inevitable." That is a welcome deepening of the theory.

### 3. Integrating acquisition evidence
The most critical mechanism you must address is **statistical preemption**. How do learners retreat from overgeneralization if categories are fuzzy property clusters? In CxG, we show that hearing *sneeze* in the intransitive enough times blocks it from the transitive (*He sneezed the napkin*).

If word classes are HPCs, acquisition is the process of tuning the tolerance levels for these clusters. You need to cite evidence showing that children rely on token frequency to establish the core (the prototype) and type frequency to expand the boundaries. The "adjective-adverb asymmetry" you note likely stems from the lower type frequency and higher functional variability of adjectival slots compared to the rigid argument structure slots of verbs. Stability is a function of input statistics.
